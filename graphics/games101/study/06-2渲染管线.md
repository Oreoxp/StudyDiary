[TOC]

[TOC]



# 渲染管线 Graphics (Real-time Rendering)Pipeline

### 2.1 渲染管线流程

​		通过图形渲染管线都是流水线形式，上一阶段的输出作为下一阶段的输入，该课程的一个图形渲染管线（也是前向渲染管线）流程如下：
![image.png](https://bbs-img.huaweicloud.com/blogs/img/20220506/1651822500227254676.png)

​		总体来说：顶点 →光栅化 →着色
​		用mvp举例：
MVP（Model, View, Projection transforms）→采样 →z-buffer test →shading →Texture mapping
![image.png](https://bbs-img.huaweicloud.com/blogs/img/20220506/1651822511823927146.png)

具体来说：

1. 首先我们有一系列三维点坐标，可能是从某些文件读入。然后我们把它们输入给Vertex Processing阶段（顶点着色器），该阶段主要进行的操作是`model`，`view`，`projection`变换，将三维坐标变换到二维裁剪空间（通过投影丢掉了不可见的区域），也可以进行`gouraud shading`等操作。
   ![image.png](https://bbs-img.huaweicloud.com/blogs/img/20220506/1651824544265916242.png)
2. 随后把顶点着色器的输出，作为输入给`Triangle Processing`阶段，这里主要是进行一些图元的绘制，包括把点连接成三角形，或者制作一些顶点的副本等
3. 下一个阶段是`Rasterization`阶段（光栅化），该阶段将三维图元作为输入，通过采样将其绘制在二维屏幕上，并以`片段`的形式作为输出。

片段、像素 关系说明：

- `片段(Fragment)`:三维顶点光栅化后的数据集合，还没有经过深度测试
- `像素`:片段经过深度测试、模板测试、alpha混合之后的结果
- 片段的个数远远多于像素，因为有的片段会在测试和混合阶段被丢弃，无法被渲染成像素

![image.png](https://bbs-img.huaweicloud.com/blogs/img/20220506/1651824753556261646.png)

1. `Fragment Processing` 把片段作为输入。该阶段主要进行`深度测试`，`计算光照`以及`纹理映射`等，所以该阶段输出的结果基本上已经确定了像素最终的颜色。
   ![image.png](https://bbs-img.huaweicloud.com/blogs/img/20220506/1651824875253313204.png)

![image.png](https://bbs-img.huaweicloud.com/blogs/img/20220506/1651824892223991670.png)

![image.png](https://bbs-img.huaweicloud.com/blogs/img/20220506/1651824902380140045.png)





### 2.2 管线渲染编程

​		通常可以在`Vertex Processing`阶段（顶点着色器） 和 `Fragment Processing`阶段（片段着色器） 进行编程，这些编程的小程序被称为Shader Programs，里面常用的语言有glsl等。

​		shader 编写学习资料: https://www.shadertoy.com/.

#### 2.2.1 Shader programs概念说明

1. 能在硬件上执行的语言
2. 每个顶点/像素执行一次（通用的，不用for循环）
   - 顶点的操作→顶点着色器 vertex shader
   - 像素的操作→像素/片元着色器 fragment shader

​        一个 GLSL 中的例子：下面的示例程序简单描述了一个着色器的工作，`uniform` 表示从 cpu 传来的变量，`varying`  表示从上一个阶段传来的变量，`void diffuseShader()`  为着色函数， `texture2d` 是内置函数，它表示将纹理 myTexture 对应到 uv 向量，`gl_FragColor`  可以看做是内置参数，它是屏幕上用来显示的最终颜色。

```javascript
uniform sampler2D myTexture; // program parameter 
uniform vec3 lightDir;   // program parameter 
varying vec2 uv;    // per fragment value (interp. by rasterizer)
varying vec3 norm;   // per fragment value (interp. by rasterizer) 
void diffuseShader() 
{   
	vec3 kd;   
	kd = texture2d(myTexture, uv);    // material color from texture  
	kd *= clamp(dot(–lightDir, norm), 0.0, 1.0);  // Lambertian shading model   
	gl_FragColor = vec4(kd, 1.0);    // output fragment color 
}
```

#### 2.2.2 Snail Shader Program 在线Shader编写网站

https://www.shadertoy.com/view/ld3Gz2

3.GPU
①gpu：-独显；-核显
②gpu可以理解成高度并行化的处理器
（核心数量理解为并行线程的数量）
gpu 并行度惊人，远超过cpu

## 三、Texture Mapping纹理映射

​		`纹理映射`就是将纹理空间中的纹理像素映射到屏幕空间中的像素的过程。通俗来说可以认为是一张二维纹理把一个三维物体“包裹”了起来，因此三维物体获得了一些表面纹理：

![image.png](https://bbs-img.huaweicloud.com/blogs/img/20220506/1651826357031629706.png)
![image.png](https://bbs-img.huaweicloud.com/blogs/img/20220506/1651822553834857811.png)

### 纹理坐标系

​		纹理也是有坐标的，它的坐标空间是由 uv 构成(通常 [0, 1] )，里面对应的元素是`纹素`，是计算机图形纹理空间中的基本单元，如下图：
![image.png](https://bbs-img.huaweicloud.com/blogs/img/20220506/1651822568799189548.png)

​		`纹素`和`像素`不一样，因为它们是处于不同坐标下的，纹素处于纹理空间，而像素处于屏幕空间。在对三维表面铺设纹理的时候，通过纹理映射技术将纹素映射到恰当的输出图像像素上，这种映射不是简单的一一对应，因为会受到视角的影响，如果以一种斜的姿势观察物体，一个像素对应的纹理区域很可能是比较扭曲的，可以看下图：
![image.png](https://bbs-img.huaweicloud.com/blogs/img/20220506/1651828555838201854.png)

纹理和着色的区别与联系
纹理用来定义着色的时候需要的不同点的属性（不希望每一个点相同着色，用纹理来改变）







































