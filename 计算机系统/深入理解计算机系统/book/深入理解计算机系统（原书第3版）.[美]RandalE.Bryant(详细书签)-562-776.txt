526 第二部分在系统上运行程序
--------------------------------------------------------------------------code/ecf/shellex.c
^	/* parseline - Parse the command line and build the argv array */
2	int parseline(chax *buf, char **argv)
3	{
4	char *delim
5	int argc;
6	int bg;
7
8	buf [strlen(buf)-1] =	1 1;	/*	Replace	trailing	'\n'	with space */
9	while (*buf && (*buf	==	’	'))	/*	Ignore	leading spaces	*/
i〇	buf++;
n
12	/* Build the	argv list */
13	argc = 0;
14	while ((delim = strchr(buf,	1
15	argv[argc++] =	buf;
16	*delim = '\0’；
17	buf = delim + 1;
18	while (*buf &&	(*buf =='
19	buf++;
20	>
21	argv[argc]	-	NULL;
22
23	if (argc == 0)	/* Ignore blank line */
24	return 1;
25
26	/本 Should the job run in the background? */
27	if C(bg = (*argv[argc-l] == '&')) != 0)
28	axgv[--argc] -	NULL;
29
30	return bg;
31	>
))){
'))/* Ignore spaces */
/* Points to first space delimiter */ /* Number of args */
/* Background job? */
code/ecf/shellex.c
|¥| 8-25 parseline 解析 shell 的一个输人行
注意，这个简单的shell是有缺陷的，因为它并不回收它的后台子进程。修改这个缺 陷就要求使用信号，我们将在下一节中讲述信号。
8.	5信号
到目前为止对异常控制流的学习中，我们已经看到了硬件和软件是如何合作以提供基 本的低层异常机制的。我们也看到了操作系统如何利用异常来支持进程上下文切换的异常 控制流形式。在本节中，我们将研究一种更高层的软件形式的异常，称为Unux信号，它 允许进程和内核中断其他进程。
一个信号就是一条小消息，它通知进程系统中发生了一个某种类型的事件^比如，图8-26 展示了 Linux系统上支持的30种不同类型的信号。
每种信号类型都对应于某种系统事件。低层的硬件异常是由内核异常处理程序处理的，正 常情况下，对用户进程而言是不可见的。信号提供了一种机制，通知用户进程发生了这些异常。 比如，如果一个进程试图除以0,那么内核就发送给它一个SIGFPE信号(号码8)。如果一个进
第8章异常控制流 527
程执行一条非法指令，那么内核就发送给它一个SIGILL信号(号码4)。如果进程进行非法内存 引用，内核就发送给它一个SIGSEGV信号(号码11)。其他信号对应于内核或者其他用户进程 中较高层的软件事件==比如，如果当进程在前台运行时，你键人Ctrl+C(也就是同时按下Ctrl 键和C键)，那么内核就会发送一个SIGINT信号(号码2)给这个前台进程组中的每个进程。一 个进程可以通过向另一个进程发送一个SIGKILL信号(号码9)强制终止它。当一个子进程终止 或者停止时，内核会发送一个SIGCHLD信号(号码17)给父进程。
序号	名称	默认行为	相应事件
1	SIGHUP	终止	终端线挂断
2	SIGINT	终止	来自键盘的中断
3	SIGQUIT	终止	来自键盘的退出
4	SIGILL	终止	非法指令
5	SIGTRAP	终止并转储内存®	跟踪陷阱
6	SIGABRT	终止并转储内存®	来自abort函数的终止信号
7	SIGBUS	终止	总线错误
8	SIGFPE	终止并转储内存®	浮点异常
9	SIGKILL	终止②	杀死程序
10	SIGUSR1	终止	用户定义的信号1
11	SIGSEGV	终止并转储内存®	无效的内存引用（段故障）
12	SIGUSR2	终止	用户定义的信号2
13	SIGPIPE	终止	向一个没有读用户的管道做写操作
14	SIGALRM	终止	来自alarm函数的定时器信号
15	SIGTERM	终止	软件终止信号
16	SIGSTKFLT	终止	协处理器上的栈故障
17	SIGCHLD	忽略	一个子进程停止或者终止
18	SIGCONT	忽略	继续进程如果该进程停止
19	SIGSTOP	停止直到下一个SIGCONT®	不是来自终端的停止信号
20	SIGTSTP	停止直到下一个SIGCONT	来自终端的停止信号
21	SIGTTIN	停止直到下一个SIGCONT	后台进程从终端读
22	SIGTTOU	停止直到下一个SIGCONT	后台进程向终端写
23	SIGURG	忽略	套接字上的紧急情况
24	SIGXCPU	终止	CPU时间限制超出
25	SIGXFSZ	终止	文件大小限制超出
26	SIGVTALRM	终止	虚拟定时器期满
27	SIGPROF	终止	剖析定时器期满
28	SIGWINCH	忽略	窗口大小变化
29	SIGIO	终止	在某个描述符上可执行I/O操作
30	SIGPWR	终止	电源故障
图8-26 Linux信号
注：①多年前，主存是用一种称为磁芯存储器（core memory)的技木来实现的„ “转储内存"（dumping core)是一 个历史术语，意思是把代码和数据内存段的映像写到磁盘上。
②这个信号既不能被捕获，也不能被忽略。
(来源：man 7 signal。数据来自 Linux Foundation。）
8.5. 1信号术语
传送一个信号到目的进程是由两个不同步骤组成的：
*发送信号。内核通过更新目的进程上下文中的某个状态，发送（递送）一个信号给目 的进程。发送信号可以有如下两种原因：1)内核检测到一个系统事件，比如除零错 误或者子进程终止。2)—个进程调用了 kill函数（在下一节中讨论），显式地要求 内核发送一个信号给目的进程。一个进程可以发送信号给它自己。
528 第二部分在系统上运行程序
•接收信号。当目的进程被内核强迫以某种方式对信号的发送做出反应时，它就接收了 信号。进程可以忽略这个信号，终止或者通过执行一个称为信号处理程序（signal handler) 的用户层函数捕获这个信号。图 8-27 给出了信号处理程序捕获信号的基本思想。
(3)信号处 理程序运行
1^1 8-27信号处理。接收到信号会触发控制转移到信号处理程序。在信号处理程序 完成处理之后，它将控制返回给被中断的程序
—个发出而没有被接收的信号叫做待处理信号（pending signal)。在任何时刻，一种类 型至多只会有一个待处理信号。如果一个进程有一个类型为々的待处理信号，那么任何接 下来发送到这个进程的类型为々的信号都不会排队等待；它们只是被简单地丢弃。一个进 程可以有选择性地阻塞接收某种信号。当一种信号被阻塞时，它仍可以被发送，但是产生 的待处理信号不会被接收，直到进程取消对这种信号的阻塞。	•
—个待处理信号最多只能被接收一次。内核为每个进程在pending位向量中维护着 待处理信号的集合，而在blocked位向量e中维护着被阻塞的信号集合。只要传送了一个 类型为A的信号，内核就会设置pending中的第々位，而只要接收了一个类型为々的信 号，内核就会清除pending中的第々位。
8.	5. 2发送信号
Unix系统提供了大量向进程发送信号的机制。所有这些机制都是基于进程组（process group)这个概念的。
1.进程组
每个进程都只属于一个进程组，进程组是由一个正整数进程组ID来标识的。getpgrp 函数返回当前进程的进程组ID:
(2 )控制传递到 信号处理程序
(4 >信号处理程序 返回到下一条指令
#include <unistd.li>	
pid_t getpgrp(void);	返回：调用进程的进程组ID„
默认地，一个子进程和它的父进程同属于一个进程组。一个进程可以通过使用set-pgid函数来改变自己或者其他进程的进程组：
#include <unistd.li>
int setpgid(pid_t pid, pid_t pgid);
返回：若成功则为〇，若错误则为一L
setpgid函数将进程pid的进程组改为pgid。如果pid是0,那么就使用当前进程
©也称为信号掩码（signal mask)。
第8章异常控制流	5烈
的PHX如果pgid是0,那么就用pid指定的进程的PID作为进程组1D。例如，如果进 程15213是调用进程，那么 setpgid(0, 0);
会创建一个新的进程组，其进程组ID是15213,并且把进程15213加人到这个新的进程 组中。
2.用/bin/kill程序发送信号
/bin/kill程序可以向另外的进程发送任意的信号。比如，命令 linux> /bin/kill -9 15213
发送信号9(SIGKILL)给进程15213。一个为负的PID会导致信号被发送到进程组PID中 的每个迸程。比如，命令
linux> /bin/kill -9 -15213
发送一个SIGKILL信号给进程组15213中的每个进程。注意，在此我们使用完整路径/ bin/kill，因为有些Unix shell有自己内置的kill命令。
3.从键盘发送信号
Unix shell使用作业(job)这个抽象概念来表示为对一条命令行求值而创建的进程。在 任何时刻，至多只有一个前台作业和〇个或多个后台作业。比如，键人 linux> Is I sort
会创建一个由两个进程组成的前台作业，这两个进程是通过Unix管道连接起来的：一个 进程运行Is程序，另一个运行sort程序。shell为每个作业创建一个独立的进程组。进程 组ID通常取自作业中父进程中的一个。比如，图8-28展示了有一个前台作业和两个后台 作业的shell。前台作业中的父进程PID为20,进程组ID也为20。父进程创建两个子进 程，每个也都是进程组20的成员。
pid = 40 pgid=40
前台进程组20
图8-28前台和后台进程组
在键盘上输入Ctrl+C会导致内核发送一个SIGINT信号到前台进程组中的每个进 程。默认情况下，结果是终止前台作业。类似地，输人Ctrl + Z会发送一个SIGTSTP信 号到前台进程组中的每个进程。默认情况下，结果是停止（挂起）前台作业。
530 第二部分在系统上运行程序
4.用kill函数发送信号
进程通过调用kill函数发送信号给其他进程（包括它们自己）。
#include <sys/types.h>
#include <signal.h>
int kill(pid_t pid, int sig);
返回：若成功则为0，若错误则为一 1。
如果pid大于零，那么kill函数发送信号号码sig给进程pid。如果pid等于零，那么 kill发送信号sig给调用进程所在进程组中的每个进程，包括调用进程自己。如果pid 小于零，kill发送信号sig给进程组|pid|(pid的绝对值）中的每个进程。图8-29雇示 了一个示例，父进程用kill函数发送SIGKILL信号给它的子进程。
---------------------------------------code/ecf/kill.c
1	#include "csapp.tL1*	
3	int r	mainO
4 5 6	\	pid_t pid;
7		/* Child sleeps until SIGKILL signal received, then
8		if ((pid = ForkO) == 0) {
9		Pause(); /* Wait for a signal to arrive */
10		printf("control should never reach here!\n");
11		exit(0);
12		>
13 14		/* Parent sends a SIGKILL signal to a child */
15		Kill(pid, SIGKILL);
16		exit(O);
17	>	
code/ecf/kill.c
-阁8-29使用kill函数发送信号给子进程
5.用alarm函数发送信号
进程可以通过调用alarm函数向它自己发送SIGALRM信号。
#include <unistd.h>
unsigned int alarm(unsigned int secs);
返回：前一次闹钟剩余的秒数，若以前没有设定闹钟，则为o.
alarm函数安排内核在secs秒后发送一个SIGALRM信号给调用进程。如果secs 是零，那么不会调度安排新的闹钟（alarm)。在任何情况下，对alarm的调用都将取消任 何待处理的（pending)闹钟，并且返回任何待处理的闹钟在被发送前还剩下的秒数（如果这 次对alarm的调用没有取消它的话）；如果没有任何待处理的闹钟，就返回零。
第8章异常控制流 531
8.5.3接收信号
当内核把进程从内核模式切换到用户模式时（例如，从系统调用返回或是完成了一 次上下文切换），它会检査进程的未被阻塞的待处理信号的集合(pending &〜blocked)。 如果这个集合为空（通常情况下），那么内核将控制传递到的逻辑控制流中的下一条指令 (U。然而，如果集合是非空的，那么内核选择集合中的某个信号M通常是最小的是）， 并且强制P接收信号纟。收到这个信号会触发进程采取某种行为。一旦进程完成了这个行 为，那么控制就传递回{的逻辑控制流中的下一条指令aexl)。每个信号类型都有一个预 定义的默认行为，是下面中的一种：
•进程终止。
*进程终止并转储内存。
•进程停止(挂起）直到被SIGCONT信号重启。
*进程忽略该信号。
图8-26展示了与每个信号类型相关联的默认行为。比如，收到SIGKILL的默认行为 就是终止接收进程。另外，接收到SIGCHLD的默认行为就是忽略这个信号。进程可以通 过使用signal函数修改和信号相关联的默认行为。唯一的例外是SIGSTOP和SIGKILL， 它们的默认行为是不能修改的。
#include <signal.h>
typedef void (*sighandler_t)(int);
sighandler_t signal(int signum, sighandler.t handler);
返回：若成功则为指向前次处理程序的指针，若出错则为SIG_ERR(不设置eirrno)。
signal函数可以通过下列三种方法之一来改变和信号signum相关联的行为：
•如果handler是SIG_IGN，那么忽略类型为signum的信号D i•如果handler是SIG_DFL，那么类型为signum的信号行为恢复为默认行为。
•否则，handler就是用户定义的函数的地址，这个函数被称为信号处理程序，只要进 程接收到一个类型为signum的信号，就会调用这个程序。通过把处理程序的地址传 递到signal函数从而改变默认行为，这叫做设置信号处理程序（installing the handler)。 调用信号处理程序被称为捕获信号。执行信号处理程序被称为处理信号。
当一个进程捕获了一个类型为々的信号时，会调用为信号丨设置的处理程序，一个整 数参数被设置为匕这个参数允许同一个处理函数捕获不同类型的信号。
当处理程序执行它的return语句时，控制（通常）传递回控制流中进程被信号接收中 断位置处的指令。我们说“通常”是因为在某些系统中，被中断的系统调用会立即返回一 个错误。
图8-30展示了一个程序，它捕获用户在键盘上输人Ctrl + C时发送的SIGINT信号。 SIGINT的默认行为是立即终止该进程。在迭个示例中，我们将默认行为修改为捕获信 号，输出一条消息，然后终止该进程。
信号处理程序可以被其他信号处理程序中断，如图8-31所示。在这个例子中，主程 序捕获到信号该信号会中断主程序，将控制转移到处理程序S。S在运行时，程序捕 获信号该信号会中断S，控制转移到处理程序了。当了返回时，S从它被中断的地 方继续执行。最后，S返回，控制传送回主程序，主程序从它被中断的地方继续执行。
532 第二部分在系统上运行程序
1	#include "csapp.h"	
3	void sigint_handler(int sig) /* SIGINT	handler */
4		
5	printf("Caught SIGINT!\n");	
6	exit(0);	
7 8	>	
9	int main()	
10		
11	/* Install the SIGINT handler */	
12	if (signal(SIGINT, sigint.handler)	==SIG.ERR)
13	unix_error("signal error");	
14		
15	pauseO ; /* Wait for the receipt of	a signal */
16		
17	return 0;	
18	>	
code/ecf/sigint. c
code/ecf/sigint.c
m .W —个用信号处理程序捕获SIGINT信号的程序
主程序
处理程序^	处理程序r
(1)程序捕获信号s I
(2)控制信号传递 给处理程序
(4)控制传递给处理程序r
(7)主程序继续执行
(3)程序捕获信号/
(6 )处理程序返回到主程序	处理程序_S
1^1 8-3 I信号处理程序可以被其他信号处理程序中断
练习题8.7编写一个叫做snooze的程序，它有一个命令行参数，用这个参数调用 练习题8.5中的snooze函数，然后终止。编写程序，使得用户可以通过在键盘上输 入Ctrl + C中断snooze函数。比如： linux> ./snooze 5
CTRL+C	User hits Crtl+C after 3 seconds
Slept for 3 of 5 secs.
linux>
8.	5. 4 阻塞和解除阻塞信号
Linux提供阻塞信号的隐式和显式的机制：
隐式阻塞机制。内核默认阻塞任何当前处理程序正在处理信号类型的待处理的信号。 例如，图8-31中，假设程序捕获了信号5，当前正在运行处理程序S。如果发送给该进程 另一个信号^那么直到处理程序S返回，5会变成待处理而没有被接收。
显式阻塞机制。应用程序可以使用sigprocmask函数和它的辅助函数，明确地阻塞 和解除阻塞选定的信号。
第8章异常控制流 533
#include <signal.h>
int sigprocmask(int how, const sigset_t *set， sigset_t *oldset);
int sigemptyset(sigset_t *set);
int sigfillsetCsigset_t *set);
int sigaddset(sigset_t *set, int signum);
int sigdelset(sigset.t *set, int signum);
返回：如果成功则为0,若出错则为一u
int sigismember(const sigset_t *set, int signum);
返回：若signum是set的成员则为1,如果不是则为〇，若出错则为一U
sigprocmask函数改变当前阻塞的信号集合（8. 5. 1节中描述的blocked位向量）。具 体的行为依赖于how的值：
SIG—BLOCK:把 set 中的信号添加到 blocked 中（blocked=blocked | set)。 SIG_UNBLOCK:从 blocked 中删除 set 中的信号（blocked=blocked kset)。 SIG_SETMASK ： block=set〇
如果oldset非空，那么blocked位向量之前的值保存在oldset中。
使用下述函数对set信号集合进行操作：sigenptyset初始化set为空集合。sigfillset 函数把每个信号都添加到set中。sigaddset函数把signum添加到set，sigdelset从set中 删除signum，如果signum是set的成员，那么sigismember返回1，否则返回0。
例如，图8-32展7K 了如何用sigprocmask来临时阻塞接收SIGINT信号D
1	sigset.t mask, prev.mask;
2
3	SigemptysetC&mask);
4	Sigaddset(&mask, SIGINT);
5
6	/* Block SIGINT and save previous blocked set */
7	Sigprocmask(SIG_BL0CK, &mask, &prev_mask);
8	.	// Code region that will not be interrupted by SIGINT
9	/* Restore previous blocked set, unblocking SIGINT */
10	Sigprocmask(SIG_SETMASK, &prev_mask, NULL);
11
m 8-32临时阻塞接收一个信号
8.5.5编写信号处理程序
信号处理是Linux系统编程最棘手的一个问题。处理程序有几个属性使得它们很难推 理分析：1)处理程序与主程序并发运行，共享同样的全局变量，因此可能与主程序和其他 处理程序互相干扰；2)如何以及何时接收信号的规则常常有违人的直觉；3)不同的系统有 不同的信号处理语义。
在本节中，我们将讲述这些问题，介绍编写安全、正确和可移植的信号处理程序的一 些基本规则。
1.安全的信号处理
信号处理程序很麻烦是因为它们和主程序以及其他信号处理程序并发地运行，正如我 们在图8-31中看到的那样。如果处理程序和主程序并发地访问同样的全局数据结构，那
534 第二部分在系统上运行程序
么结果可能就不可预知，而且经常是致命的。
我们会在第12章详细讲述并发编程。这里我们的目标是给你一些保守的编写处理程 序的原则，使得这些处理程序能安全地并发运行。如果你忽视这些原则，就可能有引入细 微的并发错误的风险。如果有这些错误，程序可能在绝大部分时候都能正确工作。然而当 它出错的时候，就会错得不可预测和不可重复，这样是很难调试的。一定要防患于未然！
•	GO.处理程序要尽可能简单。避免麻烦的最好方法是保持处理程序尽可能小和简 单。例如，处理程序可能只是简单地设置全局标志并立即返回；所有与接收信号相 关的处理都由主程序执行，它周期性地检查（并重置）这个标志。
•	G1.在处理程序中只调用异步信号安全的函数。所谓异步信号安全的函数(或简称安全的函 数)能够被信号处理程序安全地调用，原因有二：要么它是可重入的(例如只访问局部变量， 见12. 7.2节)，要么它不能被信号处理程序中断。图8-33列出了 Linux保证安全的系统级 函数。注意，许多常见的函数(例如printf、sprintf、malloc和exit)都不在此列。
_Exit	fexecve	poll	sigqueue
_exit	fork	posix_trace_event	sigset
abort	f stat	pselect	sigsuspend
accept	fstatat	raise	sleep
access	f sync	read	sockatmark
aio.error	ftruncate	readlink	socket
aio.return	futimens	readlinkat	socketpair
aio_suspend	getegid	recv	stat
alarm	geteuid	recvfrom	symlink
bind	getgid	recvmsg	symlinkat
cfgetispeed	getgroups	rename	tcdrain
cfgetospeed	getpeername	renameat	tcflow
cfsetispeed	getpgrp	rmdir	tcflush
cfsetospeed	getpid	select	tcgetattr
chdir	getppid	sem_post	tcgetpgrp
chmod	getsockname	send	tcsendbreak
chown	getsockopt	sendmsg	tcsetattr
clock.gettime	getuid	sendto	tcsetpgrp
close	kill	setgid	time
connect	link	setpgid	timer^getoverrun
creat	linkat	setsid	timer_gettime
dup	listen	setsockopt	timer_settime
dup2	lseek	setuid	times
execl	lstat	shutdown	umask
execle	mkdir	sigaction	uname
execv	mkdirat	sigaddset	unlink
execve	mkfifo	sigdelset	uniinkat
faccessat	mkfifoat	sigemptyset	utime
fchmod	mknod	sigfillset	utimensat
fchmodat	mknodat	sigismember	utimes
fchown	open	signal	wait
fchownat	openat	sigpause	waitpid
f cntl	pause	sigpending	write
fdatasync	pipe	sigprocmask	
1¾1] 8-33 异步f目号安全的函数（来源：man 7 signal。數据来自Linux Foundation)
第8章异常控制流	535
信号处理程序中产生输出唯一安全的方法是使用write函数（见10. 1节）。特别地, 调用printf或sprintf是不安全的。为了绕开这个不幸的限制，我们开发一些安全的函 数，称为SIO(安全的I/O)包，可以用来在信号处理程序中打印简单的消息。
#include "csapp.h"	
ssize_t sio_putl(long v); ssize.t sio_puts(char s[]);	返回：如果成功则为传送的字节数，如果出错，则为_iD
void sio.error(char s []);	返回：空。
sio^putl和sio_puts函数分别向标准输出传送一个long类型数和一个字符串。 sio_error函数打印一条错误消息并终止。
图8-34给出的是SIO包的实现，它使用了 csapp.c中两个私有的可重人函数。第3 行的sio^strlen函数返回字符串s的长度。第10行的si〇_lt〇a函数基于来自[61]的 itoa函&，把v转换成它的基b字符串表示，保存在3中。^17行的_exit函数是exit 的一个异步信号安全的变种。
-----------------------------------------------code/src/csapp. c
1	ssize_t sio_puts(char s[]) /* Put string */
2	{
3	return writeCSTDDUT_FILENO, s, sio_strlen(s));
4	>
5
6	ssize.t sio_putl(long v) /* Put long */
7	{
8	char s[128];
9
10	sio_ltoa(v,	s,	10); /* Based on K&R itoa() */
.11	return sio_puts(s);
12	>
13
14	void sio_error(ch.ar s[]) /* Put error message and exit */
15	{
16	sio_puts(s);
17	_exit(l);
18	>
-----------------------------------------------code/src/csapp. c
图8-34信号处理程序的SIO(安全I/O)包
图8-35给出了图8-30中SIGINT处理程序的一个安全的版本。
----------------------------------------code/ecf/sigintsafe. c
^	#include "csapp.h"
2
3	void sigint_handler(int sig) /* Safe SIGINT handler */
4	{
5	Sio_puts("Caught SIGINT!\n"); /* Safe output */
6	_exit(0);	/* Safe exit */
7	>
------------------------------------------------------------code/ecf/sigintsafe. c
图8-35图8-30的SIGINT处理程序的一个安全版本
536 第二部分在系统上运行程序
•	G2.保存和恢复errno。许多Linux异步信号安全的函数都会在出错返回时设置 errno。在处理程序中调用这样的函数可能会干扰主程序中其他依赖于errn〇的部 分。解决方法是在进入处理程序时把errno保存在一个局部变量中，在处理程序返 回前恢复它。注意，只有在处理程序要返回时才有此必要。如果处理程序调用 _exit终止该进程，那么就不需要这样做了。
•	G3•阻塞所有的信号，保护对共享全局数据结构的访问。如果处理程序和主程序或其 他处理程序共享一个全局数据结构，那么在访问（读或者写)该数据结构时，你的处理 程序和主程序应该暂时阻塞所有的信号。这条规则的原因是从主程序访问一个数据结 构d通常需要一系列的指令，如果指令序列被访问d的处理程序中断，那么处理程序 可能会发现^的状态不一致，得到不可预知的结果。在访问J时暂时阻塞信号保证了 处理程序不会中断该指令序列。
•	G4•用volatile声明全局变量。考虑一个处理程序和一个mairi函数，它们共享一个全 局变量g。处理程序更新g，main周期性地读g。对于一个优化编译器而言，main中g 的值看上去从来没有变化过，因此使用缓存在寄存器中g的副本来满足对g的每次引用 是很安全的。如果这样，main函数可能永远都无法看到处理程序更新过的值。
可以用volatile类型限定符来定义一个变量，告诉编译器不要缓存这个变量。例如： volatile int g;
volatile限定符强迫编译器每次在代码中引用g时，都要从内存中读取g的 值。一般来说，和其他所有共享数据结构一样，应该暂时阻塞信号，保护每次对全 局变量的访问。
•	G5•用sig_atomiC_t声明标志。在常见的处理程序设计中，处理程序会写全局标 志来记录收到了信号。主程序周期性地读这个标志，响应信号，再清除该标志。对 于通过这种方式来共享的标志，C提供一种整型数据类型sig_atomic_t,对它的 读和写保证会是原子的（不可中断的），因为可以用一条指令来实现它们： volatile sig_atomic_t flag;
因为它们是不可中断的，所以可以安全地读和写sig_at〇miC_t变量，而不需 要暂时阻塞信号。注意，这里对原子性的保证只适用于单个的读和写，不适用于像 flag+ +或flag=flag+10这样的更新，它们可能需要多条指令。
要记住我们这里讲述的规则是保守的，也就是说它们不总是严格必需的。例如，如果 你知道处理程序绝对不会修改errno,那么就不需要保存和恢复errn◦。或者如果你可以 证明printf的实例都不会被处理程序中断，那么在处理程序中调用printf就是安全的。 对共享全局数据结构的访问也是同样。不过，一般来说这种断言很难证明。所以我们建议 你采用保守的方法，遵循这些规则，使得处理程序尽可能简单，调用安全函数，保存和恢 复errno，保护对共享数据结构的访问，并使用volatile和sig_atomic_t。
2.正确的信号处理
信号的一个与直觉不符的方面是未处理的信号是不排队的。因为pending位向量中 每种类型的信号只对应有一位，所以每种类型最多只能有一个未处理的信号。因此，如果 两个类型々的信号发送给一个目的进程，而因为目的进程当前正在执行信号々的处理程 序，所以信号6被阻塞了，那么第二个信号就简单地被丢弃了；它不会排队。关键思想是 如果存在一个未处理的信号就表明至少有一个信号到达了。
第8章异常控制流	537
要了解这样会如何影响正确性，来看一个简单的应用，它本质上类似于像shell和 Web服务器这样的真实程序。基本的结构是父进程创建一些子进程，这些子进程各自独立 运行一段时间，然后终止。父进程必须回收子进程以避免在系统中留下僵死进程。但是我 们还希望父进程能够在子进程运行时自由地去做其他的工作。所以，我们决定用 SIGCHLD处理程序来回收子进程，而不是显式地等待子进程终止。（回想一下，只要有 一个子进程终止或者停止，内核就会发送一个SIGCHLD信号给父进程。）
图8-36展示了我们的初次尝试。父进程设置了一个SIGCHLD处理程序，然后创建
1
10
12
13
14
15
16
17
18
19
20
23
24
25
26
27
28
29
30
32
33
34
35
36
37
38
39
/* WARNING: This code is buggy! */
code/ecf/signall. c
void handlerl(int sig)
int olderrno = errno;
if ((waitpid(-l, NULL, 0)) < 0) sio_error("waitpid error"); Sio_puts("Handler reaped SleepCl); errno = olderrno;
int main0
int i, n;
char buf[MAXBUF];
if (signal(SIGCHLD, handlerl) == SIG.ERR) unix_error("signal error");
/* Parent creates children */ for (i = 0; i < 3; i++) { if (Fork() == 0) {
printf ("Hello from child %d\n" , (int)getpidO); exit(0);
>
>
/* Parent waits for terminal input and then processes it */ if ((n = read(ST0IN_FILENO, buf, sizeof(buf))) < 0) unix_error("read");
printf("Parent processing input\n”）； while (1)
exit(0);
-------------------------------------code/ecf/signall.c
图8-36 signall:这个程序是有缺陷的，因为它假设信号是排队的
538 第二部分在系统上运行程序
了3个子进程。同时，父进程等待来自终端的一个输人行，随后处理它。这个处理被模型 化为一个无限循环。当每个子进程终止时，内核通过发送一个SIGCHLD信号通知父进 程。父进程捕获这个S1GCHLD信号，回收一个子进程，做一些其他的清理工作（模型化 为sleep语句），然后返回。
图8-36中的signall程序看起来相当简单。然而，当在Linux系统上运行它时，我 们得到如下输出：
linux> ./signall Hello from child 14073 Hello from child 14074 Hello from child 14075 Handler reaped child Handler reaped child CR
Parent processing input
从输出中我们注意到，尽管发送了 3个SIGCHLD信号给父进程，但是其中只有两个信号被 接收了，因此父进程只是回收了两个子进程。如果挂起父进程，我们看到，实际上子进程 14075没有被回收，它成了一个僵死进程（在ps命令的输出中由字符串“defunct”表呀)：
Ctrl+Z	
Suspended	
linux> ps t	
PID TTY	STAT TIME COMMAND
14072 pts/3	T	0:02	./signall
14075 pts/3	Z	0:00	[signall] <defunct>
14076 pts/3	R+	0:00	ps t
哪里出错了呢？问题就在于我们的代码没有解决信号不会排队等待这样的情况。所发 生的情况是：父进程接收并捕获了第一个信号。当处理程序还在处理第一个信号时，第二 个信号就传送并添加到了待处理信号集合里。然而，因为SIGCHLD信号被SIGCHLD处 理程序阻塞了，所以第二个信号就不会被接收。此后不久，就在处理程序还在处理第一个 信号时，第三个信号到达了。因为已经有了一个待处理的SIGCHLD,第三个SIGCHLD 信号会被丢弃。一段时间之后，处理程序返回，内核注意到有一个待处理的SIGCHLD信 号，就迫使父进程接收这个信号。父进程捕获这个信号，并第二次执行处理程序。在处理 程序完成对第二个信号的处理之后，已经没有待处理的SIGCHLD信号了，而且也绝不会 再有，因为第三个SIGCHLD的所有信息都已经丢失了。由此得到的重要教训是，不可以 用信号来对其他进程中发生的事件计数。
为了修正这个问题，我们必须回想一下，存在一个待处理的信号只是暗示自进程最后 一次收到一个信号以来，至少已经有一个这种类型的信号被发送了。所以我们必须修改 SIGCHLD的处理程序，使得每次SIGCHLD处理程序被调用时，回收尽可能多的僵死子 进程。图8-37展示了修改后的SIGCHLD处理程序。
当我们在Umix系统上运行signal2时，它现在可以正确地回收所有的僵死子进 程了：
linux> ./signal2 Hello from child 15237
第8章异常控制流 539
Hello from child 15238 Hello from child 15239 Handler reaped child Handler reaped child Handler reaped child CR
Parent processing input
1	void handler2(int sig)
2	{
3	int olderrno = errno;
code/ecf/signal2. c
5	while (waitpid(-l, NULL, 0)>0){
6	Sio_puts("Handler reaped child\n");
7	>
8	if (errno	!=	ECHILD)
9	Sio_error("waitpid error");
10	Sleep(l);
n	errno = olderrno;
12 >
------------------------------------------code/ecf/signal2. c
图8-37 Signai2:图8-36的一个改进版本，它能够正确解决信号不会排队等待的情况
JSk练习题8.8下面这个程序的输出是什么？
code/ecf/signalprobO. c
1	volatile long counter = 2;
2
3	void handlerl(int sig)
* 4	■[
5	sigset_t mask, prev_mask;
6
7	Sigfillset(&mask);
8	Sigprocmask(SIG_BL0CK, &mask, &prev_mask); /* Block sigs */
9	Sio_putl(--counter);
10	Sigprocmask(SIG_SETMASK, &prev_mask, NULL); /* Restore sigs */
11
12	_exit(0);
13	>
14
is int main()
16	{
17	pid_t pid;
18	sigset.t mask, prev_mask;
19
20	printf ("78ld" , counter);
21	fflush(stdout);
22
23	signal(SIGUSR1, handlerl);
24	if ((pid = ForkO) == 0) {
540 第二部分在系统上运行程序
28
29
30
31
32
33
while(l) {>;
>
Kill(pid, SIGUSR1);
Waitpid(-1, NULL, 0);
Sigfillset(femask);
Sigprocmask(SIG_BL0CK, &mask, &prev_mask);	/* Block sigs */
printf("%ld", ++counter);
Sigprocmask(SIG_SETMASK, &prev_mask, NULL); /* Restore sigs */ exit(0);
-----------------------------------------------code/ecf/signalprobO. c
3.可移植的信号处理
Unix信号处理的另一个缺陷在于不同的系统有不同的信号处理语义。例如：
• signal函数的语义各有不同。有些老的Unix系统在信号々被处理程序捕获之后就 把对信号6的反应恢复到默认值。在这些系统上，每次运行之后，处理程序必须调 用signal函数，显式地重新设置它自己。
•系统调用可以被中断。像read、write和accept这样的系统调用潜在地会阻塞进 程一段较长的时间，称为慢速系统调用。在某些较早版本的Unix系统中，当处理 程序捕获到一个信号时，被中断的慢速系统调用在信号处理程序返回时不再继续， 而是立即返回给用户一个错误条件，并将errn◦设置为EINTR。在这些系统上， 程序员必须包括手动重启被中断的系统调用的代码。
要解决这些问题，Posix标准定义了 sigaction函数，它允许用户在设置信号处理 时，明确指定他们想要的信号处理语义。
#include <signal.li>
int sigaction(int signum, struct sigaction *act, struct sigaction *oldact);
返回：若成功则为0，若出错则为一 1。
sigaction函数运用并不广泛，因为它要求用户设置一个复杂结构的条目。一个更简 洁的方式，最初是由W.Richard Stevens提出的[110]，就是定义一个包装函数，称为 Signal，它调用sigaction。图8-38给出了 Signal的定义，它的调用方式与signal函 数的调用方式一样。
Signal包装函数设置了一个信号处理程序，其信号处理语义如下：
•只有这个处理程序当前正在处理的那种类型的信号被阻塞。
•和所有信号实现一样，信号不会排队等待。
*只要可能，被中断的系统调用会自动重启。
•一旦设置了信号处理程序，它就会一直保持，直到Signal带着handler参数为 SIG_IGN或者SIG_DFL被调用。
我们在所有的代码中实现Signal包装函数。
8.5.6同步流以避免讨厌的并发错误
如何编写读写相同存储位置的并发流程序的问题，困扰着数代计算机科学家。一般而
第8章异常控制流 541
言，流可能交错的数量与指令的数量呈指数关系。这些交错中的一些会产生正确的结果， 而有些则不会。基本的问题是以某种方式同步并发流，从而得到最大的可行的交错的集 合，每个可行的交错都能得到正确的结果。
1
handler.t *Signal(int signum, hajidler_t ^handler)
code/src/csapp. c
struct sigaction action, old_action; act ion.sa_handler = handler;
sigemptyset(&action.sa.mask); /* Block sigs of type being handled */ action.sa_flags = SA_RESTART; /* Restaxt syscalls if possible */
if (sigaction(signum, feaction, &old_action) < 0) unix_error("Signal error"); return (old_action.sa_liandler);
— ----------------------------------code/src/csapp. c
阁8-38 Signal: sigaction的一个包装函数，它提供在Posix兼容系统上的可移植的信号处理
并发编程是一个很深且很重要的问题，我们将在第12章中更详细地讨论。不过，在 本章中学习的有关异常控制流的知识，可以让你感觉一下与并发相关的有趣的智力挑战。 例如，考虑图8-39中的程序，它总结了一个典型的Unix shell的结构。父进程在一个全局 作业列表中记录着它的当前子进程，每个作业一个条目。addjob和deletejob函数分别 向这个作业列表添加和从中删除作业。
当父进程创建一个新的子进程后，它就把这个子进程添加到作业列表中。当父进程在 SIGCHLD处理程序中回收一个终止的（僵死）子进程时，它就从作业列表中删除这个子 进程。
¥—看，这段代码是对的。不幸的是，可能发生下面这样的事件序列：
1)	父进程执行fork函数，内核调度新创建的子进程运行，而不是父进程。
2)	在父进程能够再次运行之前，子进程就终止，并且变成一个僵死进程，使得内核 传递一个SIGCHLD信号给父进程。
3)	后来，当父进程再次变成可运行但又在它执行之前，内核注意到有未处理的 SIGCHLD信号，并通过在父进程中运行处理程序接收这个信号。
4)	信号处理程序回收终止的子进程，并调用deletejob,这个函数什么也不做，因 为父进程还没有把该子进程添加到列表中。
5)	在处理程序运行完毕后，内核运行父进程，父进程从fork返回，通过调用add-job 错误地把 （不存在的） 子进程添加到作业列表中。
因此，对于父进程的main程序和信号处理流的某些交错，可能会在addjob之前调 用deletejob。这导致作业列表中出现一个不正确的条目，对应于一个不再存在而且永远 也不会被删除的作业。另一方面，也有一些交错，事件按照正确的顺序发生。例如，如果 在fork调用返回时，内核刚好调度父进程而不是子进程运行，那么父进程就会正确地把 子进程添加到作业列表中，然后子进程终止，信号处理函数把该作业从列表中删除。
这是一个称为竞争（race)的经典同步错误的示例。在这个情况中，main函数中调用 addjob和处理程序中调用deletejob之间存在竞争。如果addjob赢得进展，那么结果
542 第二部分在系统上运行程序
就是正确的。如果它没有，那么结果就是错误的。这样的错误非常难以调试，因为几乎不 可能测试所有的交错。你可能运行这段代码十亿次，也没有一次错误，但是下一次测试却 导致引发竞争的交错。
----------------------------------------------------------code/ecf/procmaskl.c
1	/* WARNING: This code is buggy! */
2	void handler(int sig)
B
4
5
6
7
8 9
10 11 12
13
14
15
16
17
18
19	int main(int argc, char **argv)
20	{
21 22
23
24
25
26
27
28	while (1)	{
29	if ((pid = ForkO) == 0) { /* Child process */
30	ExecveC'/bin/date", argv, NULL);
31	>
32	Sigprocmask(SIG_BL0CK, &mask_all, &prev_all); /* Parent process */
33	addjob(pid);	/* Add the child to the job list */
34	Sigprocmask(SIG_SETMASK, &prev_all, IJULL);
35	>
36	exit(0);
37	}
int pid;
sigset_t mask_all, prev.all;
Sigfillset(&mask_all);
Signal(SIGCHLD, handler);
initjobsO; /* Initialize the job list */
mt olderrno = errno; sigset.t mask_all, prev_all; pid_t pid;
Sigfillset(&mask_all);
while ((pid = waitpid(-l, NULL, 0)) >0){/* Reap a zombie child */ Sigprocmask(SIG_BL0CK, &mask_all, &prev_all); deletejob(pid); /* Delete the child from the job list */ Sigprocmask(SIG_SETMASK, &prev„all, NULL);
>
if (errno != ECHILD)
Sio_error("waitpid error"); errno = olderrno:
---------------------------------------code/ecf/procmaskl.c
图8-39 一个具有细微同步错误的shdl程序。如果子进程在父进程能够开始运行前就结束了，那么 addjob和deletejob会以错误的方式被调用
图8-40展示了消除图8-39中竞争的一种方法。通过在调用fork之前，阻塞 SIGCHLD信号，然后在调用addjob之后取消阻塞这些信号，我们保证了在子进程被添 加到作业列表中之后回收该子进程。注意，子进程继承了它们父进程的被阻塞集合，所以 我们必须在调用execve之前，小心地解除子进程中阻塞的SIGCHLD信号。
第8章异常控制流 543
code/ecf/procmask2.c
1	void handler(int sig)
2	{
3	int olderrno = errno;
4	sigset.t mask_all, prev_all;
5	pid_t pid;
6
7	Sigfillset(&mask_all);
8	while ((pid = waitpid(-l, NULL, 0)) >0) { /* Reap a zombie child */
9	Sigprocinask(SIG_BLOCK, &mask_all, &prev_all);
10	deletejob(pid); /* Delete the child from the job list */
n	Sigprocmask(SIG_SETMASK, &prev_all, NULL);
12	>
13	if (errno != ECHILD)
14	Sio_error("waitpid error");
15	errno = olderrno;
16	>
17
18	int main(int axgc, char 木木argv)
19	{
20	int pid;
21	sigset_t mask_all, mask_one, prev一one;
22
23	Sigfillset(&mask_all);
24	Sigemptyset(&mask_one);
25	Sigaddset(&mask_one, SIGCHLD);
26	Signal(SIGCHLD, handler);
27	initjobsO	; /* Initialize the job list */
28
29	while (1)	{.
30	*	Sigprocmask(SIG_BL0CK, &mask_one, &prev_one);	/* Block SIGCHLD */
31	if ((pid = ForkO) == 0) { /* Child process	*/
32	Sigprocmask(SIG_SETMASK, &prev_one, NULL); /* Unblock SIGCHLD */
33	Execve("/bin/date", argv, NULL);
34	>
35	Sigprocinask(SIG_BL〇CK, ftmas^all, NULL); /* Parent process */
36	addjob(pid);	/* Add tlie	child to the job list	*/
37	Sigprocmask(SIG_SETMASK,	&prev_one, NULL); /*	Unblock	SIGCHLD */
38	>
39	exit(0);
40	>
code/ecf/procmask2. c
图8*40用sigprocmask来同步进程。在这个例子中，父进程保证在相应的deletejob之前执行addjob
8.5.7显式地等待信号
有时候主程序需要显式地等待某个信号处理程序运行。例如，当Linux shell创建一个前 台作业时，在接收下一条用户命令之前，它必须等待作业终止，被SIGCHLD处理程序回收。 图8-41给出了一个基本的思路。父进程设置SIGINT和SIGCHLD的处理程序，然后
544	第二部分在系统上运行程序
进人一个无限循环。它阻塞SIGCHLD信号，避免8. 5. 6节中讨论过的父进程和子进程之 间的竞争。创建了子进程之后，把pid重置为〇,取消阻塞SIGCHLD，然后以循环的方 式等待pid变为非零。子进程终止后，处理程序回收它，把它非零的P1D赋值给全局pid 变量。这会终止循环，父进程继续其他的工作，然后开始下一次迭代。
1	#include "csapp.h"
code/ecf/waitforsignaic
3 volatile sig_atomic_t pid;
5
10
12
13
14
15
16
17
18
19
20
22
23
24
25
26
27
28
29
30
32
35
36
37
38
39
40
42
void sigctLld_handler(int s)
int olderrno = errno; pid = waitpid(-l, NULL, 0); errno = olderrno;
void sigint_handler(int s)
int main(int argc, char **argv)
sigset.t mask, prev;
Signal (SIGCHLD, sigchld_liandler);
Signal(SIGINT, sigint_handler);
Sigeinptyset(&mask);
Sigaddset(&mask, SIGCHLD);
while (1) {
Sigprocmask(SIG_BLDCK, femask, &prev); /* Block SIGCHLD */ if (ForkO == 0) /* Child */ exit(0);
/* Parent */ pid = 0;
Sigprocmask(SIG_SETMASK, &prev, NULL); /* Unblock SIGCHLD */
/* Wait for SIGCHLD to be received (wasteful) */ while (!pid)
/* Do some work after receiving SIGCHLD */ printfC'.");
>
exit(0);
code/ecf/waitforsignaic
图8-11用循环来等待信号。这段代码正确，但循环是一种浪费
第8章异常控制流 545
当这段代码正确执行的时候，循环在浪费处理器资源。我们可能会想要修补这个问 题，在循环体内插人pause:
while (!pid) /* Race! */ pause 0 ;
注意，我们仍然需要一个循环，因为收到一个或多个SIGINT信号，pause会被中 断。不过，这段代码有很严重的竞争条件：如果在while测试后和pause之前收到 SIGCHLD信号，pause会永远睡眠。
另一个选择是用sleep替换pause:
while (!pid) /* Too slow! */ sleep(l);
当这段代码正确执行时，它太慢了。如果在while之后pause之前收到信号，程序 必须等相当长的一段时间才会再次检查循环的终止条件。使用像nanosleep这样更高精 度的休眠函数也是不可接受的，因为没有很好的方法来确定休眠的间隔。间隔太小，循环 会太浪费。间隔太大，程序又会太慢。
合适的解决方法是使用sigsuspend。
#include <signal.li>
int sigsuspend(const sigset_t *mask);
返回：一1。
sigsuspend函数暂时用mask替换当前的阻塞集合，然后挂起该进程，直到收到一 个信号，其行为要么是运行一个处理程序，要么是终止该进程。如果它的行为是终止，那 么该进程不从sigsuspend返回就直接终止。如果它的行为是运行一个处理程序，那么 sigsuspend从处理程序返回，恢复调用sigsuspend时原有的阻塞集合。
Sigsuspend函数等价于下述代码的原子的（不可中断的）版本：
1	sigprocmask(SIG.SETMASK,	&mask,	&prev);
2	pause ();
3	sigprocmask(SIG_SETMASK,	&prev,	NULL);
原子属性保证对sigprocmask(第1行）和pause(第2行）的调用总是一起发生的，不会被 中断。这样就消除了潜在的竞争，即在调用sigprocmask之后但在调用pause之前收到 了一个信号。
图8-42展75了如何使用sigsuspend来替代图8-41中的循环。在每次调用sigsuspend 之前，都要阻塞 SIGCHLD。 sigsuspend 会暂时取消阻塞 SIGCHLD， 然后休眠， 直到父进程捕获信号。在返回之前，它会恢复原始的阻塞集合，又再次阻塞SIGCHLD。 如果父进程捕获一个SIGIN丁信号，那么循环测试成功，下一次迭代又再次调用sigsus-perxl。如果父进程捕获一个SIGCHLD，那么循环测试失败，会退出循环。此时， SIGCHLD是被阻塞的，所以我们可以可选地取消阻塞SIGCHLD。在真实的有后台作业 需要回收的shell中这样做可能会有用处。
sigsuspend版本比起原来的循环版本不那么浪费，避免了引入pause带来的竞争， 又比sleep更有效率。
546 第二部分在系统上运行程序
1	#include "csapp.h"
2
3	volatile sig_atomic_t pid;
4
5	void sigchld_handler(int s)
6	{
7	int olderrno = errno;
8	pid = Waitpid(-1, NULL,	0);
9	errno = olderrno; i〇 >
code/ecf/sigsuspend. c
12	void sigint_h«indler (int s)
13	{
14	>
15
16	int main(int argc, char **argv)
17	{
18	sigset_t mask, prev;
19
20	Signal(SIGCHLD, sigchld_handler);
21	Signal(SIGINT, sigint_handler);
22	Sigemptyset(&mask);
23	Sigaddset(&mask,	SIGCHLD);
24
25	while (1)	{
26	Sigprocmask(SIG_BLOCK,	femask, &prev); /* Block SIGCHLD */
27	if (Fork() == 0) /* Child */
28	exit(0);
29
30	/* Wait for SIGCHLD to be received */
31	pid = 0;
32	while (!pid)
33	sigsuspend(&prev);
34
35	/* Optionally unblock SIGCHLD */
36	Sigprocmask(SIG_SETMASK, &prev, NULL);
37
38	/* Do some work after receiving SIGCHLD */
39	printf(".;
40	>
41	exit CO);
42	>
code/ecf/sigsuspend. c
图8_42 用sigsuspend来等待信号
8.	6非本地跳转
C语言提供了一种用户级异常控制流形式，称为非本地跳转（nonlocal jump),它将控 制直接从一个函数转移到另一个当前正在执行的函数，而不需要经过正常的调用-返回序
第8章异常控制流	547
列。非本地跳转是通过setjmp和longjmp函数来提供的。
#include <setjmp.h> int setjrap(jmp_buf env);
int sigsetjmp(sigjmp_buf env, int savesigs);
返回：setjmp返回0，longjmp返回非零。
setjmp函数在env缓冲区中保存当前调用环境，以供后面的l〇ngjmp使用，并返回 〇。调用环境包括程序计数器、栈指针和通用目的寄存器。出于某种超出本书描述范围的 原因，setjmp返回的值不能被赋值给变量： rc = setjmp(env);	/木 Wrong! */
不过它可以安全地用在switch或条件语句的测试中[62]。
#include <setjmp.ti>	
void longjmp(jnip_buf env, int retval); void siglongjmp(sigjmp_buf env, int retval);	从不返回。
longjmp函数从env缓冲E中恢复调用环境，然后触发一个从最近一次初始化env 的setjmp调用的返回。然后setjmp返回，并带有非零的返回值retval。
第一眼看过去，setjmp和longjmp之间的相互关系令人迷惑。setjmp函数只被调 用一次，但返回多次：一次是当第一次调用setjmp，而调用环境保存在缓冲区env中时， 一次是为每个相应的longjmp调用。另一方面，longjmp函数被调用一次，但从不返回。
非本地跳转的一个重要应用就是允许从一个深层嵌套的函数调用中立即返回，通常是 由检测到某个错误情况引起的。如果在一个深层嵌套的函数调用中发现了一个错误情况， 我们•可以使用非本地跳转直接返回到一个普通的本地化的错误处理程序，而不是费力地解 开调用栈。
图8-43展示了一个示例，说明这可能是如何工作的。main函数首先调用setjmp以 保存当前的调用环境，然后调用函数f〇o, foo依次调用函数bar。如果fo◦或者bar遇 到一个错误，它们立即通过一次longjmp调用从setjmp返回。set jmp的非零返回值指 明了错误类型，随后可以被解码，且在代码中的某个位置进行处理。
-----------------------------------------------------------------code/ecf/setjmp. c
1	#include "csapp.h"
2
3 jmp-tmf buf;
5	int errorl = 0;
6	int error2 = 1;
7
8	void foo(void), bar(void);
9
图8_43非本地跳转的示例。本示例表明了使用非本地跳转来从深层嵌套的 函数调用中的错误情况恢复，而不需要解开整个栈的基本框架
548 第二部分在系统上运行程序
10
11
15
16
18
19
20 21 22
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
int main()
{
switch(setjmp(buf)) { case 0: f〇〇(); break; case 1:
printf("Detected an error1 condition in foo\n"); break; case 2:
printf("Detected an error2 condition in foo\n"); break; default:
printf("Unknown error condition in foo\n");
>
exit(0);
>
/* Deeply nested function foo */ void fooCvoid)
if (errorl)
longjmp(buf, 1); bax();
>
void bar(void)
■C
if (error2)
longjmp(buf, 2);
code/ecf/setjmp. c
m 8-.i3	(续）
longjmp允许它跳过所有中间调用的特性可能产生意外的后果。例如，如果中间函数 调用中分配了某些数据结构，本来预期在函数结尾处释放它们，那么这些释放代码会被跳 过，因而会产生内存泄漏。
非本地跳转的另一个重要应用是使一个信号处理程序分支到一个特殊的代码位置，而不 是返回到被信号到达中断了的指令的位置。图8-44展示了一个简单的程序，说明了这种基本 技术。当用户在键盘上键人Ctrl+C时，这个程序用信号和非本地跳转来实现软重启。5ig-setjmp和siglongjmp函数是setjmp和longjmp的可以被信号处理程序使用的版本。
在程序第一次启动时，对sigsetjmp函数的初始调用保存调用环境和信号的上下文 (包括待处理的和被阻塞的信号向量）。随后，主函数进人一个无限处理循环。当用户键人 Ctrl + C时，内核发送一个SIGINT信号给这个进程，该进程捕获这个信号。不是从信号 处理程序返回，如果是这样那么信号处理程序会将控制返回给被中断的处理循环，反之， 处理程序完成一个非本地跳转，回到main函数的开始处。当我们在系统上运行这个程序 时，得到以下输出：
第8章异常控制流	549
linux> ./restart starting processing... processing...
Ctrl+C restarting processing...
Ctrl+C restarting processing...
关于这个程序有两件很有趣的事情。首先，为了避免竞争，必须在调用了 sigsetjmp之 后再设置处理程序。否则，就会冒在初始调用sigsetjmp为siglongjmp设置调用环境之前 运行处理程序的风险。其次，你可能已经注意到了，sigsetjmp和siglongjmp函数不在图
8-33中异步信号安全的函数之列。原因是一般来说siglongjmp可以跳到任意代码，所以我 们必须小心，只在siglongjmp可达的代码中调用安全的函数。在本例中，我们调用安全的 si〇_puts和sleep函数。不安全的exit函数是不可达的。
—--------------------------------------code/ecf/restart. c
#include "csapp.h"
sigjmp_buf buf;
void handler(int sig)
siglongjmp(buf, 1);
int main()
{
if (!sigsetjmp(buf, 1)) {
Signal(SIGIMT, handler);
Sio_puts("starting\n");
>
else
Sio_puts("restarting\n");
while(l) {
Sleep ⑴；
Sio_puts("processing…\n");
}
exit(O); /* Control never reaches here */
>
-----------------------------------------------code/ecf/restart. c
图S-44当用户键人Ctrl+C时，使用非本地跳转来重启动它自身的程序
1
2
3
4
5
6
7
8 9
10
11
12
13
14
15
16
17
18
19
20 21 22
23
24
旁注
C++和Java中的软件异常
C++和Java提供的异常机制是较高层次的，是C语言的set jmp和longjmp函数 的更加结构化的版本。你可以把try语句中的catch子句看做类似于setjmp函数。相 似地，throw语句就类似于longjmp函数。
550 第二部分在系统上运行程序
8.7操作进程的工具
Linux系统提供了大量的监控和操作进程的有用工具。
STRACE:打印一个正在运行的程序和它的子进程调用的每个系统调用的轨迹。对于 好奇的学生而言，这是一个令人着迷的工具。用-static编译你的程序，能得到一个更干 净的、不带有大量与共享库相关的输出的轨迹。
PS:列出当前系统中的进程（包括僵死进程）■=
TOP:打印出关于当前进程资源使用的信息。
PMAP:显示进程的内存映射。
/proc: —个虚拟文件系统，以ASCII文本格式输出大量内核数据结构的内容，用户 程序可以读取这些内容。比如，输入“cat/proc/loadavg”，可以看到你的Linux系统上 当前的平均负载。
8.	8 小结
异常控制流（ECF)发生在计算机系统的各个层次，是计算机系统中提供并发的基本机制。
在硬件层，异常是由处理器中的事件触发的控制流中的突变。控制流传递给一个软件处理程序，该 处理程序进行一些处理，然后返回控制给被中断的控制流。
有四种不同类型的异常：中断、故障、终止和陷阱。当一个外部I/O设备（例如定时器芯片或者磁盘 控制器）设置了处理器芯片上的中断管脚时，（对于任意指令）中断会异步地发生^控制返回到故障指令后 面的那条指令。一条指令的执行可能导致故障和终止同步发生。故障处理程序会重新启动故障指令，而 终止处理程序从不将控制返回给被中断的流。最后，陷阱就像是用来实现向应用提供到操作系统代码的 受控的人口点的系统调用的函数调用。
在操作系统层，内核用ECF提供进程的基本概念。进程提供给应用两个重要的抽象：1)逻辑控制 流，它提供给每个程序一个假象，好像它是在独占地使用处理器，2)私有地址空间，它提供给每个程序 一个假象，好像它是在独占地使用主存。
在操作系统和应用程序之间的接口处，应用程序可以创建子进程，等待它们的子进程停止或者终止， 运行新的程序，以及捕获来自其他进程的信号。信号处理的语义是微妙的，并且随系统不同而不同。然 而，在与Pasix兼容的系统上存在着一些机制，允许程序清楚地指定期望的信号处理语义。
最后，在应用层，C程序可以使用非本地跳转来规避正常的调用/返回栈规则，并且直接从一个函数 分支到另一个函数。
参考文献说明
Keirisk是Linux环境编程的完全参考手册[62]。Intel ISA规范包含对Intel处理器上的异常和中断 的详细讨论[50]。操作系统教科书[102，106, 113]包括关于异常、进程和信号的其他信息^ W.Rlchard Stevens的[111]是一本有价值的和可读性很高的经典著作，是关于如何在应用程序中处理进程和信号的。 Bovet和CeSati[ll]给出了一个关于Linux内核的非常清晰的描述，包括进程和信号实现的细节。
家庭作业
*8.9考虑四个具有如下开始和结束时间的进程：
进程	开始时间	结束时间
A	5	7
B	2	4
C	3	6
D	1	8
第8章异常控制流 551
对于每对进程，指明它们是否是并发地运行的：
进程对	并发地？
AB	
AC	
AD	
BC	
BD	
CD	
*8. 10在这一章里，我们介绍了一些具有不寻常的调用和返回行为的函数：setjmp、longjmp、execve 和fork。找到下列行为中和每个函数相匹配的一种：
A.	调用一次，返回两次。
B.	调用一次，从不返回a
C.	调用一次，返回一次或者多次。
• 8. 11这个程序会输出多少个“hello”输出行？
#include "csapp.h"
code/ecf/forkprobl. c
int mainO int i;
for (i = 0; i < 2; i++) ForkC);
printf("hello\n"); exit(O);
code/ecf/forkprobl .c
*8. 12这个程序会输出多少个“hello”输出行？
code/ecf/forkprob4.c
#include "csapp.h." void doit ()
■C
ForkO ;
ForkO ;
printf("hello\n");
int main()
doitO ;
printf("hello\n"); exit(0); * *
code/ecf/forkprob4.c
*8. 13下面程序的一种可能的输出是什么？
--------------------------------------code/ecf/forkprob3.c
#include "csapp.h" int mainO
552 第二部分在系统上运行程序
5	int x = 3;
6
7	if CForkO	!=	0)
8	printf("x=%d\n", ++x);
9
10	printf("x=%d\n",	—x);
11	exit(0);
12	>
code/ecf/forkprob3. c
*8. 14下面这个程序会输出多少个“hello”输出行？
code/ecf/forkprob5.c
1	#include "csapp.h"
2
3	void doit ()
4	{
5	if (ForlcO	«	0)	{
6	Fork();
7	printf("hello\n");
8	exit(0);
9	}
10	return;
11	>
12
13	int main()
14	i
15	doit();
16	printf("hello\n");
17	exit(0);
18	>
code/ecf/forkprob5. c
*8. 15下面这个程序会输出多少个“hello”输出行？
-------------------------------------------------code/ecf/forkprob6. c
1	#include "csapp.h"
2
3	void doit ()
4	i
5	if CForkO	==	0)	{
6	ForkO;
7	printf C"hello\n");
8	return;
9	>
io	return;
n >
12
13	int main()
14	{
15	doit();
16	printf("helloVn");
17	exit(0);
18	> •
• 8. 16下面这个程序的输出是什么？
code/ecf/forkprob6.c
第8章异常控制流 553
1	#include "csapp.h"
2	int counter = 1；
code/ecf/forkprob7.c
4	int main〇
5	{
6	if (fork〇 == 0) {
7	counter—;
8	exit(0);
9	>
10	else {
n	Wait(NULL);
12	printf("counter » %d\n", ++counter);
13	}
14	exit(0);
15	>
---------------------------------------------------------code/ecf/forkprob7. c
*8.〗7列举练习题8. 4中程序所有可能的输出。 »8. 18考虑下面的程序：
code/ecf/forkp rob2. c
1	#include "csapp.h"	
2		
3	void end(void)	
5	printf("2"); fflush(stdout);	
6	>	
7		
8	int main〇	
9	{	
10	if (ForkO -= 0)	
11	atexit(end);	
12	if (ForkO == 0)	
13	printf ;	fflush(stdout);
14	>	
15	else {	
16	printf("1");	fflush(stdout);
17	>	
18	exit(0);	
19	>	
code/ecf/forkprob2.c
判断下面哪个输出是可能的^注意：atexit函数以一个指向函数的指针为输入， 到函数列表中（初始为空），当exit函数被调用时，会调用该列表中的函数。
A. 112002	B. 211020	C. 102120	D. 122001
8. 19下面的函数会打印多少行输出？用一个7!的函数给出答案。假设/<>1。
code/ecf/forkprob8. c
1	void foo(int n)
2	{
3	int i;
4
5	for (i = 0; i < n; i++)
6	ForkO;
7	printf("hello\n");
8	exit(0);
9	>
并将它添加 E. 100212
code/ecf/forkprob8.c
554	第二部分在系统上运行程序
**8.20使用execve编写一个叫做myls的程序，该程序的行为和/bin/ls程序的一样。你的程序应该接 受相同的命令行参数，解释同样的环境变量，并产生相同的输出。
Is程序从COLUMNS环境变量中获得屏幕的宽度。如果没有设置COLUMNS,那么Is会假 设屏幕宽80列。因此，你可以通过把COLUMNS环境设置得小于80,来检查你对环境变量的 处理：
linux> setenv COLUMNS 40 linux> ./myls
// Output is 40 columns wide
lin\ix> unsetenv COLUMNS linux> ./myls
// Output is now 80 columns wide -8.21下面的程序可能的输出序列是什么？
----------------------------------------------------------code/ecf/waitprob3.c
1	int main()
2	{
3	if CforkO == 0) {
4	printf("a");	fflush(stdout);
5	exit(0);
6	>
7	else {
8	printf("b");	fflush(stdout);
9	waitpid(-l,	NULL, 0);
10	>
n	printf("c"); fflush(stdout);
12	exit(0);
code/ecf/waitprob3. c
*/8. 22编写Unix system函数的你自己的版本
int mysystem(char ^command);
** 8. 23
mysystem函数通过调用“/bin/sh-c command”来执行command，然后在command完成后返回。 如果command(通过调用exit函数或者执行一条return语句）正常退出，那么mysystem返回 command退出状态。例如，如果command通过调用exit(8)终止，那么mysystem返回值8。否 则，如果command是异常终止的，那么mysystem就返回shell返回的状态。
你的一个同事想要使用信号来让一个父进程对发生在子进程中的事件计数。其想法是每次发生一 个事件时，通过向父进程发送一个信号来通知它，并且让父进程的信号处理程序对一个全局变量 counter加一，在子进程终止之后，父进程就可以检查这个变量。然而，当他在系统上运行图8-45中的测试程序时，发现当父进程调用printf时，counter的值总是2，即使子进程向父进程发 送了 5个信号也是如此。他很困惑，向你寻求帮助^你能解释这个程序有什么错误吗？
1	#include "csapp.h"
2
3	int counter = 0;
code/ecf/counterprob.c
5	void handler(int sig)
6	{
7	counter—;
8	sleep(l); /* Do some work in the handler */
9	return;
丨冬 1 8-45家庭作业8. 23中引用的计数器程序
第8章异常控制流 555
12	int main()
13	{
14	int i;
16
20
22
23
24
Signal(SIGUSR2, handler);
if (Fork() == 0) {	/* Child */
for (i = 0; i < 5; i++) {
KillCgetppidO , SIGUSE2); printf("sent SIGUSR2 to parent\n");
>
exit(0);
>
26	Wait(NULL);
27	printf("counter=%d\nM, counter);
28	exit(0);
29	>
code/ecf/counterprob.c
阍8-45	(续）
78.24修改图8-18中的程序，以满足下面两个条件：
1)	每个子进程在试图写一个只读文本段中的位置时会异常终止。
2)	父进程打印和下面所示相同（除了 PID)的输出：
child 12255 terminated by signal 11: Segmentation fault child 12254 terminated by signal 11: Segmentation fault
提示：请参考psignal (3)的man页。
? 8. 25编写fgets函数的一个版本，叫做tfgets，它5秒钟后会超时。tfgets函数接收和fgets相同 的输人。如果用户在5秒内不键人一个输人行，tfgets返回NULL。否则，它返回一个指向输人 .行的指针。
8. 26以图8-23中的示例作为开始点，编写一个支持作业控制的shell程序。shell必须具有以下特性：
*用户输人的命令行由一个name、零个或者多个参数组成，它们都由一个或者多个空格分隔开。 如果name是一个内置命令，那么shell就立即处理它，并等待下一个命令行。否则，shell就假 设name是一个可执行文件，在一个初始的子进程(作业）的上下文中加载并运行它。作业的进程 组ID与子进程的P1D相同。
*每个作业是由一个进程KXPID)或者一个作业ID(JK))来标识的，它是由一个shell分配的任意的 小正整数。JID在命令行上用前缀“%”来表示。比如，“％5”表示JID5,而“5”表示HD5。
鲁如果命令行以&来结束，那么shel丨就在后台运行这个作业。否则，shell就在前台运行这个作业。 •输人Ctrl+C(Ctrl + Z)，使得内核发送一个SIGINT(SIGTSTP)信号给shell, shell再转发给前 台进程组中的每个进程0 ■内置命令jobs列出所有的后台作业。
*内置命令bg)〇6通过发送一个SIGCONT信号重启j〇6,然后在后台运行它D 必参数可以是一 个PID，也可以是一个JIA
•内置命令fg)〇6通过发送一个SIGCONT信号重启）然后在前台运行它^
㊀注意这是对真实的shell工作方式的简化。真实的shell里，内核响应CtH+C(Ctrl+Z),把SIGINT(SIGT-STP)直接发送给终端前台进程组中的每个进程。shell用tcsetpgrp函数管理这个进程组的成员，用tc-setattr函数管理终端的属性，这两个函数都超出了本书讲述的范围。可以参考[62]获得详细信息。
556 第二部分在系统上运行程序
籲shell回收它所有的僵死子进程。如果任何作业因为收到一个未捕获的信号而终止，那么shell就 输出一条消息到终端，消息中包含该作业的PID和对该信号的描述。
图8-46展示了一个shell会话示例。
linux> ./shell		Run your shell program
>bogus		
bogus: Command not foimd.		Execve can't find executable
>foo 10 Job 5035 terminated by signal:	Interrupt	User types Ctrl+C
>foo 100 & [1]	5036 foo 100 & >f〇o 200 & [2]	5037 foo 200 & >jobs [1]	5036 Running foo 100 k [2]	5037 Running foo 200 & >fg XI Job [1] 5036 stopped by signal	Stopped	User types Ctrl+Z
>jobs [1]	5036 Stopped foo 100 & [2]	5037 Running foo 200 & >bg 5035 5035: No such process >bg 5036 [1] 5036 foo 100 & >/bin/kill 5036 Job 5036 terminated by signal:	Terminated	
> fg 12		Wait for fg job to finish
>quit linux>		Back to the Unix shell
图8-46 家庭作业8. 26的shell会话示例
练习题答案
8. 1进程A和B是互相并发的，就像B和C一样，因为它们各自的执行是重叠的，也就是一个进程在 另一个进程结束前开始。进程A和C不是并发的，因为它们的执行没有重叠；A在C开始之前就 结束了。
8. 2在图8-15的示例程序中，父子进程执行无关的指令集合。然而，在这个程序中，父子进程执行的 指令集合是相关的，这是有可能的，因为父子进程有相同的代码段。这会是一个概念上的障碍，所 以请确认你理解了本题的答案。图8-47给出了进程图。
A.	这里的关键点是子进程执行了两个printf语句。在fork返回之后，它执行第6行的printf。 然后它从if语句中出来，执行第7行的printf语句。下面是子进程产生的输出：
pi: x=2 p2: x=l
B.	父进程只执行第7行的printf:
p2: x=0
PI: x=2 P2: x=l
	printf printf ex]
x==l	P2: x=0
main fork printf exit
子进程
父进程
图8-47练习题8. 2的进程图
第8章异常控制流	557
8.3我们知道序列acbc、abcc和bacc是可能的，因为它们对应有进程图的拓扑排序（图8-48)。而像 bcac和cbca这样的序列不对应有任何拓扑排序，因此它们是不可行的^
main
fork
printf
b
printf
print f
c
waitpid printf
exit:
图8-48 练习题8. 3的进程图
8.4 A.只简单地计算进程图（图8-49)中printf顶点的个数就能确定输出行数。在这里，有6个这样的 顶点，因此程序会打印6行输出。
B.任何对应有进程图的拓扑排序的输出序列都是可能的。例如：Hello、1、0、Bye、2、Bye是可 能的。
	printf	printf	exit(2)	
Hello	0		1	Bye
main printf fork printf	waitpid printf printf exit
阁8-19练习题8. 4的进程图
8. 5
6
unsigned int snooze(unsigned int secs) { unsigned int rc = sleep(secs);
一 code/ecf/snooze. c
printf("Slept for %d of %d secs.\n", secs-rc, secs); return rc;
-------------------------------------------------------------code/ecf/snooze.c
8. 6----------------------------------------------------------------code/ecf/myecho.c
1	#include "csapp.h"
2
*3 int main (int argc, ch«ir *argv[], char *envp[])
4	i
5	int i;
6
7	printf("Command-line arguments:\n");
8	for (i=0; argvti]	!®	NULL;	i++)
9	printf ("	argv[7,2d]: y,s\n", i, argv[i]);
10
11	printf("\n");
12	printf("Environment variables:\n");
13	for Ci=0; envp[i]	!=	NULL;	i++)
14	printf("	envp[yt2d]: %s\n", i, envp[i]);
15
16	exit(0);
1? >
-------------------------------------------------------------code/ecf/myecho.c
8.7只要休眠进程收到一个未被忽略的信号，sleep函数就会提前返回。但是，因为收到一个SIGINT 信号的默认行为就是终止进程（图8-26)，我们必须设置一个SIGINT处理程序来允许sleep函数返 回。处理程序简单地捕获SIGNAL,并将控制返回给sleep函数，该函数会立即返回。
-----------------------------------code/ecf/snooze. c
1 #include "csapp-h*'
558 第二部分在系统上运行程序
3	/* SIGINT handler */
4	void handler(int sig)
5	{
6	return; /* Catch the signal and return */
7	y
8
9	unsigned int snooze(unsigned int secs) { i〇	unsigned int rc = sleep(secs);
11
12	printf("Slept for %d of %d secs.\nH, secs-rc, secs);
13	return rc;
14	}
15
16	int main(int axgc, char **argv) {
17
18	if (argc != 2) {
19	fprintf(stderr, "usage: %s <secs>\n", argv[〇3);
20	exit(0);
21	>
22
23	if (signal(SIGINT, handler) == SIG_ERR) /* Install SIGINT */
24	unix_error("signal error\nM);	/* handler	*/
25	(void)snooze(atoi(argv[1]));	.
26	exit(0);
27	>
-------------------------------------------------code/ecf/snooze. c
8.8这个程序打印字符串“213”，这是卡内基-梅隆大学CS: APP课程的缩写名。父进程开始时打印 “2”，然后创建子进程，子进程会陷人一个无限循环。然后父进程向子进程发送一个信号，并等待 它终止。子进程捕获这个信号（中断这个无限循环），对计数器值（从初始值2)减一，打印“1”，然 后终止。在父进程回收子进程之后，它对计数器值(从初始值2)加一，打印“3”，并且终止。
第9章
虚拟内存
一个系统中的进程是与其他进程共享CPU和主存资源的。然而，共享主存会形成一 些特殊的挑战。随着对CPU需求的增长，进程以某种合理的平滑方式慢了下来。但是如 果太多的进程需要太多的内存，那么它们中的一些就根本无法运行。当一个程序没有空间 可用时，那就是它运气不好了。内存还很容易被破坏。如果某个进程不小心写了另一个进 程使用的内存，它就可能以某种完全和程序逻辑无关的令人迷惑的方式失败。
为了更加有效地管理内存并且少出错，现代系统提供了一种对主存的抽象概念，叫做 虚拟内存（VM)。虚拟内存是硬件异常、硬件地址翻译、主存、磁盘文件和内核软件的完 美交互，它为每个进程提供了一个大的、一致的和私有的地址空间。通过一个很清晰的机 制，虚拟内存提供了三个重要的能力：1)它将主存看成是一个存储在磁盘上的地址空间的 高速缓存，在主存中只保存活动区域，并根据需要在磁盘和主存之间来回传送数据，通过 这种方式，它高效地使用了主存。2)它为每个进程提供了一致的地址空间，从而简化了内 存管理。3)它保护了每个进程的地址空间不被其他进程破坏。
虚拟内存是计算机系统最重要的概念之一。它成功的一个主要原因就是因为它是沉默 地、自动地工作的，不需要应用程序员的任何干涉。既然虚拟内存在幕后工作得如此之 好，为什么程序员还需要理解它呢？有以下几个原因：
•虚拟内存是核心的。虚拟内存遍及计算机系统的所有层面，在硬件异常、汇编器、 链接器、加载器、共享对象、文件和进程的设计中扮演着重要角色。理解虚拟内存 将帮助你更好地理解系统通常是如何工作的。
•«虚拟内存是强大的。虚拟内存给予应用程序强大的能力，可以创建和销毁内存片 (chunk)、将内存片映射到磁盘文件的某个部分，以及与其他进程共享内存。比如， 你知道可以通过读写内存位置读或者修改一个磁盘文件的内容吗？或者可以加载一 个文件的内容到内存中，而不需要进行任何显式地复制吗？理解虚拟内存将帮助你 利用它的强大功能在应用程序中添加动力。
*虚拟内存是危险的。每次应用程序引用一个变量、间接引用一个指针，或者调用一个 诸如malloc这样的动态分配程序时，它就会和虚拟内存发生交互。如果虚拟内存使 用不当，应用将遇到复杂危险的与内存有关的错误。例如，一个带有错误指针的程序 可以立即崩溃于“段错误”或者“保护错误”，它可能在崩溃之前还默默地运行了几 个小时，或者是最令人惊慌地，运行完成却产生不正确的结果。理解虚拟内存以及诸 如malloc之类的管理虚拟内存的分配程序，可以帮助你避免这些错误。
这一章从两个角度来看虚拟内存。本章的前一部分描述虚拟内存是如何工作的。后一 部分描述的是应用程序如何使用和管理虚拟内存。无可避免的事实是虚拟内存很复杂，本 章很多地方都反映了这一点。好消息就是如果你掌握这些细节，你就能够手工模拟一个小 系统的虚拟内存机制，而且虚拟内存的概念将永远不再神秘。
第二部分是建立在这种理解之上的，向你展示了如何在程序中使用和管理虚拟内存。 你将学会如何通过显式的内存映射和对像malloc程序这样的动态内存分配器的调用来管
560 第二部分在系统上运行程序
理虚拟内存。你还将了解到C程序中的大多数常见的与内存有关的错误，并学会如何避免 它们的出现。
9.	1物理和虚拟寻址
计算机系统的主存被组织成一个由M个连续的字节大小的单元组成的数组。每字节 都有一个唯一的物理地址（Physical Address，	主存
PA)。第一个字节的地址为0,接下来的字节地址 为1，再下一个为2,依此类推。给定这种简单的 结构，CPU访问内存的最自然的方式就是使用物 理地址。我们把这种方式称为物理寻址（physical addressing)。图9-1展示了一个物理寻址的示例，
该示例的上下文是一条加载指令，它读取从物理 地址4处开始的4字节字。当CPU执行这条加载 指令时，会生成一个有效物理地址，通过内存总 线，把它传递给主存。主存取出从物理地址4处 开始的4字节字，并将它返回给CPU，CPU会将 它存放在一个寄存器里。
早期的PC使用物理寻址，而且诸如数字信号处理器、嵌人式微控制器以及Cray超级 计算机这样的系统仍然继续使用这种寻址方式。然而，现代处理器使用的是一种称为虚拟 寻址（virtual addressing)的寻址形式，参见图9-2。
m 9-1
数据字
■*个使用物理寻址的系“
数据字
丨冬 1 9-2	—个使用虚拟寻址的系统
使用虚拟寻址，CPU通过生成一个虚拟地址（Virtual Address，VA)来访问主存，这 个虚拟地址在被送到内存之前先转换成适当的物理地址。将一个虚拟地址转换为物理地址 的任务叫做地址翻译（address translation)。就像异常处理一样，地址翻译需要CPU硬件 和操作系统之间的紧密合作。CPU芯片上叫做内存管理单元（Memory Management Unit, MMU)的专用硬件，利用存放在主存中的查询表来动态翻译虚拟地址，该表的内容由操作 系统管理。
9.	2 地址空间
地址空间（address space)是一个非负整数地址的有序集合:
第9章虚拟内存 561
{〇，1，2，一}
如果地址空间中的整数是连续的，那么我们说它是一个线性地址空间（linear address space)。为了简化讨论，我们总是假设使用的是线性地址空间。在一个带虚拟内存的系统 中，CPU从一个有iV = 2”个地址的地址空间中生成虚拟地址，这个地址空间称为虚拟地 址空间（virtual address space):
{0，1，2,…，N — l}
一个地址空间的大小是由表示最大地址所需要的位数来描述的。例如，一个包含N= 2”个地址的虚拟地址空间就叫做一个《位地址空间。现代系统通常支持32位或者64位虚 拟地址空间。
一个系统还有一个物理地址空间（physical address space)，对应于系统中物理内存的 M个字节：
{0，1，2,…，M-1}
M不要求是2的幂，但是为了简化讨论，我们假设2'
地址空间的概念是很重要的，因为它清楚地区分了数据对象（字节）和它们的属性（地 址）。一旦认识到了这种区别，那么我们就可以将其推广，允许每个数据对象有多个独立 的地址，其中每个地址都选自一个不同的地址空间。这就是虚拟内存的基本思想。主存中 的每字节都有一个选自虚拟地址空间的虚拟地址和一个选自物理地址空间的物理地址。
2¾练习题9.1完成下面的表格，填写缺失的条目，并且用适当的整数取代每个问号。 利用下列单位：K = 21Q(kil〇，千），M = 2£°(mega，兆，百万），G = 23°(giga，千兆， 十亿），T=24Q(tera，万亿），P=25°(peta，千千兆），或 E = 2s°(exa，千兆兆）。
虚拟地址位数（n)	虚拟地址数（AO	最大可能的虚拟地址
8		
	2? = 64K	
		232 - 1 = ?G- 1
	2? = 256T	
64		
9.3虚拟内存作为缓存的工具
概念上而言，虚拟内存被组织为一个由存放在磁盘上的N个连续的字节大小的单元 组成的数组。每字节都有一个唯一的虚拟地址，作为到数组的索引。磁盘上数组的内容被 缓存在主存中。和存储器层次结构中其他缓存一样，磁盘（较低层）上的数据被分割成块， 这些块作为磁盘和主存(较高层）之间的传输单元。VM系统通过将虚拟内存分割为称为虚 拟页（Virtual Page，VP)的大小固定的块来处理这个问题。每个虚拟页的大小为字 节。类似地，物理内存被分割为物理页（Physical Page, PP),大小也为尸字节（物理页也 被称为页帧（page frame))。
在任意时刻，虚拟页面的集合都分为三个不相交的子集：
*未分配的：VM系统还未分配(或者创建）的页^未分配的块没有任何数据和它们相 关联，因此也就不占用任何磁盘空间。
*缓存的：当前已缓存在物理内存中的已分配页。
*未缓存的：未缓存在物理内存中的已分配页。
图9-3的示例展示了一个有8个虚拟页的小虚拟内存。虚拟页0和3还没有被分配，
562 第二部分在系统上运行程序
因此在磁盘上还不存在。虚拟页1、4和6被缓存在物理内存中。页2、5和7已经被分配 了，但是当前并未缓存在主存中。
虚拟内存
物理内存
VPO
VP2"
-1
PP 0 pp 1
?P2m~p-
I
虚拟页（VP)	物理页（PP)
存储在磁盘上	缓存在DRAM中
m ：： 一个vm系统是如何使用主存作为缓存的
9.	3. 1 DRAM缓存的组织结构
为了有助于清晰理解存储层次结构中不同的缓存概念，我们将使用术语SRAM缓存 来表示位于CPU和主存之间的Ll、L2和L3高速缓存，并且用术语DRAM缓存来表示 虚拟内存系统的缓存，它在主存中缓存虚拟页。
在存储层次结构中，DRAM缓存的位置对它的组织结构有很大的影响。回想一下， DRAM比SRAM要慢大约10倍，而磁盘要比DRAM慢大约100 000多倍。因此， DRAM缓存中的不命中比起SRAM缓存中的不命中要昂贵得多，这是因为DRAM缓存 不命中要由磁盘来服务，而SRAM缓存不命中通常是由基于DRAM的主存来服务的。而 且，从磁盘的一个扇区读取第一个字节的时间开销比起读这个扇区中连续的字节要慢大约 100 000倍。归根到底，DRAM缓存的组织结构完全是由巨大的不命中开销驱动的。
因为大的不命中处罚和访问第一个字节的开销，虚拟页往往很大，通常是4KB〜 2MB。由于大的不命中处罚，DRAM缓存是全相联的，即任何虚拟页都可以放置在任何 的物理页中。不命中时的替换策略也很重要，因为替换错了虚拟页的处罚也非常之高。因 此，与硬件对SRAM缓存相比，操作系统对DRAM缓存使用了更复杂精密的替换算法。 (这些替换算法超出了我们的讨论范围）。最后，因为对磁盘的访问时间很长，DRAM缓 存总是使用写回，而不是直写。
9. 3. 2 页表
同任何缓存一样，虚拟内存系统必须有某种方法来判定一个虚拟页是否缓存在 DRAM中的某个地方。如果是，系统还必须确定这个虚拟页存放在哪个物理页中。如果 不命中，系统必须判断这个虚拟页存放在磁盘的哪个位置，在物理内存中选择一个牺牲 页，并将虚拟页从磁盘复制到DRAM中，替换这个牺牲页。
这些功能是由软硬件联合提供的，包括操作系统软件、MMU(内存管理单元）中的地 址翻译硬件和一个存放在物理内存中叫做责表（page table)的数据结构，页表将虚拟页映 射到物理页。每次地址翻译硬件将一个虚拟地址转换为物理地址时，都会读取页表。操作 系统负责维护页表的内容，以及在磁盘与DRAM之间来回传送页。
图9-4展示了一个页表的基本组织结构。页表就是一个页表条目（Page Table Entry， PTE)的数组。虚拟地址空间中的每个页在页表中一个固定偏移量处都有一个PTE。为了
第9章虚拟内存 563
我们的目的，我们将假设每个PTE是由一个有效位（valid bit)和一个rz位地址字段组成
的。有效位表明了该虚拟页当前是否被 缓存在DRAM中。如果设置了有效位， 那么地址字段就表示DRAM中相应的 物理页的起始位置，这个物理页中缓存 了该虚拟页。如果没有设置有效位，那 么一个空地址表示这个虚拟页还未被分 配。否则，这个地址就指向该虚拟页在 磁盘上的起始位置。
图9-4中的示例展示了一个有8个 虚拟页和4个物理页的系统的页表.四 个虚拟页（VP 1、VP 2、VP 4和VP 7)当前被缓存在DRAM中。两个页 (VPO和VP5)还未被分配，而剩下的
物理内存
页（VP 3和VP 6)已经被分配了，但是当前还未被缓存。图9-4中有一个要点要注意，因 为DRAM缓存是全相联的，所以任意物理页都可以包含任意虚拟页。
练习题9. 2确定下列虚拟地址大小U)和页大小（P)的组合所需要的PTE数量：
n	P = 2»	PTE数量
16	4K	
16	8K	
32	4K	
32	8K	
9.3.3 页命中
考虑一下当CPU想要读包含在VP 2中的虚拟内存的一个字时会发生什么（图9-5)，VP 2被缓存在DRAM中。使用我们将在9. 6节中详细描述的一种技术，地址翻译硬件将虚 拟地址作为一个索引来定位PTE 2,并从内存中读取它。因为设置了有效位，那么地址翻 译硬件就知道VP 2是缓存在内存中的了。所以它使用PTE中的物理内存地址（该地址指 向PP1中缓存页的起始位置），构造出这个字的物理地址。
物理内存
PPO
PP3
564 第二部分在系统上运行程序
9. 3. 4 缺页
在虚拟内存的习惯说法中，DRAM缓存不命中称为缺页（page fault)。图9-6展示了 在缺页之前我们的示例页表的状态。CPU引用了 VP 3中的一个字，VP 3并未缓存在 DRAM中。地址翻译硬件从内存中读取PTE 3,从有效位推断出VP 3未被缓存，并且触 发一个缺页异常。缺页异常调用内核中的缺页异常处理程序，该程序会选择一个牺牲页， 在此例中就是存放在PP 3中的VP 4。如果VP 4已经被修改了，那么内核就会将它复制 回磁盘。无论哪种情况，内核都会修改VP 4的页表条目，反映出VP 4不再缓存在主存中 这一事实。
物理内存
图9-6 VM缺页（之前）。对VP3中的字的引用会不命中，从而触发了缺页
接下来，内核从磁盘复制VP 3到内存中的PP 3,更新PTE 3,随后返回。当异常处 理程序返回时，它会重新启动导致缺页的指令，该指令会把导致缺页的虚拟地址重发送到 地址翻译硬件。但是现在，VP 3已经缓存在主存中了，那么页命中也能由地址翻译硬件 正常处理了。图9-7展示了在缺页之后我们的示例页表的状态。
物理内存
m 9-7 VM缺页(之后h缺页处理程序选择VP 4作为牺牲页，并从磁盘上用VP 3的副本取代它。在缺页 处理程序重新启动导致缺页的指令之后，该指令将从内存中正常地读取字，而不会再产生异常
第9章虚拟内存 565
虚拟内存是在20世纪60年代早期发明的，远在CPU-内存之间差距的加大引发产生 SRAM缓存之前。因此，虚拟内存系统使用了和SRAM缓存不同的术语，即使它们的许 多概念是相似的。在虚拟内存的习惯说法中，块被称为页。在磁盘和内存之间传送页的活 动叫做交换（swapping)或者页面调度（paging)。页从磁盘换入（或者页面调入）DRAM和从 DRAM换出（或者页面调出）磁盘。一直等待，直到最后时刻，也就是当有不命中发生时， 才换人页面的这种策略称为按需页面调度（demand paging)。也可以采用其他的方法，例 如尝试着预测不命中，在页面实际被引用之前就换人页面。然而，所有现代系统都使用的 是按需页面调度的方式。
9.3.5 分配页面
图9-8展示了当操作系统分配一个 新的虚拟内存页时对我们示例页表的 影响，例如，调用malloc的结果。在 这个示例中，VP5的分配过程是在磁 盘上创建空间并更新PTE 5，使它指 向磁盘上这个新创建的页面。
9.3.6又是局部性救了我们
当我们中的许多人都了解了虚拟 内存的概念之后，我们的第一印象通 常是它的效率应该是非常低。因为不 命中处罚很大，我们担心页面调度会罔9-8分配一个新的虚拟页面。内核在磁盘上分配VP5, 破坏程序性能。实际上，虚拟内存工	并且将PTE 5指向这个新的位置
作得相当好，这主要归功于我们的老朋友局部性（locality)。
.尽管在整个运行过程中程序引用的不同页面的总数可能超出物理内存总的大小，但是局部 性原则保证了在任意时刻，程序将趋向于在一个较小的活动瓦面(active page)集合上工作，这个 集合叫做工作集(working set)或者常驻集合(resident set)。在初始开销，也就是将工作集页面调 度到内存中之后，接下来对这个工作集的引用将导致命中，而不会产生额外的磁盘流量。
只要我们的程序有好的时间局部性，虚拟内存系统就能工作得相当好。但是，当然不 是所有的程序都能展现良好的时间局部性。如果工作集的大小超出了物理内存的大小，那 么程序将产生一种不幸的状态，叫做抖动（thrashing)，这时页面将不断地换进换出。虽然 虚拟内存通常是有效的，但是如果一个程序性能慢得像爬一样，那么聪明的程序员会考虑 是不是发生了抖动。
物理内存
PP3
旁注
统计缺页次数
你可以利用Linux的getrusage函数监测缺贵的数量（以及许多其他的信息）。
9.	4虚拟内存作为内存管理的工具
在上一节中，我们看到虚拟内存是如何提供一种机制，利用DRAM缓存来自通常更 大的虚拟地址空间的页面。有趣的是，一些早期的系统，比如DEC PDP-11/70，支持的 是一个比物理内存更小的虚拟地址空间。然而，虚拟地址仍然是一个有用的机制，因为它
566 第二部分在系统上运行程序
大大地简化了内存管理，并提供了一种自然的保护内存的方法。
到目前为止，我们都假设有一个单 独的页表，将一个虚拟地址空间映射到 物理地址空间。实际上，操作系统为每 个进程提供了一个独立的页表，因而也 就是一个独立的虚拟地址空间。图9-9 展示了基本思想。在这个示例中，进程 i的页表将V P1映射到PP 2，VP 2映 射到PP 7。相似地，进程；'的页表将 VP 1映射到PP 7，VP 2映射到PP
10。注意，多个虚拟页面可以映射到同IJly-9 VM如何为进程提供独立的地址空间。操作系统 一个共享物理页面上。	为系统中的每个进程都维护一个独立的页表
按需页面调度和独立的虚拟地址空间的结合，对系统中内存的使用和管理造成了深远的 影响。特别地，VM简化了链接和加载、代码和数据共享，以及应用程序的内存分配。
•简化链接。独立的地址空间允许每个进程的内存映像使用相同的基本格式，而不管 代码和数据实际存放在物理内存的何处。例如，像我们在图8-13中看到的，-■个给 定的Linux系统上的每个进程都使用类似的内存格式。对于64位地址空间，代码 段总是从虚拟地址OdOOOOO开始。数据段跟在代码段之后，中间有一段符合要求 的对齐空白。栈占据用户进程地址空间最高的部分，并向下生长。这样的一致性极 大地简化了链接器的设计和实现，允许链接器生成完全链接的可执行文件，这些可 执行文件是独立于物理内存中代码和数据的最终位置的。
•简化加载。虚拟内存还使得容易向内存中加载可执行文件和共享对象文件。要把目 标文件中.text和.data节加载到一个新创建的进程中，Linux加载器为代码和数 据段分配虚拟页，把它们标记为无效的（即未被缓存的），将页表条目指向目标文件 中适当的位置。有趣的是，加载器从不从磁盘到内存实际复制任何数据。在每个页 初次被引用时，要么是CPU取指令时引用的，要么是一条正在执行的指令引用一 个内存位置时引用的，虚拟内存系统会按照需要自动地调人数据页。
将一组连续的虚拟页映射到任意一个文件中的任意位置的表示法称作内存映射（memory mapping)。 Linux 提供一个称为 mmap 的系统调用， 允许应用程序自己做内存映 射。我们会在9. 8节中更详细地描述应用级内存映射。
•简化共享。独立地址空间为操作系统提供了一个管理用户进程和操作系统自身之间 共享的一致机制。一般而言，每个进程都有自己私有的代码、数据、堆以及栈区 域，是不和其他进程共享的。在这种情况中，操作系统创建页表，将相应的虚拟页 映射到不连续的物理页面。
然而，在一些情况中，还是需要进程来共享代码和数据。例如，每个进程必须调用相同 的操作系统内核代码，而每个C程序都会调用C标准库中的程序，比如printf。操作系统 通过将不同进程中适当的虚拟页面映射到相同的物理页面，从而安排多个进程共享这部分代 码的一个副本，而不是在每个进程中都包括单独的内核和C标准库的副本，如图9-9所示。
•简化内存分配。虚拟内存为向用户进程提供一个简单的分配额外内存的机制。当一 个运行在用户进程中的程序要求额外的堆空间时（如调用malloc的结果），操作系 统分配一个适当数字（例如《个连续的虚拟内存页面，并且将它们映射到物理内存
第9章虚拟内存 567
中任意位置的々个任意的物理页面。由于页表工作的方式，操作系统没有必要分配 々个连续的物理内存页面。页面可以随机地分散在物理内存中。
9.5虚拟内存作为内存保护的工具
任何现代计算机系统必须为操作系统提供手段来控制对内存系统的访问。不应该允许 一个用户进程修改它的只读代码段。而且也不应该允许它读或修改任何内核中的代码和数 据结构。不应该允许它读或者写其他进程的私有内存，并且不允许它修改任何与其他进程 共享的虚拟页面，除非所有的共享者都显式地允许它这么做（通过调用明确的进程间通信 系统调用）。
就像我们所看到的，提供独立的地址空间使得区分不同进程的私有内存变得容易。但 是，地址翻译机制可以以一种自然的方式扩展到提供更好的访问控制。因为每次CPU生 成一个地址时，地址翻译硬件都会读一个PTE，所以通过在PTE上添加一些额外的许可 位来控制对一个虚拟页面内容的访问十分简单。图9-10展示了大致的思想。
带许可位的页表
SUP READ WRITE
VP0:	否	是	否	PP6 v
进程/: VP 1:	否	是	是	PP4 、
VP2:	是	是	是	PP2 —
SUP READ WRITE
进程y:
VPO
VP2
物理内存
否	是	否	PP9 •—
是	是	是	PP6 Z
否	是	是	PP11 —
PPO
PP2
PP4
PP6
PP9 PP 11
阁9-10用虚拟内存来提供页面级的内存保护
在这个示例中，每个PTE中已经添加了三个许可位。SUP位表示进程是否必须运行 在内核(超级用户）模式下才能访问该页。运行在内核模式中的进程可以访问任何页面，但 是运行在用户模式中的进程只允许访问那些SUP为0的页面。READ位和WRITE位控 制对页面的读和写访问。例如，如果进程i运行在用户模式下，那么它有读VP0和读写 VP1的权限。然而，不允许它访问VP2。
如果一条指令违反了这些许可条件，那么CPU就触发一个一般保护故障，将控制传 递给一个内核中的异常处理程序。Linux shell—般将这种异常报告为“段错误（segmentation fault)’’。
9.	6地址翻译
这一节讲述的是地址翻译的基础知识。我们的目标是让你了解硬件在支持虚拟内存中 的角色，并给出足够多的细节使得你可以亲手演示一些具体的示例。不过，要记住我们省 略了大量的细节，尤其是和时序相关的细节，虽然这些细节对硬件设计者来说是非常重要 的，但是超出了我们讨论的范围。图9-11概括了我们在这节里将要使用的所有符号，供 读者参考。
568 第二部分在系统上运行程序
基本参数	
符号	描述
N=2n	虚拟地址空间中的地址数量
M^2m	物理地址空间中的地址数量
P = 2P	页的大小（字节）
虚拟地址（VA)的组成部分	
符号	描述
VPO	虚拟页面偏移量（字节）
VPN	虚拟页号
TLBI	TLB索引
TLBT	TLB标记
物理地址（PA)的组成部分	
符号	描述
PPO	物理页面偏移量（字节）
PPN	物理页号
C0	缓冲块内的字节偏移量
CI	高速缓存索引
CT	髙速缓存标记
图9-11地址翻译符号小结
形式上来说，地址翻译是一个N元素的虚拟地址空间（VAS)中的元素和一个M元素 的物理地址空间（PAS)中元素之间的映射，
MAP:VAS — PAS U 0
这里
MA	如果虚拟地址A处的数据在PAS的物理地址A'处
_ ^0如果虚拟地址A处的数据不在物理内存中 图9-12展示了 MMU如何利用页表来实现这种映射。CPU中的一个控制寄存器，页表 基址寄存器（Page Table Base Register, PTBR)指向当前页表。；7位的虚拟地址包含两个部分: —个P位的虚拟瓦面偏移（Virtual Page Offset，VPO)和一个（n — p)位的虚拟页号（Virtual
虚抛址
物理册
阁9-〗2使用页表的地址翻译
第9章虚拟内存 569
Page Number，VPN)。MMU利用VPN来选择适当的PTE。例如，VPNO选择PTEO, VPN1选择PTE1，以此类推。将页表条目中物理页号（Physical Page Number, PPN)和虚拟 地址中的VPO串联起来，就得到相应的物理地址^注意，因为物理和虚拟页面都是P字节 的，所以物理页面偏移（Physical Page Offset, PPO)和VPO是相同的。
图9-13a展示了当页面命中时，CPU硬件执行的步骤。
•第1步：处理器生成一个虚拟地址，并把它传送给MMU。
•第2步：MMU生成PTE地址，并从高速缓存/主存请求得到它。
•第3步：高速缓存/主存向MMU返回PTE。
*第4步：MMU构造物理地址，并把它传送给高速缓存/主存。
•第5步：高速缓存/主存返回所请求的数据字给处理器。
CPU芯片	®
©
a)页面命中
©
b)缺页
图9-13页面命中和缺页的操作图（VA:虚拟地址。PTEA:页表条目地址。
PTE:页表条目。PA:物理地址）
页面命中完全是由硬件来处理的，与之不同的是，处理缺页要求硬件和操作系统内核 协作完成，如图9_13b所示。
•第1步到第3步：和图9-13a中的第1步到第3步相同。
*第4步：PTE中的有效位是零，所以MMU触发了一次异常，传递CPU中的控制 到操作系统内核中的缺页异常处理程序。
•第5步：缺页处理程序确定出物理内存中的牺牲页，如果这个页面已经被修改了， 则把它换出到磁盘。
•第6步：缺页处理程序页面调人新的页面，并更新内存中的PTE。
570 第二部分在系统上运行程序
•第7步：缺页处理程序返回到原来的进程，再次执行导致缺页的指令。CPU将引起缺 页的虚拟地址重新发送给MMU。因为虚拟页面现在缓存在物理内存中，所以就会命 中，在MMU执行了图9-13b中的步骤之后，主存就会将所请求字返回给处理器^ 练习题9. 3给定一个32位的虚拟地址空间和一个24位的物理地址，对于下面的页 面大小P，确定VPN、VPO、PPN和PPO中的位数：
P	VPN位数	VPO位数	PPN位数	PPO位数
1KB				
2KB				
4KJB				
8KB				
9. 6. 1结合高速缓存和虚拟内存
在任何既使用虚拟内存又使用SRAM高速缓存的系统中，都有应该使用虚拟地址还 是使用物理地址来访问SRAM高速缓存的问题。尽管关于这个折中的详细讨论已经超出 了我们的讨论范围，但是大多数系统是选择物理寻址的。使用物理寻址，多个进程同时在 高速缓存中有存储块和共享来自相同虚拟页面的块成为很简单的事情。而且，高速缓存无 需处理保护问题，因为访问权限的检查是地址翻译过程的一部分。
图9-14展示了一个物理寻址的高速缓存如何和虚拟内存结合起来。主要的思路是地 址翻译发生在高速缓存查找之前。注意，页表条目可以缓存，就像其他的数据字一样。
图!Ml将VM与物理寻址的高速缓存结合起来（VA:虚拟地址。
PTEA:页表条目地址^ PTE:页表条目。PA:物理地址）
9.6.2	利用TLB加速地址翻译
正如我们看到的，每次CPU产生一个虚拟地址，MMU就必须查阅一个PTE,以便 将虚拟地址翻译为物理地址。在最糟糕的情况下，这会要求从内存多取一次数据，代价是 几十到几百个周期。如果PTE碰巧缓存在L1中，那么开销就下降到1个或2个周期。然 而，许多系统都试图消除即使是这样的开销，它们在MMU中包括了一个关于PTE的小 的缓存，称为翻译后备缓冲器（Translation Lookaside Buffer，TLB)。
TLB是一个小的、虚拟寻址的缓存，其 p______P+t p+t-i_pp-i 0
中每一行都保存着一个由单个PTE组成的块。标记^(TLBT ) | TLB索引 （TLBI) |
TLB通常有高度的相联度。如图9-15所示，'	^	’
用于组选择和行匹配的索引和标记字段是从	阁9-15虚拟地址中用以访问TLB的组成部分
第9章虚拟内存 571
虚拟地址中的虚拟页号中提取出来的。如果TLB有了=2'个组，那么TLB索弓KTLBI)是由 VPN的/个最低位组成的，而TLB标记(TLBT)是由VPN中剩余的位组成的。
图9-16a展示了当TLB命中时（通常情况）所包括的步骤。这里的关键点是，所有的地 址翻译步骤都是在芯片上的MMU中执行的，因此非常快。
•第1步：CPU产生一个虚拟地址。
•第2步和第3步：MMU从TLB中取出相应的PTE。
*第4步：MMU将这个虚拟地址翻译成一个物理地址，并且将它发送到高速缓存/主存。 ♦第5步：高速缓存/主存将所请求的数据字返回给CPU。
当TLB不命中时，MMU必须从L1缓存中取出相应的PTE，如图9-16b所示。新取 出的PTE存放在TLB中，可能会覆盖一个已经存在的条目。
⑤数据	®
a) TLB命中	b) TLB不命中
罔9-16 TLB命中和不命中的操作图
9.6..3 多级页表
到目前为止，我们一直假设系统只用一个单独的页表来进行地址翻译。但是如果我们 有一个32位的地址空间、4KB的页面和一个4字节的PTE，那么即使应用所引用的只是 虚拟地址空间中很小的一部分，也总是需要一个4MB的页表驻留在内存中。对于地址空 间为64位的系统来说，问题将变得更复杂。
用来压缩页表的常用方法是使用层次结构的页表。用一个具体的示例是最容易理解这 个思想的。假设32位虚拟地址空间被分为4KB的页，而每个页表条目都是4字节。还假 设在这一时刻，虚拟地址空间有如下形式：内存的前2K个页面分配给了代码和数据，接 下来的6K个页面还未分配，再接下来的1023个页面也未分配，接下来的1个页面分配给 了用户栈。图9-17展示了我们如何为这个虚拟地址空间构造一个两级的页表层次结构。
—级页表中的每个PTE负责映射虚拟地址空间中一个4MB的片（chunk)，这里每一 片都是由1024个连续的页面组成的。比如，PTE0映射第一片，PTE1映射接下来的一 片，以此类推。假设地址空间是4GB，1024个PTE已经足够覆盖整个空间了。
如果片；中的每个页面都未被分配，那么一级PTEz_就为空。例如，图9-17中，片2〜7 是未被分配的。然而，如果在片丨中至少有一个页是分配了的，那么一级PTE;就指向一 个二级页表的基址。例如，在图9-17中，片0、1和8的所有或者部分已被分配，所以它 们的一级PTE就指向二级页表。
572 第二部分在系统上运行程序
一级页表
二级页表
虚拟内存
已分配的2K个代码和 数据VMS
6K个未分配的VM页
1023个未分配的页 1个已分配的用做栈的VMM
阍9-17 —个两级页表层次结构。注意地址是从上往下增加的	.
二级页表中的每个PTE都负责映射一个4KB的虚拟内存页面，就像我们查看只有一 级的页表一样。注意，使用4字节的PTE，每个一级和二级页表都是4KB字节，这刚好 和一个页面的大小是一样的。
这种方法从两个方面减少了内存要求。第一，如果一级页表中的一个PTE是空的， 那么相应的二级页表就根本不会存在。这代表着一种巨大的潜在节约，因为对于一个典型 的程序，4GB的虚拟地址空间的大部分都会是未分配的。第二，只有一级页表才需要总是 在主存中；虚拟内存系统可以在需要时创建、页面调人或调出二级页表，这就减少了主存 的压力；只有最经常使用的二级页表才需要缓存在主存中。
图9-18描述了使用（级页表层次结构的地址翻译。虚拟地址被划分成为纟个VPN和 1个VPO。每个VPN/都是一个到第〗级页表的索引，其中第）级页表中的每 个PTE，—1，都指向第i + 1级的某个页表的基址。第々级页表中的每个PTE包 含某个物理页面的PPN，或者一个磁盘块的地址。为了构造物理地址，在能够确定PPN 之前，MMU必须访问6个PTE。对于只有一级的页表结构，PPO和VPO是相同的。
物理地址
阁9-18使用々级页表的地址翻译
第9章虚拟内存 573
访问々个PTE，第一眼看上去昂贵而不切实际。然而，这里TLB能够起作用，正是 通过将不同层次上页表的PTE缓存起来。实际上，带多级页表的地址翻译并不比单级页 表慢很多。
9. 6. 4综合：端到端的地址翻译
在这一节里，我们通过一个具体的端到端的地址翻译示例，来综合一下我们刚学过的 这些内容，这个示例运行在有一个TLB和Lid-cache的小系统上。为了保i正可管理性， 我们做出如下假设：
♦内存是按字节寻址的。
♦内存访问是针对1字节的字的（不是4字节的字）。
*虚拟地址是14位长的（77 = 14)。
*物理地址是12位长的（m = 12)。
•页面大小是64字节（P = 64)。
♦	TLB是四路组相联的，总共有16个条目。
•	Lid-cache是物理寻址、直接映射的，行大小为4字节，而总共有16个组。
图9-19展示了虚拟地址和物理地址的格式。因为每个页面是26 = 64字节，所以虚拟 地址和物理地址的低6位分别作为VPO和PPO。虚拟地址的高8位作为VPN。物理地址 的高6位作为PPN。
虚拟地址
13	12	11	10	9	8	7	6	5	4	3	2
VPO
(虚拟页号）
(虚拟页偏移）
物理地址
11	10	98	76	54	3	2	10
—PPN —
(物理页号）
——PPO——
(物理页偏移）
图9-19 小内存系统的寻址。假设14位的虚拟地址（tt=14)，
12位的物理地址（m=12)和64字节的页面（P=64)
图9-20展示了小内存系统的一个快照，包括TLB(图9-20a)、页表的一部分（图9-20b)和L1高速缓存（图9-20c)。在TLB和高速缓存的图上面，我们还展示了访问这些设 备时硬件是如何划分虚拟地址和物理地址的位的。
• TLB。TLB是利用VPN的位进行虚拟寻址的。因为TLB有4个组，所以VPN的 低2位就作为组索弓KTLBI)。VPN中剩下的高6位作为标记（TLBT)，用来区别 可能映射到同一个TLB组的不同的VPN。
*页表。这个页表是一个单级设计，一共有28 =256个页表条目（PTE)。然而，我们 只对这些条目中的开头16个感兴趣。为了方便，我们用索引它的VPN来标识每个 PTE;但是要记住这些VFN并不是页表的一部分，也不储存在内存中。另外，注 意每个无效PTE的PPN都用一个破折号来表示，以加强一个概念：无论刚好这里 存储的是什么位值，都是没有任何意义的。
•高速缓存。直接映射的缓存是通过物理地址中的字段来寻址的^因为每个块都是4 字节，所以物理地址的低2位作为块偏移（CO)。因为有16组，所以接下来的4位 就用来表示组索引（CI)。剩下的6位作为标记（CT)。
574	第二部分在系统上运行程序
--------TLBT------►♦丁LBI-^
13	12	11	10	9	8	7	6	5	4	3	2	1	0
虚拟地址 I I 1 I I I I I I I I I I i~n
•*----------------VPN-----------► ----- VPO--------►
位标记位PPN有效位标记位PPN有效位标记位PPN有效位标记位PPN有效位
0	03	-	0	09	0D		00	-	0	07	02	1
1	03	2D		02	-	0	04	-	0	0A	-	0
2	02	-	0	08	-	0	06	-	0	03	-	0
3	07	-	0	03	0D	1	0A	34	1	02	-	0
a) TLB:四组，16个条目，四路组相联
VPN PPN有效位 VPN PPN有效位
00	28	1	08	13	1
01	—	0	09	17	1
02	33	1	0A	09	1
03	02	1	0B	-	0
04	—	0	0C	-	0
05	16	1	0D	2D	1
06	—	0	0E	11	1
07	—	0	0F	0D	1
b)页表：只展示了前16个PTE
<--CT ------CI---►—(：0-►
11	10	9876543210
物理地址 1 I I 1 I I I I I I 1 I I
•*-PPN---► ■*- PPO -►
索引标记位有效位块0块1块2块3
0	19		99	11	23	11
1	15	0	—	—	—	—
2	IB		00	02	04	08
3	36	0	—	—	—	—
4	32		43	6D	8F	09
5	0D		36	72	F0	ID
6	31	0	—	—	——	——
7	16		11	C2	DF	03
8	24	1	3A	00	51	89
9	2D	0	—	—	—	—
A	2D	1	93	15	DA	3B
B	OB	0	—	—	—	—
C	12	0	—	—	—	—
D	16	1	04	96	34	15
E	13	1	83	77	IB	D3
F	14	0	—	—	一	—
c)高速缓存：16个组，4字节的块，直接映射
罔9-20小内存系统的TLB、页表以及缓存^ TLB、页表和缓存中所有的值都是十六进制表示的
给定了这种初始化设定，让我们来看看当CPU执行一条读地址0x03d4处字节的加载 指令时会发生什么。（回想一下我们假定CPU读取1字节的字，而不是4字节的字。）为了
第9章虚拟内存 575
开始这种手工的模拟，我们发现写下虚拟地址的各个位，标识出我们会需要的各种字段， 并确定它们的十六进制值，是非常有帮助的。当硬件解码地址时，它也执行相似的任务。
	TLBT TLBI
	0x03 0x03
位位置	13 12 11 10 9 8 7 6 5 4 3 2 1 0
VA = 0x03d4	0 0 0 0 1 1 1 1 0 1 0 1 0 0
	VPN VPO
	0x0f 0x14
开始时，MMU从虚拟地址中抽取出VPN(OxOF)，并且检查TLB，看它是否因为前 面的某个内存引用缓存了 PTE OxOF的一个副本。丁LB从VPN中抽取出TLB索引（0x03) 和TLB标记（0x3)，组0x3的第二个条目中有效匹配，所以命中，然后将缓存的PPN (OxOD)返回给 MMU。
如果TLB不命中，那么MMU就需要从主存中取出相应的PTE。然而，在这种情况 中，我们很幸运，TLB会命中。现在，MMU有了形成物理地址所需要的所有东西。它通 过将来自PTE的PPN(OxOD)和来自虚拟地址的VPO(0xl4)连接起来，这就形成了物理地 址（0x354)。
接下来，MMU发送物理地址给缓存，缓存从物理地址中抽取出缓存偏移CO(OxO)、 缓存组索引CI(0X5)以及缓存标记CT(0x0D)。
			CT				Cl	CO 0x0
			OxOd				0x05	
位位置	11	10	9 8	7	6	5	4 3 2	1 0
PA = 0x354	0	0	1 1	0	1	0	10 1	0 0
			PPN				PPO	
			OxOd				0x14	
'因为组0x5中的标记与CT相匹配，所以缓存检测到一个命中，读出在偏移量CO处 的数据字节（0x36),并将它返回给MMU，随后MMU将它传递回CPU。
翻译过程的其他路径也是可能的。例如，如果TLB不命中，那么MMU必须从页表 中的PTE中取出PPN。如果得到的PTE是无效的，那么就产生一个缺页，内核必须调人 合适的页面，重新运行这条加载指令。另一种可能性是PTE是有效的，但是所需要的内 存块在缓存中不命中。
这练习题9.4 说明9.6.4节中的示例内存系统是如何将一个虚拟地址翻译成一个物理 地址和访问缓存的。对于给定的虚拟地址，指明访问的TLB条目、物理地址和返回 的缓存字节值。指出是否发生了 TLB不命中，是否发生了缺页，以及是否发生了缓 存不命中。如果是缓存不命中，在“返回的缓存字节”栏中输入“一”。如果有缺页， 则在“PPN” 一栏中输入“一”，并且将C部分和D部分空着。
虚拟地址：0x03d7 A.虚拟地址格式
13	12	11	10	9	8	7	6	5	4	3	2	1	0
B.地址翻译
576 第二部分在系统上运行程序
参数	值
VPN	
TLB索引	
TLB标记	
TLB命中？（是/否）	
缺页？（是/否）	
PPN	
C.物理地址格式
11	10	9876543210
D.物理内存引用
参数	值
字节偏移	
缓存索引	
缓存标记	
缓存命中？（是/否）	
返回的缓存字节	
9.7 案例研究：Intel Core i7/Linux内存系统
我们以一个实际系统的案例研究来总结我们对虚拟内存的讨论：一个运行Linux的 Intel Core i7。虽然底层的Haswell微体系结构允许完全的64位虚拟和物理地址空间，而 现在的（以及可预见的未来的）Core i7实现支持48位（256TB)虚拟地址空间和52位（4PB) 物理地址空间，还有一个兼容模式，支持32位（4GB)虚拟和物理地址空间。
图9-21给出了 Core i7内存系统的重要部分。处理器封装（processor package)包括四 个核、一个大的所有核共享的L3高速缓存，以及一个DDR3内存控制器。每个核包含一 个层次结构的TLB、一个层次结构的数据和指令高速缓存，以及一组快速的点到点链路， 这种链路基于QuickPak技术，是为了让一个核与其他核和外部I/O桥直接通信。TLB 是虚拟寻址的，是四路组相联的。Ll、L2和L3高速缓存是物理寻址的，块大小为64字 节。L1和L2是8路组相联的，而L3是16路组相联的。页大小可以在启动时被配置为 4KB或4MB。Linux使用的是4KB的页。
9.	7. 1 Core i7地址翻译
图9-22总结了完整的Core i7地址翻译过程，从CPU产生虚拟地址的时刻一直到来 自内存的数据字到达CPU。Core i7采用四级页表层次结构。每个进程有它自己私有的页 表层次结构。当一个Linux进程在运行时，虽然Core i7体系结构允许页表换进换出，但 是与已分配了的页相关联的页表都是驻留在内存中的。CR3控制寄存器指向第一级页表 (L1)的起始位置。CR3的值是每个进程上下文的一部分，每次上下文切换时，CR3的值 都会被恢复。
第9章虚拟内存 5尸
处理器封装 核x4
寄存器		取指令				MMU (地址翻译）			
1						1			
LI d-cache 32KB，8 路		LI i-cache 32 KB, 8路			LI d-TLB 64个条目，4路		LI i-TLB 128个条目，4路		
L3统一高速缓存 8MB，16 路 (所有的核共享）
L2统一高速缓存		L2 统一TLB
256KB，8路		512个条目，4路
QuickPath 互连
DDR3存储器控制器 (所有的核共享）
主存
到其他核 到I/O桥
图9-21 Core i7的内存系统
页表
图9-22 Corei7地址翻译的概况。为了简化，没有显示i-cache、i-TLB和L2统一TLB
578	第二部分在系统上运行程序
图9-23给出了第一级、第二级或第三级页表中条目的格式。当P=1时（Linux中就 总是如此），地址字段包含一个40位物理页号（PPN)，它指向适当的页表的开始处。注 意，这强加了一个要求，要求物理页表4KB对齐。
63	62 52 51		12	11 9	8	7	6	5	4	3	2 1		0
XD	未使用	页表物理基地址		未使用	G	PS		A	CD	WT	U/S	R/W	P=1
OS可用（磁盘上的页表位置）	P=0
字段	描述
P	子页表在物理内存中（1)，不在（0)
R/W	对于所有可访问页，只读或者读写访问权限
U/S	对于所有可访问页，用户或超级用户（内核）模式访问权限
WT	子页表的直写或写回缓存策略
CD	能/不能缓存子页表
A	引用位（由MMU在读和写时设置，由软件清除）
PS	页大小为4 KB或4 MB (只对第一层PTE定义）
Base addr	子页表的物理基地址的最高40位
XD	能/不能从这个PTE可访问的所有页中取指令
图9-23第一级、第二级和第三级页表条目格式。每个条目引用一个4KB子页表
图9-24给出了第四级页表中条目的格式。当P=l，地址字段包括一个40位PPN， 它指向物理内存中某一页的基地址。这又强加了一个要求，要求物理页4KB对齐。
63	62 52 51		12 11 9		8	7	6	5	4	3	2		0
XD	未使用	页表物理基地址		未使用	G	0	D	A	CD	WT	U/S	R/W	P=1
OS可用（磁盘上的页表位置）	P=0
字段	描述
P	子页表在物理内存中（1)，不在（0)
R/W	对于子页，只读或者读写访问权限
U/S	X于于子页，用户或超级用户（内核）模式访问权限
WT	子页的直写或写回缓存策略
CD	能/不能缓存
A	引用位（由MMU在读和写时设置，由软件清除）
D	修改位（由MMU在读和写时设置，由软件清除）
G	全局页（在任务切换时，不从TLB中驱逐出去）
Base addr	子页物理基地址的最高40位
XD	能/不能从这个子页中取指令
图9-24第四级页表条目的格式。每个条目引用一个4KB子页
PTE有三个权限位，控制对页的访问。R/W位确定页的内容是可以读写的还是只读 的。U/S位确定是否能够在用户模式中访问该页，从而保护操作系统内核中的代码和数据
第9章虚拟内存 579
不被用户程序访问。XD(禁止执行)位是在64位系统中引人的，可以用来禁止从某些内存 页取指令。这是一个重要的新特性，通过限制只能执行只读代码段，使得操作系统内核降 低了缓冲区溢出攻击的风险。
当MMU翻译每一个虚拟地址时，它还会更新另外两个内核缺页处理程序会用到的 位。每次访问一个页时，MMU都会设置A位，称为引用位（reference bit)。内核可以用 这个引用位来实现它的页替换算法。每次对一个页进行了写之后，MMU都会设置D位， 又称修改位或脏位（diny bit)。修改位告诉内核在复制替换页之前是否必须写回牺牲页。 內核可以通过调用一条特殊的内核模式指令来清除引用位或修改位。
图9-25给出了 Core i7 MMU如何使用四级的页表来将虚拟地址翻译成物理地址。36 位VPN被划分成四个9位的片，每个片被用作到一个页表的偏移量。CR3寄存器包含L1 页表的物理地址。VPN1提供到一个L1PET的偏移量，这个PTE包含L2页表的基地 址。VPN2提供到一个L2PTE的偏移量，以此类推。
9	9	9	9	12
[
CR3
LI PT 的 物理地址
T
LI PT
4〇页全局目录
^9
I
L2PT
页上层目录
_9^
L2PTE
T
L3PT
页中层目录
_9^
L3PTE
T
VPO
L4 PT
40页表
_^9
g条g	每个条巨
512GB区域	1GB区域
每个条目 2 MB区域
每个条目 4KB区域
40
40
页的物理
J mjmt
,到物理和虚拟 ’页的偏移量
PPN
PPO
]物理紐
图9-25 Corei7页表翻译(PT:页表，PTE:页表条目，VPN:虚拟页号，VPO:虚拟页偏移， PPN:物理页号，PPO:物理页偏移量。图中还给出了这四级页表的Linux名字）
优化地址翻译
在对地址翻译的讨论中，我们描述了一个顺序的两个步骤的过程，1)MMU将虚拟 地址翻译成物理地址，2)将物理地址传送到L1高速缓存。然而，实际的硬件实现使用 了一个灵活的技巧，允许这些步骤部分重叠，因此也就加速了对L1高速缓存的访问。 例如，页面大小为4KB的Core i7系统上的一个虚拟地址有12位的VPO，并且这些位 和相应物理地址中的PP0的12位是相同的。因为八路组相联的、物理寻址的L1高速 缓存有64个组和大小为64字节的缓存块，每个物理地址有6个（log2 64)缓存偏移位和 6个（log264)索引位。这12位恰好符合虚拟地址的VPO部分，这绝不是偶然！当CPU 需要翻译一个虚拟地址时，它就发送VPN到MMU，发送VPO到高速L1缓存。当MMU
580	第二部分在系统上运行程序
向TLB请求一个页表条目时，L1高速缓存正忙着利用VPO位查找相应的纽，并读出 这个组里的8个标记和相应的数据字。当MMU从TLB得到PPN时，缓存已经准备好 试着把这个PPN与这8个标记中的一个进行匹配了。
9. 7. 2 Linux虚拟内存系统
对每个进程 都不相同
对每个进程 都一样
%rsp-
与进程相关的数据结构 (例如，页表、task和 mm结构，内核栈）
物理内存
内核代码和数据
用户栈
内核虚拟 内存
一个虚拟内存系统要求硬件和内核软件之间的紧密协作。版本与版本之间细节都不尽 相同，对此完整的阐释超出了我们讨论的范围。但是，在这一小节中我们的目标是对 Linux的虚拟内存系统做一个描述，使你能够大致了解一个实际的操作系统是如何组织虚 拟内存，以及如何处理缺页的。
Linux为每个进程维护了一个单独的 虚拟地址空间，形式如图9-26所示。我们 已经多次看到过这幅图了，包括它那些熟 悉的代码、数据、堆、共享库以及栈段。
既然我们理解了地址翻译，就能够填人更 多的关于内核虚拟内存的细节了，这部分 虚拟内存位于用户栈之上。
内核虚拟内存包含内核中的代码和数 据结构。内核虚拟内存的某些区域被映射 到所有进程共享的物理页面。例如，每个 进程共享内核的代码和全局数据结构。有 趣的是，Linux也将一组连续的虚拟页面 (大小等于系统中DRAM的总量）映射到 相应的一组连续的物理页面。这就为内核 提供了一种便利的方法来访问物理内存中 任何特定的位置，例如，当它需要访问页 表，或在一些设备上执行内存映射的I/O 操作，而这些设备被映射到特定的物理内 存位置时。	图9_26 —个Linux进程的虚拟内存
内核虚拟内存的其他区域包含每个进程都不相同的数据。比如说，页表、内核在进程 的上下文中执行代码时使用的栈，以及记录虚拟地址空间当前组织的各种数据结构。
1. Linux虚拟内存区域
Limix将虚拟内存组织成一些区域（也叫做段）的集合。一个区域（area)就是已经存在 着的（已分配的）虚拟内存的连续片（chunk),这些页是以某种方式相关联的。例如，代码 段、数据段、堆、共享库段，以及用户栈都是不同的区域。每个存在的虚拟页面都保存在 某个区域中，而不属于某个区域的虚拟页是不存在的，并且不能被进程引用。区域的概念 很重要，因为它允许虚拟地址空间有间隙。内核不用记录那些不存在的虚拟页，而这样的
0x40000000
代码（.text)
进程虚拟 内存
页也不占用内存、磁盘或者内核本身中的任何额外资源。
图9-27强调了记录一个进程中虚拟内存区域的内核数据结构。内核为系统中的每个 进程维护一个单独的任务结构（源代码中的taSk_Struct)。任务结构中的元素包含或者指 向内核运行该进程所需要的所有信息（例如，PID、指向用户栈的指针、可执行目标文件的 名字，以及程序计数器）。
I
第9章虚拟内存 581
进程虚拟内存
图9-27 Unux是如何组织虚拟内存的
任务结构中的一个条目指向mm_StruCt，它描述了虚拟内存的当前状态。我们感兴趣的 两个字段是pgd和ramap，其中pgd指向第一级页表(页全局目录）的基址，而rnmap指向一个 vm_area_structs(区域结构）的链表，其中每个vm_area_structs都描述了当前虚拟地址空 间的一个E域。当内核运行这个进程时，就将pgd存放在CR3控制寄存器中。
为了我们的目的，一个具体区域的区域结构包含下面的字段：
•	vm_start:指向这个区域的起始处。
•*vra_end:指向这个区域的结束处。
•	vm^rot:描述这个区域内包含的所有页的读写许可权限。
*vm_fiagS:描述这个区域内的页面是与其他进程共享的，还是这个进程私有的（还 描述了其他一些信息）。
•	vm_next:指向链表中下一个K域结构。
2.	Linux缺页异常处理
假设MMU在试图翻译某个虚拟地址A时，触发了一个缺页。这个异常导致控制转 移到内核的缺页处理程序，处理程序随后就执行下面的步骤：
1)	虚拟地址A是合法的吗？换句话说，A在某个区域结构定义的区域内吗？为了回 答这个问题，缺页处理程序搜索区域结构的链表，把A和每个区域结构中的vm_Start和 vm_end做比较。如果这个指令是不合法的，那么缺页处理程序就触发一个段^误，从而 终止这个进程。这个情况在图9-28中标识为“1”。
因为一个进程可以创建任意数量的新虚拟内存区域（使用在下一节中描述的mmap函 数），所以顺序搜索区域结构的链表花销可能会很大。因此在实际中，Linux使用某些我 们没有显示出来的字段，Linux在链表中构建了一棵树，并在这棵树上进行査找。
2)	试图进行的内存访问是否合法？换句话说，进程是否有读、写或者执行这个区域 内页面的权限？例如，这个缺页是不是由一条试图对这个代码段里的只读页面进行写操作
582	第二部分在系统上运行程序
的存储指令造成的？这个缺页是不是因为一个运行在用户模式中的进程试图从内核虚拟内 存中读取字造成的？如果试图进行的访问是不合法的，那么缺页处理程序会触发一个保护 异常，从而终止这个进程。这种情况在图9-28中标识为“2”。
3)此刻，内核知道了这个缺页是由于对合法的虚拟地址进行合法的操作造成的。它是 这样来处理这个缺页的：选择一个牺牲页面，如果这个牺牲页面被修改过，那么就将它交换 出去，换人新的页面并更新页表。当缺页处理程序返回时，CPU重新启动引起缺页的指令，这 条指令将再次发送A到MMU。这次，MMU就能正常地翻译A,而不会再产生缺页中断了。
9.8内存映射
Linux通过将一个虚拟内存区域与一个磁盘上的对象（object)关联起来，以初始化这 个虚拟内存区域的内容，这个过程称为内存映射（memory mapping)。虚拟内存区域可以 映射到两种类型的对象中的一种：
1)	Linux文件系统中的普通文件：一个区域可以映射到一个普通磁盘文件的连续部 分，例如一个可执行目标文件。文件区（section)被分成页大小的片，每一片包含一个虚拟 页面的初始内容。因为按需进行页面调度，所以这些虚拟页面没有实际交换进入物理内 存，直到CPU第一次引用到页面（即发射一个虚拟地址，落在地址空间这个页面的范围之 内）。如果区域比文件E要大，那么就用零来填充这个区域的余下部分。
2)	匿名文件：一个区域也可以映射到一个匿名文件，匿名文件是由内核创建的，包 含的全是二进制零。CPU第一次引用这样一个区域内的虚拟页面时，内核就在物理内存 中找到一个合适的牺牲页面，如果该页面被修改过，就将这个页面换出来，用二进制零覆 盖牺牲页面并更新页表，将这个页面标记为是驻留在内存中的。注意在磁盘和内存之间并 没有实际的数据传送。因为这个原因，映射到匿名文件的区域中的页面有时也叫做请求二 进制零的瓦（demand-zero page)。
无论在哪种情况中，一旦一个虚拟页面被初始化了，它就在一个由内核维护的专门的 交换文件（swap file)之间换来换去。交换文件也叫做交换空间（swap space)或者交换区域
第9章虚拟内存 583
(swap area)。需要意到的很重要的一点是，在任何时刻，交换空间都限制着当前运行着 的进程能够分配的虚拟页面的总数。
9.8.	1再看共享对象
内存映射的概念来源于一个聪明的发现：如果虚拟内存系统可以集成到传统的文件系 统中，那么就能提供一种简单而高效的把程序和数据加载到内存中的方法。
正如我们已经看到的，进程这一抽象能够为每个进程提供自己私有的虚拟地址空间， 可以免受其他进程的错误读写。不过，许多进程有同样的只读代码区域。例如，每个运行 Linux shell程序bash的进程都有相同的代码区域。而且，许多程序需要访问只读运行时 库代码的相同副本。例如，每个C程序都需要来自标准C库的诸如printf这样的函数。 那么，如果每个进程都在物理内存中保持这些常用代码的副本，那就是极端的浪费了。幸 运的是，内存映射给我们提供了一种清晰的机制，用来控制多个进程如何共享对象。
一个对象可以被映射到虚拟内存的一个区域，要么作为共享对象，要么作为私有对 象。如果一个进程将一个共享对象映射到它的虚拟地址空间的一个E域内，那么这个进程 对这个K域的任何写操作，对于那些也把这个共享对象映射到它们虚拟内存的其他进程而 言，也是可见的。而且，这些变化也会反映在磁盘上的原始对象中。
另一方面，对于一个映射到私有对象的区域做的改变，对于其他进程来说是不可见 的，并且进程对这个区域所做的任何写操作都不会反映在磁盘上的对象中。一个映射到共 享对象的虚拟内存区域叫做共享区域。类似地，也有私有区域。
假设进程1将一个共享对象映射到它的虚拟内存的一个区域中，如图9-29a所示。现 在假设进程2将同一个共享对象映射到它的地址空间（并不一定要和进程1在相同的虚拟 地址处，如图9-29b所示）。
进程1的	物理	进程2的	进程1的
虚拟内存	内存	虚拟内存	虚拟内存
物理	进程2的
内存	虚拟内存
共享对象
共享对象
a)进程I映射了共享对象之后
b)进程2映射了同一个共享对象之后
图9-29	—个共享对象（注意，物理页面不一定是连续的）
因为每个对象都有一个唯一的文件名，内核可以迅速地判定进程1已经映射了这个对 象，而且可以使进程2中的页表条目指向相应的物理页面。关键点在于即使对象被映射到 了多个共享区域，物理内存中也只需要存放共享对象的一个副本。为了方便，我们将物理 页面显示为连续的，但是在一般情况下当然不是这样的。
私有对象使用一种叫做写时复制（copy-on-write)的巧妙技术被映射到虚拟内存中。一个
584	第二部分在系统上运行程序
私有对象开始生命周期的方式基本上与共享对象的一样，在物理内存中只保存有私有对象的 一份副本。比如，图9-30a展示了一种情况，其中两个进程将一个私有对象映射到它们虚拟内 存的不同区域，但是共享这个对象同一个物理副本。对于每个映射私有对象的进程，相应私有 区域的页表条目都被标记为只读，并且区域结构被标记为私有的写时复制。只要没有进程试图 写它自己的私有区域，它们就可以继续共享物理内存中对象的一个单独副本。然而，只要有一 个进程试图写私有区域内的某个页面，那么这个写操作就会触发一个保护故障。
当故障处理程序注意到保护异常是由于进程试图写私有的写时复制区域中的一个页面 而引起的，它就会在物理内存中创建这个页面的一个新副本，更新页表条目指向这个新的 副本，然后恢复这个页面的可写权限，如图9-30b所示。当故障处理程序返回时，CPU重 新执行这个写操作，现在在新创建的页面上这个写操作就可以正常执行了。
进程1的	物理	进程2的
虚拟内存	内存	虚拟内存
进程1的	物理	进程2的
虚拟内存	内存	虚拟内存
私有的写时复制对象
私有的写时复制对象
a)两个进程都映射了私有的写时复制对象之后	b)进程2写了私有区域中的一个页之后
图9-3〇	—个私有的写时复制对象
通过延迟私有对象中的副本直到最后可能的时刻，写时复制最充分地使用了稀有的物
理内存。
9. 8.2再看fork函数
既然我们理解了虚拟内存和内存映射，那么我们可以清晰地知道fork函数是如何创 建一个带有自己独立虚拟地址空间的新进程的。
当fork函数被当前进程调用时，内核为新进程创建各种数据结构，并分配给它一个 唯一的PID。为了给这个新进程创建虚拟内存，它创建了当前进程的mm_struct、区域结 构和页表的原样副本。它将两个进程中的每个页面都标记为只读，并将两个进程中的每个 区域结构都标记为私有的写时复制。
当fork在新进程中返回时，新进程现在的虚拟内存刚好和调用fork时存在的虚拟 内存相同。当这两个进程中的任一个后来进行写操作时，写时复制机制就会创建新页面， 因此，也就为每个进程保持了私有地址空间的抽象概念。
9. 8. 3 再看execve函数
虚拟内存和内存映射在将程序加载到内存的过程中也扮演着关键的角色。既然已经理 解了这些概念，我们就能够理解execve函数实际上是如何加载和执行程序的。假设运行
第9章虚拟内存 585
在当前进程中的程序执行了如下的execve调用：
execveC'a.out", NULL, NULL);
正如在第8章中学到的，execve函数在当前进程中加载并运行包含在可执行目标文件a.ont 中的程序，用a.out程序有效地替代了当前程序。加载并运行a.out需要以下几个步骤：
•删除已存在的用户区域。删除当前进程虚拟地址的用户部分中的已存在的区域结构。
•映射私有区域。为新程序的代码、数据、bss和栈区域创建新的区域结构。所有这些 新的区域都是私有的、写时复制的。代码和数据区域被映射为a.out文件中的.text 和.data区。bss区域是请求二进制零的，映射到匿名文件，其大小包含在a.out中。栈 和堆区域也是请求二进制零的，初始长度为零。图9-31概括了私有区域的不同映射。
•映射共享区域。如果a.out程序与共享对象（或目标）链接，比如标准C库libc. so,那么这些对象都是动态链接到这个程序的，然后再映射到用户虚拟地址空间中 的共享区域内。
•设置程序计数器（PC)。execve做的最后一件事情就是设置当前进程上下文中的程 序计数器，使之指向代码区域的人口点。
下一次调度这个进程时，它将从这个入口点开始执行。Linux将根据需要换人代码和 数据页面。
		
		运行时堆 (通过malloc分配的）
		未初始化的数据（.bSS)
.data		已初始化的数据（.data)
.text		代码（.text)
		
私有的，请求二进制零的
共享的，文件提供的
，私有的，请求二进制零的 •私有的，请求二进制零的 •私有的，文件提供的
图9-31加载器是如何映射用户地址空间的区域的
9. 8. 4使用mmap函数的用户级内存映射
Linux进程可以使用_P函数来创建新的虚拟内存区域，并将对象映射到这些区域中。
#include <unistd.li>
#include <sys/mman.h>
void *mmap(void *start, size_t length, int prot, int flags, int fd, off_t offset);
返回：若成功时则为指向映射区域的指针，若出错則为MAP_FAILED(-l)e
586 第二部分在系统上运行程序
mrnap函数要求内核创建一个新的虚拟内存区域，最好是从地址start开始的一个区 域，并将文件描述符fd指定的对象的一个连续的片（chunk)映射到这个新的区域。连续的 对象片大小为length字节，从距文件开始处偏移量为offset字节的地方开始。start 地址仅仅是一个暗示，通常被定义为NULL。为了我们的目的，我们总是假设起始地址为 NULL。图9-32描述了这些参数的意义。
文件描述符fd指定	进程虚拟内存
的磁盘文件
图9-32 rnmap参数的可视化解释
参数prot包含描述新映射的虚拟内存区域的访问权限位（即在相应区域结构中的vm_ prot 位）。
•	PROT_EXEC:这个区域内的页面由可以被CPU执行的指令组成。
•	PROT_READ:这个区域内的页面可读。
•	PR〇T_WRITE:这个区域内的页面可写。
*PROT_NONE:这个区域内的页面不能被访问。
参数flags由描述被映射对象类型的位组成。如果设置了 MAP_ANON标记位，那 么被映射的对象就是一个匿名对象，而相应的虚拟页面是请求二进制零的。MAP_PRI-VATE表示被映射的对象是一个私有的、写时复制的对象，而MAP_SHARED表示是一 个共享对象。例如
bufp = Mmap(NULL, size, PR0T_READ, MAP.PRIVATE|MAP.ANQN, 0, 0);
让内核创建一个新的包含Size字节的只读、私有、请求二进制零的虚拟内存区域^ 如果调用成功，那么bufp包含新区域的地址。
murnnap函数删除虚拟内存的区域：
#include <unistd.h>
#include <sys/mman.h>
int munmapCvoid *start, size_t length);
返回：若成功则为0，若出错则为一1,
munmap函数删除从虚拟地址start开始的，由接下来length字节组成的区域。接 下来对已删除区域的引用会导致段错误。
练习题9. 5编写一个C程序mmapcopy.c，使用mmap将一个任意大小的磁盘文件复 制到stdout。输入文件的名字必须作为一个命令行参数来传递。
第9章虚拟内存 587
9.9动态内存分配
虽然可以使用低级的mmap和munmap函数来创建和删除虚拟内存的区域，但是C程 序员还是会觉得当运行时需要额外虚拟内存时，用动态内存分配器（dynamic memory allo-
cator)更方便，也有更好的可移植性。
动态内存分配器维护着一个进程的虚拟内存区 域，称为堆（heap)(见图9-33)。系统之间细节不同， 但是不失通用性，假设堆是一个请求二进制零的区 域，它紧接在未初始化的数据区域后开始，并向上生 长（向更高的地址）。对于每个进程，内核维护着一个 变量brk(读做“break”），它指向堆的顶部。
分配器将堆视为一组不同大小的块（block)的集合 来维护。每个块就是一个连续的虚拟内存片（chunk)， 要么是已分配的，要么是空闲的。已分配的块显式地 保留为供应用程序使用=■空闲块可用来分配。空闲块 保持空闲，直到它显式地被应用所分配。一个已分配 的块保持已分配状态，直到它被释放，这种释放要么 是应用程序显式执行的，要么是内存分配器自身隐式 执行的。
分配器有两种基本风格。两种风格都要求应用显 式地分配块。它们的不同之处在于由哪个实体来负责 释放已分配的块。
用户栈
共享库的内存映射区域
堆向上生长
堆
未初始化的数据（.bss)
已初始化的数据（.data)
代码（.text)
•-堆顶 (brk指针）
图9-33 堆
•显式分配器（explicit allocator)，要求应用显式地释放任何已分配的块。例如，C标 准库提供一种叫做malloc程序包的显式分配器。C程序通过调用malloc函数来
.分配一个块，并通过调用free函数来释放一个块。C++中的new和delete操作 符与C中的malloc和f ree相当。
•隐式分配器（implicit allocator),另一方面，要求分配器检测一个已分配块何时不再 被程序所使用，那么就释放这个块。隐式分配器也叫做垃圾收集器（garbage collector)， 而自动释放未使用的已分配的块的过程叫做垃圾收集 （garbage collection)。 例如，诸如Usp、ML以及Java之类的高级语言就依赖垃圾收集来释放已分配 的块D
本节剩下的部分讨论的是显式分配器的设计和实现。我们将在9. 10节中讨论隐式分 配器。为了更具体，我们的讨论集中于管理堆内存的分配器。然而，应该明白内存分配是 一个普遍的概念，可以出现在各种上下文中。例如，图形处理密集的应用程序就经常使用 标准分配器来要求获得一大块虚拟内存，然后使用与应用相关的分配器来管理内存，在该 块中创建和销毁图形的节点。
9.	9. 1 malloc 和 free 函数
C标准库提供了一个称为malloc程序包的显式分配器。程序通过调用malloc函数 来从堆中分配块。
588 第二部分在系统上运行程序
#include <stdlib.h> void *malloc(size_t size);
返回：若成功则为已分配块的指针，若出错则为NULL。
malloc函数返回一个指针，指向大小为至少size字节的内存块，这个块会为可能包 含在这个块内的任何数据对象类型做对齐。实际中，对齐依赖于编译代码在32位模式 (gcc-m32)还是64位模式（默认的）中运行。在32位模式中，malloc返回的块的地址总 是8的倍数。在64位模式中，该地址总是16的倍数。
旁注
回想一下在第3章中我们对机器代码的讨论，Intel将4字节对象称为双字。然而，在 本节中，我们会假设字是4字节的对象，而双字是8字节的对象，这和传统术语是一 致的。
如果malloc遇到问题(例如，程序要求的内存块比可用的虚拟内存还要大），那么它 就返回NULL，并设置errno。malloc不初始化它返回的内存。那些想要已初始化的动 态内存的应用程序可以使用calloc，calloc是一个基于malloc的痩包装函数，它将分 配的内存初始化为零。想要改变一个以前已分配块的大小，可以使用realloc函数。
动态内存分配器，例如malloc，可以通过使用mmap和munmap函数，显式地分配和 释放堆内存，或者述可以使用sbrk函数：
#include <unistd.li> void *sbrk(intptr_t incr);
返回：若成功则为旧的brk指针，若出错則为一1。
sbrk函数通过将内核的brk指针增加incr来扩展和收缩堆。如果成功，它就返回 brk的旧值，否则，它就返回_1，并将errriQ设置为ENOMEN^如果incr为零，那么 sbrk就返回brk的当前值。用一个为负的incr来调用sbrk是合法的，而且很巧妙，因 为返回值(brk的旧值）指向距新堆顶向上absUncr)字节处。
程序是通过调用free函数来释放已分配的堆块。
#include <stdlib.li>	
void free(void *ptr);	返回：无。
ptr参数必须指向一个从malloc、calloc或者realloc获得的已分配块的起始位 置。如果不是，那么free的行为就是未定义的。更糟的是，既然它什么都不返回，free 就不会告诉应用出现了错误。就像我们将在9. 11节里看到的，这会产生一些令人迷惑的 运行时错误。
图9-34展示了一个malloc和free的实现是如何管理一个C程序的16字的（非常)小 的堆的。每个方框代表了一个4字节的字。粗线标出的矩形对应于已分配块（有阴影的)和 空闲块(无阴影的）。初始时，堆是由一个大小为16个字的、双字对齐的、空闲块组成的。 (本节中，我们假设分配器返回的块是8字节双字边界对齐的。）
第9章虚拟内存 589
•图9-34a:程序请求一个4字的块。malloc的响应是：从空闲块的前部切出一个4 字的块，并返回一个指向这个块的第一字的指针。
•图9-34b:程序请求一个5字的块。 malloc的响应是：从空闲块的前部分 配一个6字的块。在本例中，malloc 在块里填充了一个额外的字，是为了 保持空闲块是双字边界对齐的。
*图9-34c:程序请求一个6字的块，而 malloc就从空闲块的前部切出一个6 字的块。
•图9-34d:程序释放在图9-34b中分配
a) pi = malloc (4*sizeof (int))
b)p2 = malloc{5*sizeof(int))
I I__________________I_________________
I I I I i I I I I B I I I II I I I
的那个6字的块。注意，在调用free 返回之后，指针p2仍然指向被释放了 的块。应用有责任在它被一个新的 malloc调用重新初始化之前，不再使 用p2。
♦图9-34e:程序请求一个2字的块。在 这种情况中，malloc分配在前一步中 被释放了的块的一部分，并返回一个 指向这个新块的指针。
9.9.2为什么要使用动态内存分配
c)p3 = malloc(6*sizeof(int)) p1	p2	p3
d)	free (p2) p1	p2 p4
i w
e)	p4 = malloc (2*sizeof (int))
图9-34用malloc和free分配和释放块D每个 方框对应于一个字。每个粗线标出的矩 形对应于一个块。阴影部分是已分配的 块。已分配的块的填充区域是深阴影的。 无阴影部分是空闲块。堆地址是从左往 右增加的
程序使用动态内存分配的最重要的原因 是经常直到程序实际运行时，才知道某些数
据结构的大小。例如，假设要求我们编写一个C程序，它读一个n个ASCII码整数的链 表，每一行一个整数，从stdin到一个C数组。输人是由整数?!和接下来要读和存储到 数组中的《个整数组成的。最简单的方法就是静态地定义这个数组，它的最大数组大小是 硬编码的：
1	#include "csapp.li"
2	#define MAXN 15213
3
4	int array[MAXN];
5
6	int main()
7	{
8	int i, n;
9
10	scanf("%d",	&n);
11	if (n > MAXN)
12	app_error("Input file too big");
13	for (i = 0;	i	<	n; i++)
14	scanf(n%d", &array[i]);
15	exit(0);
16
590 第二部分在系统上运行程序
像这样用硬编码的大小来分配数组通常不是一种好想法。MAXN的值是任意的，与 机器上可用的虚拟内存的实际数量没有关系。而且，如果这个程序的使用者想读取一个比 MAXN大的文件，唯一的办法就是用一个更大的MAXN值来重新编译这个程序。虽然对 于这个简单的示例来说这不成问题，但是硬编码数组界限的出现对于拥有百万行代码和大 量使用者的大型软件产品而言，会变成一场维护的噩梦。
一种更好的方法是在运行时，在已知了〃的值之后，动态地分配这个数组。使用这种 方法，数组大小的最大值就只由可用的虚拟内存数量来限制了。
#include "csapp.h"
int mainO {
int *array， i, n;
scanf("%d", &n);
array = (int *)Malloc(n * sizeof(int)); for (i = 0; i < n; i++)
scanf("%d", &array[i]); free(array); exit(0);
>
动态内存分配是一种有用而重要的编程技术。然而，为了正确而高效地使用分配器， 程序员需要对它们是如何工作的有所了解。我们将在9. 11节中讨论因为不正确地使用分 配器所导致的一些可怕的错误。
9.9.	3分配器的要求和目标
显式分配器必须在一些相当严格的约束条件下工作：
•处理任意请求序列。一个应用可以有任意的分配请求和释放请求序列，只要满足约 束条件：每个释放请求必须对应于一个当前已分配块，这个块是由一个以前的分配 请求获得的。因此，分配器不可以假设分配和释放请求的顺序。例如，分配器不能 假设所有的分配请求都有相匹配的释放请求，或者有相匹配的分配和空闲请求是嵌 套的。
•立即响应请求。分配器必须立即响应分配请求。因此，不允许分配器为了提高性能 重新排列或者缓冲请求。
*只使用堆。为了使分配器是可扩展的，分配器使用的任何非标量数据结构都必须保 存在堆里。
*对齐块（对齐要求）。分配器必须对齐块，使得它们可以保存任何类型的数据对象。 •不修改已分配的块。分配器只能操作或者改变空闲块。特别是，一旦块被分配了， 就不允许修改或者移动它了。因此，诸如压缩已分配块这样的技术是不允许使 用的。
在这些限制条件下，分配器的编写者试图实现吞吐率最大化和内存使用率最大化，而 这两个性能目标通常是相互冲突的。
•目标1:最大化吞吐率。假定n个分配和释放请求的某种序列：
R〇 tR\»yRk ♦ *•* yRn-i
4
5
6
7
8 9
10
第9章虚拟内存 591
我们希望一个分配器的吞吐率最大化，吞吐率定义为每个单位时间里完成的请求 数。例如，如果一个分配器在1秒内完成500个分配请求和500个释放请求，那么 它的吞吐率就是每秒1000次操作。一般而言，我们可以通过使满足分配和释放请 求的平均时间最小化来使吞吐率最大化。正如我们会看到的，开发一个具有合理性 能的分配器并不困难，所谓合理性能是指一个分配请求的最糟运行时间与空闲块的 数量成线性关系，而一个释放请求的运行时间是个常数。
*目标2:最大化内存利用率。天真的程序员经常不正确地假设虚拟内存是一个无限 的资源。实际上，一个系统中被所有进程分配的虚拟内存的全部数量是受磁盘上交 换空间的数量限制的。好的程序员知道虚拟内存是一个有限的空间，必须高效地使 用。对于可能被要求分配和释放大块内存的动态内存分配器来说，尤其如此。
有很多方式来描述一个分配器使用堆的效率如何。在我们的经验中，最有用的标准是 峰值利用率（peak utilization)。像以前一样，我们给定?1个分配和释放请求的某种顺序
■R〇，jRi，…，尺4，…，尺„-i
如果一个应用程序请求一个f字节的块，那么得到的已分配块的有效载荷（payload)是户 字节。在请求私完成之后，聚集有效载荷（aggregate payload)表示为P,，为当前已分配的 块的有效载荷之和，而^^表示堆的当前的（单调非递减的）大小。
那么，前々+ 1个请求的峰值利用率，表示为K，可以通过下式得到：
TT _ maxi<kPi Uk = Hk
那么，分配器的目标就是在整个序列中使峰值利用率最大化。正如我们将要看到的， 在最大化吞吐率和最大化利用率之间是互相牵制的。特別是，以堆利用率为代价，很容易 编写出吞吐率最大化的分配器。分配器设计中一个有趣的挑战就是在两个目标之间找到一 个适当的平衡。
旁注
我们可以通过让成为前々+ 1个请求的最高峰，从而使得在我们对C7*的定义中 放宽单调非递减的假设，并且允许堆增长和降低。
9. 9. 4 碎片
造成堆利用率很低的主要原因是一种称为碎片（fragmentation)的现象，当虽然有未使 用的内存但不能用来满足分配请求时，就发生这种现象。有两种形式的碎片：内部碎片 (internal fragmentation)和夕卜部碎片（external fragmentation)。
内部碎片是在一个已分配块比有效载荷大时发生的。很多原因都可能造成这个问题 例如，一个分配器的实现可能对已分配块强加一个最小的大小值，而这个大小要比某个请 求的有效载荷大。或者，就如我们在图9-34b中看到的，分配器可能增加块大小以满足对 齐约束条件。
内部碎片的量化是简单明了的。它就是已分配块大小和它们的有效载荷大小之差的 和。因此，在任意时刻，内部碎片的数量只取决于以前请求的模式和分配器的实现方式。
外部碎片是当空闲内存合计起来足够满足一个分配请求，但是没有一个单独的空闲块 足够大可以来处理这个请求时发生的。例如，如果图9-34e中的请求要求6个字，而不是 2个字，那么如果不向内核请求额外的虚拟内存就无法满足这个请求，即使在堆中仍然有
592 第二部分在系统上运行程序
6个空闲的字。问题的产生是由于这6个字是分在两个空闲块中的。
外部碎片比内部碎片的量化要困难得多，因为它不仅取决于以前请求的模式和分配器 的实现方式，还取决于将来请求的模式。例如，假设在々个请求之后，所有空闲块的大小 都恰好是4个字。这个堆会有外部碎片吗？答案取决于将来请求的模式。如果将来所有的 分配请求都要求小于或者等于4个字的块，那么就不会有外部碎片。另一方面，如果有一 个或者多个请求要求比4个字大的块，那么这个堆就会有外部碎片。
因为外部碎片难以量化且不可能预测，所以分配器通常采用启发式策略来试图维持少 量的大空闲块，而不是维持大量的小空闲块。
9. 9. 5 实现问题
可以想象出的最简单的分配器会把堆组织成一个大的字节数组，还有一个指针P，初 始指向这个数组的第一个字节。为了分配size个字节，malloc将P的当前值保存在栈 里，将P增加size，并将p的旧值返回到调用函数。free只是简单地返回到调用函数， 而不做其他任何事情。
这个简单的分配器是设计中的一种极端情况。因为每个mail〇c和free只执行很少 量的指令，吞吐率会极好。然而，因为分配器从不重复使用任何块，内存利用率将极差。 一个实际的分配器要在吞吐率和利用率之间把握好平衡，就必须考虑以下几个问题：
•空闲块组织：我们如何记录空闲块？
*放置：我们如何选择一个合适的空闲块来放置一个新分配的块？
*分割：在将一个新分配的块放置到某个空闲块之后，我们如何处理这个空闲块中的 剩余部分？
*合并：我们如何处理一个刚刚被释放的块？
本节剩下的部分将更详细地讨论这些问题。因为像放置、分割以及合并这样的基本技 术贯穿在许多不同的空闲块组织中，所以我们将在一种叫做隐式空闲链表的简单空闲块组 织结构中来介绍它们。
9. 9. 6 隐式空闲链表
任何实际的分配器都需要一些数据结构，允许它来区别块边界，以及区别已分配块和 空闲块。大多数分配器将这些信息嵌人块本身。一个简单的方法如图9-35所示。
31 头部	3 2 10
\ a = 1:已分配的 少a = 0:空闲的
块大小包括头部、
有效载荷和所有的填充
malloc返回一个指针，	块大小	00a
它指向有效载荷的开始处 _	有效载荷	
	(只包括已分配的块）	
	填充（可选）	
图9-35	—个简单的堆块的格式
在这种情况中，一个块是由一个字的头部、有效载荷，以及可能的一些额外的填充组 成的。头部编码了这个块的大小（包括头部和所有的填充），以及这个块是已分配的还是空
第9章虚拟内存 593
闲的。如果我们强加一个双字的对齐约束条件，那么块大小就总是8的倍数，且块大小的 最低3位总是零。因此，我们只需要内存大小的29个高位，释放剩余的3位来编码其他 信息。在这种情况中，我们用其中的最低位（已分配位)来指明这个块是已分配的还是空闲 的。例如，假设我们有一个已分配的块，大小为24(0x18)字节。那么它的头部将是
0x00000018 I 0x1 = 0x00000019
类似地，一个块大小为40(0x28)字节的空闲块有如下的头部:
0x00000028 | 0x0 = 0x00000028
头部后面就是应用调用mall〇c时请求的有效载荷。有效载荷后面是一片不使用的填 充块，其大小可以是任意的。需要填充有很多原因。比如，填充可能是分配器策略的一部 分，用来对付外部碎片。或者也需要用它来满足对齐要求。
假设块的格式如图9-35所示，我们可以将堆组织为一个连续的已分配块和空闲块的 序列，如图9-36所示。
未使用的 堆的 起始 位置
_8,0		16/1			誠 32/0								16/1			
																
双字
对齐的
图9-36用隐式空闲链表来组织堆。阴影部分是已分配块。没有阴影的部分是空闲块。 头部标记为（大小（字节）/已分配位）
我们称这种结构为隐式空闲链表，是因为空闲块是通过头部中的大小字段隐含地连接着 的。分配器可以通过遍历堆中所有的块，从而间接地遍历整个空闲块的集合。注意，我们需要 某种特殊标记的结束块，在这个示例中，就是一个设置了已分配位而大小为零的终止头部(terminating header)。 （ 就像我们将在 9. 9.12 节中看到的，设置已分配位简化了空闲块的合并。） 隐式空闲链表的优点是简单。显著的缺点是任何操作的开销，例如放置分配的块，要 求对空闲链表进行搜索，该搜索所需时间与堆中已分配块和空闲块的总数呈线性关系。
很重要的一点就是意识到系统对齐要求和分配器对块格式的选择会对分配器上的最小 块大小有强制的要求。没有已分配块或者空闲块可以比这个最小值还小。例如，如果我们 假设一个双字的对齐要求，那么每个块的大小都必须是双字（8字节）的倍数。因此，图9-35中的块格式就导致最小的块大小为两个字：一个字作头，另一个字维持对齐要求。即 使应用只请求一字节，分配器也仍然需要创建一个两字的块。
0练习题9.6确定下面malloc请求序列产生的块大小和头部值。假设：1)分配器保 持双字对齐，并且使用块格式如图9-35中所示的隐式空闲链表。2)块大小向上舍入 为最接近的8字节的倍数。
请求	块大小（十进制字节）	块头部（十六进制）
malloc(1)		
malloc(5)		
malloc(12)		
malloc(13)		
9.9.7放置已分配的块
当一个应用请求一个6字节的块时，分配器搜索空闲链表，查找一个足够大可以放置
594 第二部分在系统上运行程序
所请求块的空闲块。分配器执行这种搜索的方式是由放置策略（placement policy)确定的。 一些常见的策略是首次适配（first fit)、下一次适配（next fit)和最佳适配（best fit)。
首次适配从头开始搜索空闲链表，选择第一个合适的空闲块。下一次适配和首次适配 很相似，只不过不是从链表的起始处开始每次搜索，而是从上一次查询结束的地方开始。 最佳适配检查每个空闲块，选择适合所需请求大小的最小空闲块。
首次适配的优点是它趋向于将大的空闲块保留在链表的后面。缺点是它趋向于在靠近 链表起始处留下小空闲块的“碎片”，这就增加了对较大块的搜索时间。下一次适配是由 Donald Knuth作为首次适配的一种代替品最早提出的，源于这样一个想法：如果我们上 一次在某个空闲块里已经发现了一个匹配，那么很可能下一次我们也能在这个剩余块中发 现匹配。下一次适配比首次适配运行起来明显要快一些，尤其是当链表的前面布满了许多 小的碎片时。然而，一些研究表明，下一次适配的内存利用率要比首次适配低得多。研究 还表明最佳适配比首次适配和下一次适配的内存利用率都要高一些。然而，在简单空闲链 表组织结构中，比如隐式空闲链表中，使用最佳适配的缺点是它要求对堆进行彻底的搜 索。在后面，我们将看到更加精细复杂的分离式空闲链表组织，它接近于最佳适配策略， 不需要进行彻底的堆搜索。
9.9.8分割空闲块	^
一旦分配器找到一个匹配的空闲块，它就必须做另一个策略决定，那就是分配这个空 闲块中多少空间。一个选择是用整个空闲块。虽然这种方式简单而快捷，但是主要的缺点 就是它会造成内部碎片。如果放置策略趋向于产生好的匹配，那么额外的内部碎片也是可 以接受的。
然而，如果匹配不太好，那么分配器通常会选择将这个空闲块分割为两部分。第一部 分变成分配块，而剩下的变成一个新的空闲块。图9-37展示了分配器如何分割图9-36中 8个字的空闲块，来满足一个应用的对堆内存3个字的请求。
图9-37分割一个空闲块，以满足一个3个字的分配请求。阴影部分是已分配块， 没有阴影的部分是空闲块，头部标记为（大小（字节）/已分配位）
9.9.9获取额外的堆内存
如果分配器不能为请求块找到合适的空闲块将发生什么呢？ 一个选择是通过合并那些在 内存中物理上相邻的空闲块来创建一些更大的空闲块（在下一节中描述）。然而，如果这样还 是不能生成一个足够大的块，或者如果空闲块已经最大程度地合并了，那么分配器就会通过 调用sbrk函数，向内核请求额外的堆内存。分配器将额外的内存转化成一个大的空闲块， 将这个块插入到空闲链表中，然后将被请求的块放置在这个新的空闲块中。
9.9.10合并空闲块
当分配器释放一个已分配块时，可能有其他空闲块与这个新释放的空闲块相邻。这些 邻接的空闲块可能引起一种现象，叫做假碎片（fault fragmentation),就是有许多可用的
第9章虚拟内存 595
空闲块被切割成为小的、无法使用的空闲块。比如，图9-38展示了释放图9-37中分配的 块后得到的结果。结果是两个相邻的空闲块，每一个的有效载荷都为3个字。因此，接下 来一个对4字有效载荷的请求就会失败，即使两个空闲块的合计大小足够大，可以满足这 个请求。
图9-38假碎片的示例。阴影部分是已分配块。没有阴影的部分是空闲块。 头部标记为（大小(字节）/已分配位）
为了解决假碎片问题，任何实际的分配器都必须合并相邻的空闲块，这个过程称为合 并（coalescing)。这就出现了一个重要的策略决定，那就是何时执行合并。分配器可以选 择立即合并（immediate coalescing),也就是在每次一个块被释放时，就合并所有的相邻 块。或者它也可以选择推迟合并（deferred coalescing)，也就是等到某个稍晚的时候再合并 空闲块。例如，分配器可以推迟合并，直到某个分配请求失败，然后扫描整个堆，合并所 有的空闲块。
立即合并很简单明了，可以在常数时间内执行完成，但是对于某些请求模式，这种方 式会产生一种形式的抖动，块会反复地合并，然后马上分割。例如，在图9-38中，反复 地分配和释放一个3个字的块将产生大量不必要的分割和合并。在对分配器的讨论中，我 们会假设使用立即合并，但是你应该了解，快速的分配器通常会选择某种形式的推迟 合并。
9.9.	11带边界标记的合并
分配器是如何实现合并的？让我们称想要释放的块为当前块。那么，合并（内存中的） 下一个空闲块很简单而且高效。当前块的头部指向下一个块的头部，可以检查这个指针以 判断下—个块是否是空闲的。如果是，就将它的大小简单地加到当前块头部的大小上，这 两个块在常数时间内被合并。
但是我们该如何合并前面的块呢？给定一个带头部的隐式空闲链表，唯一的选择将是 搜索整个链表，记住前面块的位置，直到我们到达当前块。使用隐式空闲链表，这意味着 每次调用free需要的时间都与堆的大小成线性关系。即使使用更复杂精细的空闲链表组 织，搜索时间也不会是常数。
Kmith提出了一种聪明而通用的技术，叫做 边界标记(boundary tag)，允许在常数时间内进行 对前面块的合并。这种思想，如图9-39所示，是 在每个块的结尾处添加一个脚部（footer，边界标 记），其中脚部就是头部的一个副本。如果每个块 包括这样一个脚部，那么分配器就可以通过检查 它的脚部，判断前面一个块的起始位置和状态，
这个脚部总是在距当前块开始位置一个字的距离。
考虑当分配器释放当前块时所有可能存在的 情况：
块大小	a/f
有效载荷	
(只包括已分配的块）	
填充（可选）	
块大小	a/f
头部丨
001:已分配的 000:空闲的
脚部
图9-39使用边界标记的堆块的格式
596 第二部分在系统上运行程序
1)	前面的块和后面的块都是已分配的。
2)	前面的块是已分配的，后面的块是空闲的。
3)	前面的块是空闲的，而后面的块是已分配的。
4)	前面的和后面的块都是空闲的。
图9-40展示了我们如何对这四种情况进行合并。
ml	a
	
ml	a
n	a
	
n	a
m2	a
	
m2 | a	
图9-40使用边界标记的合并（情况1:前面的和后面块都已分配。情况2:前面块已分配，后面 块空闲。情况3:前面块空闲，后面块已分配.情况4:后面块和前面块都空闲）
在情况1中，两个邻接的块都是已分配的，因此不可能进行合并。所以当前块的状态 只是简单地从已分配变成空闲。在情况2中，当前块与后面的块合并。用当前块和后面块 的大小的和来更新当前块的头部和后面块的脚部。在情况3中，前面的块和当前块合并。 用两个块大小的和来更新前面块的头部和当前块的脚部•在情况4中，要合并所有的三个 块形成一个单独的空闲块，用三个块大小的和来更新前面块的头部和后面块的脚部。在每 种情况中，合并都是在常数时间内完成的。
边界标记的概念是简单优雅的，它对许多不同类型的分配器和空闲链表组织都是通用 的。然而，它也存在一个潜在的缺陷。它要求每个块都保持一个头部和一个脚部，在应用 程序操作许多个小块时，会产生显著的内存开销。例如，如果一个图形应用通过反复调用 malloc和free来动态地创建和销毁图形节点，并且每个图形节点都只要求两个内存字， 那么头部和脚部将占用每个已分配块的一半的空间。
幸运的是，有一种非常聪明的边界标记的优化方法，能够使得在已分配块中不再需要 脚部。回想一下，当我们试图在内存中合并当前块以及前面的块和后面的块时，只有在前 面的块是空闲时，才会需要用到它的脚部。如果我们把前面块的已分配/空闲位存放在当 前块中多出来的低位中，那么已分配的块就不需要脚部了，这样我们就可以将这个多出来 的空间用作有效载荷了。不过请注意，空闲块仍然需要脚部。
练习题9.7确定下面每种对齐要求和块格式的组合的最小的块大小。假设：隐式空 闲链表，不允许有效载荷为零，头部和脚部存放在4字节的字中。
第9章虚拟内存 597
对齐要求	已分配的块	空闲块	最小块大小（字节）
单字	头部和脚部	头部和脚部	
单字	头部，但是无脚部	头部和脚部	
双字	头部和脚部	头部和脚部	
双字	头部，但是没有脚部	头部和脚部	
9.9.〗2综合：实现一个简单的分配器
构造一个分配器是一件富有挑战性的任务。设计空间很大，有多种块格式、空闲链表 格式，以及放置、分割和合并策略可供选择。另一个挑战就是你经常被迫在类型系统的安 全和熟悉的限定之外编程，依赖于容易出错的指针强制类型转换和指针运算，这些操作都 属于典型的低层系统编程。
虽然分配器不需要大量的代码，但是它们也还是细微而不可忽视的。熟悉诸如 〇+或者Java之类高级语言的学生通常在他们第一次遇到这种类型的编程时，会遭遇 一个概念上的障碍。为了帮助你清除这个障碍，我们将基于隐式空闲链表，使用立即边 界标记合并方式，从头至尾地讲述一个简单分配器的实现。最大的块大小为232 = 4GB。 代码是64位干净的，即代码能不加修改地运行在32位（gcc-m32)或64位（gcc-m64)的 进程中。
1.通用分配器设计
我们的分配器使用如图9-41所示的memlib.c包所提供的一个内存系统模型。模型的 目的在于允许我们在不干涉已存在的系统层malloc包的情况下，运行分配器。
函数将对于堆来说可用的虚拟内存模型化为一个大的、双字对齐的字节 数组。在mem_heap和mem_brk之间的字节表7K已分配的虚拟内存-mem_brk之后的字 节表示未分配的虚拟内存。分配器通过调用mem_Sbrk函数来请求额外的堆内存，这个 函数和系统的sbrk函数的接口相同，而且语义也相同，除了它会拒绝收缩堆的请求。
■分配器包含在一个源文件中（mm.c)，用户可以编译和链接这个源文件到他们的应用之 中。分配器输出三个函数到应用程序：
1	extern int min_init(void);
2	extern void *mm_inalloc (size_t size);
3	extern void mm_free (void *ptr);
函数初始化分配器，如果成功就返回0，否则就返回一1。mm_malloc和mm_ free函^数与它们对应的系统函数有相同的接口和语义。分配器使用如图9-39所示的块格 式。最小块的大小为16字节。空闲链表组织成为一个隐式空闲链表，具有如图9-42所示 的恒定形式。
第一个字是一个双字边界对齐的不使用的填充字。填充后面紧跟着一个特殊的序言块 (prologue block)，这是一个8字节的已分配块，只由一个头部和一个脚部组成。序言块 是在初始化时创建的，并且永不释放。在序言块后紧跟的是零个或者多个由malloc或者 free调用创建的普通块。堆总是以一个特殊的结尾块（epilogue block)来结束，这个块是 一个大小为零的已分配块，只由一个头部组成。序言块和结尾块是一种消除合并时边界条 件的技巧。分配器使用一个单独的私有（static)全局变量（heap_liStp)，它总是指向序 言块。（作为一个小优化，我们可以让它指向下一个块，而不是这个序言块。）
598 第二部分在系统上运行程序
-------------------------------------------------------------------code/vm/malloc/memlib. c
1	/丰 Private global variables */
2	static	char	*mem_lieap;	/*	Points to	first byte of heap */
3	static	char	*mem_brk;	/*	Points to	last byte of heap plus	1 */
4	static	char	*mem_max_addr;	/*	Max legal	heap addr plus 1*/
5
6	/*
7	* mem_init - Initialize the memory system model
8	*/
9 void mem_iiiit(void.)
raem_iieap = (char *)Malloc(MAX_HEAP) j mem_brk = (char *)mem_lieap; mem_max_addr = (char *)(mem_lieap + MAX_HEAP);
17	* mem_sbrk - Simple model of the sbrk function. Extends the heap
18	* by incr bytes and returns the start address of the new area. In
19	* this model, the heap cannot be shrunk.	•
20	*/
21	void *mem_sbrk(int incr)
22	{
23	char *old_brk « mem_brk;
24
25	if ( (incr < 0) I I (Cmem.brk + incr) > mem_max_addr)) {
26	errno = ENOMEM;
27	fprintf(stderr, "ERROR: mem_sbrk failed. Ran out of memory.. An");
28	return (void *)-l;
29	>
30	mem_brk += incr;
31	return (void *)old_brk;
32	>
-----------------------------------------------------------------code/vm/malloc/memlib.c
图9-41 memlib.c:内存系统模型
10
n
12
13
14
15
16
/*
序言块
普通块1
普通块2
普通块^
结尾块hdr
双字
对齐的
static char *heap_listp
图9-42隐式空闲链表的恒定形式
2.操作空闲链表的基本常数和宏
图9-43展示了一些我们在分配器编码中将要使用的基本常数和宏。第2〜4行定义了 一些基本的大小常数：字的大小（WSIZE)和双字的大小（DSIZE)，初始空闲块的大小和扩 展堆时的默认大小（CHUNKSIZE)。
在空闲链表中操作头部和脚部可能是很麻烦的，因为它要求大量使用强制类型转换和指针 运算。因此，我们发现定义一小组宏来访问和遍历空闲链表是很有帮助的(第9〜25行)。PACK
第9章虚拟内存 599
宏(第9行)将大小和已分配位结合起来并返回一个值，可以把它存放在头部或者脚部中。
1
2
3
4
5
6
7
8 9
10
11
12
13
14
15
16
17
18
19
20 21 22
23
24
25
---------------------------------------------------------------code/vm/malloc/mm. c
/* Basic constants and macros */
#define WSIZE	4	/* Word and header/footer size (bytes) */
#define DSIZE	8	/* Double word size (bytes) */
#define CHUNKSIZE (1«12)	/* Extend heap by this amount (bytes) */
#define MAX(x, y) ((x) > (y)? (x) : (y))
/* Pack a size and allocated bit into a word */ #define PACK(size, alloc) ((size) I (alloc))
/* Read and write a word at address p */
#define GET(p)	(*(unsigned int *)(p))
#define PUT(p, val) (♦(■unsigned int *) (p) = (val))
/* Read the size and allocated fields from address p */
#define GET_SIZE(p) (GET(p) & ~0x7)
#define GET_ALLOC(p) (GET(p) & 0x1)
/* Given block ptr bp, compute address of its header and footer */ #define HDRP(bp)	((char *)(bp) - WSIZE)
#define FTRP(bp)	((char *)(bp) + GET_SIZE(HDRP(bp)) - DSIZE)
/* Given block ptr bp, compute address of next and previous blocks */
#define NEXT_BLKP(bp) ((char (bp) + GET_SIZE(((char *)(bp) - WSIZE))) #define PREV_BLKP(bp) ((char *)(bp) - GET_SIZE(((char *)(bp) - DSIZE))) ------------------------------------------------------------------code/vm/malloc/mm. c
图9-43操作空闲链表的基本常数和宏
GET宏（第12行)读取和返回参数P引用的字。这里强制类型转换是至关重要的。参 数1=典型地是一个（viod* )指针，不可以直接进行间接引用。类似地，PUT宏（第13行） 将val存放在参数p指向的字中。
GET_SIZE和GET_ALLOC宏（第16〜17行)从地址P处的头部或者脚部分别返回大 小和已分配位。剩下的宏是对块指针（block pointer，用bp表示）的操作，块指针指向第一 个有效载荷字节。给定一个块指针bp，HDRP和FTRP宏（第20〜21行)分别返回指向这 个块的头部和脚部的指针。NEXT_BLKP和PREV_BLKP宏(第24〜25行）分别返回指向 后面的块和前面的块的块指针。
可以用多种方式来编辑宏，以操作空闲链表。比如，给定一个指向当前块的指针bp， 我们可以使用下面的代码行来确定内存中后面的块的大小：
size_t size = GET_SIZE(HDRP(NEXT_BLKP(bp)));
3.创建初始空闲链表
在调用mm_malloc或者rnm_free之前，应用必须通过调用函数来初始化堆 (见图 9-44)。
函数从内存系统得到4个字，并将它们初始化，创建一个空的空闲链表(第4 〜10行）。然后它调用extendjieap函数（图9-45)，这个函数将堆扩展CHUNKSIZE字
600	第二部分在系统上运行程序
节，并且创建初始的空闲块。此刻，分配器已初始化了，并且准备好接受来自应用的分配
和释放请求。
---------------------------------------------------------code/vm/malloc/mm. c
1
2
3
4
5
6
7
8 9
10
11
12
13
14
15
16
int mm_init(void)
(void *)-l)
/* Alignment padding */
1)); /* Prologue header */
1)); /* Prologue footer */ PUT<heap_listp + (3*WSIZE), PACK(0, 1));	/* Epilogue header */
heap_listp += (2*WSIZE);
/* Extend the empty heap with a free block of CHUWKSIZE bytes */ if (extend_heap(CHUNKSIZE/WSIZE) == NULL) return -1; return 0;
-----------------------------------------------------------code/vm/malloc/mm.c
/* Create the initial empty heap */ if ((heap_listp = mem_sbrk(4*WSIZE))== return -1;
PUT(heap_listp, 0);
PUT(heap_listp + (1*WSIZE), PACK(DSIZE, PUT(heap_listp + (2*WSIZE), PACK(DSIZE,
1
2
3
4
5
6
7
8 9
10
11
12
13
14
15
16
17
18
图9-44皿n_init:创建带一个初始空闲块的堆
static void *extend_heap(size_t words)
char *bp; size_t size;
code/vm/malloc/mm.c
/* Allocate an even number of words to maintain alignment */ size = (words % 2) ? (uords+1) * WSIZE : words * WSIZE; if ((long)(bp = mem_sbrk(size)) ==-1) return NULL;
/* Initialize free block header/footer and the epilogue header */
PUT(HDRP(bp), PACK(size, 0));	/* Free block header */
PUT(FTEPCbp), PACKCsize, 0));	/* Free block footer */
PUT(HDRP(NEXT_BLKP(bp)), PAGK(0, 1)); /* New epilogue header */
/* Coalesce if the previous block was free */ return coalesce(bp);
-----------------------------------------------------------code/vm/malloc/mm.c
图9-45 extend__heap:用一个新的空闲块扩展堆
extend_heap函数会在两种不同的环境中被调用：1)当堆被初始化时；2)当 loc不能找到一个合适的匹配块时。为了保持对齐，extendjieap将请求大小向上舍人为 最接近的2字(8字节）的倍数，然后向内存系统请求额外的堆空间（第7〜9行）。
extendjieap函数的剩余部分(第12〜17行）有点儿微妙。堆开始于一个双字对齐的 边界，并且^次对extend_heap的调用都返回一个块，该块的大小是双字的整数倍。因 此，对rnern_Sbrk的每次调用都返回一个双字对齐的内存片，紧跟在结尾块的头部后面。 这个头部变成了新的空闲块的头部（第12行），并且这个片的最后一个字变成了新的结尾
第9章虚拟内存 601
块的头部(第14行）。最后，在很可能出现的前一个堆以一个空闲块结束的情况中，我们 调用coalesce函数来合并两个空闲块，并返回指向合并后的块的块指针(第17行）。
4.释放和合并块
应用通过调用itim_free函数(图9-46)，来释放一个以前分配的块，这个函数释放所请求 的块(bP)，然后使用9. 9. 11节中描述的边界标记合并技术将之与邻接的空闲块合并起来。 ---------------------------------code/vm/malloc/mm. c
1	void mm_free(void *bp)
2	{
3	size_t size =	GET_SIZE(HDRP(bp));
4
5	PUT(HDRP(bp),	PACK(size,	0));
6	PUTCFTRP(bp),	PACK(size,	0));
7	coalesce(bp);
8	>
10	static void *coalesce(void *bp) i			
12	size.t prev_alloc = GET_ALLOC(FTEP(PREV_BLKP(bp)));			
13	size_t next.alloc = GET_ALLOC(HDRP(NEXT_BLKP(bp)));			
14	size-t size = GET-SIZE(HDRP(bp));			
16	if (prev_alloc && next_alloc) {	/*	Case 1	*/
17	return bp;			
18	>			
19				
20	else if (prev_alloc && !next_alloc) {	/*	Case 2	*/
21	size += GET_SIZE(HDRP(NEXT_BLKP(bp)));			
22	PUTCHDEPCbp), PACK(size, 0));			
23	PUT(FTRP(bp), PACK(size.O));			
24	>			
25				
26	else if (!prev_alloc && next_alloc) {	h	Case 3	*/
27	size += GET_SIZE(HDRP(PREV_BLKP(bp)));			
28	PUT(FTRPCbp), PACK(size, 0));			
29	PUT(HDRP(PREV_BLKP(bp)), PACK(size, 0));			
30	bp = PREV_BLKP(bp);			
31	>			
32				
33	else {	/*	Case 4	*/
34	size += GET_SIZE(HDRP(PREV_BLKP(bp)))	+		
35	GET_SIZE(FTRP(NEXT_BLKP(bp)));			
36	PUT(HDRP(PREV_BLKP(bp)), PACK(size, 0));			
37	PUT(FTRP(NEXT_BLKP(bp)), PACK(size, 0));			
B8	bp = PREV.BLKP(bp);			
39	>			
40	return bp;			
41	>			
-------------------------------------code/vm/malloc/mm. c
图9-46 __free:释放一个块，并使用边界标记合并将之与所有的邻接空闲块在常数时间内合并
602	第二部分在系统上运行程序
coalesce函数中的代码是图9-40中勾画的四种情况的一种简单直接的实现。这里也 有一个微妙的方面。我们选择的空闲链表格式（它的序言块和结尾块总是标记为已分配)允 许我们忽略潜在的麻烦边界情况，也就是，请求块bP在堆的起始处或者是在堆的结尾处。 如果没有这些特殊块，代码将混乱得多，更加容易出错，并且更慢，因为我们将不得不在 每次释放请求时，都去检查这些并不常见的边界情况。
5.分配块
一个应用通过调用__malloc函数（见图9-47)来向内存请求大小为size字节的块。 在检查完请求的真假之后，分配器必须调整请求块的大小，从而为头部和脚部留有空间， 并满足双字对齐的要求。第12〜13行强制了最小块大小是16字节：8字节用来满足对齐 要求，而另外8个用来放头部和脚部。对于超过8字节的请求（第15行），一般的规则是 加上开销字节，然后向上舍入到最接近的8的整数倍。
-----------------------------------------------------------code/vm/malloc/mm.c
1	void *mm_malloc(size_t size)
2
3
4
5
6
7	/*	Ignore spurious requests */
8	if	(size	==	0)
9	return NULL;
10
n	/★ Adjust block size to include overhead and alignment reqs. */
12	if	(size	<=	DSIZE)
13	asize = 2*DSIZE;
14	else
15	asize = DSIZE * ((size + (DSIZE) + (DSIZE-1)) / DSIZE);
16
17
18
19
20 21 22
23	/* No fit found. Get more memory and place the block */
24	extendsize = MAX(asize,CHUNKSIZE);
25	if ((bp = extend_tieap(exteiidsize/WSIZE)) == NULL)
26	return NULL;
27	place(bp， asize);
28	return bp;
29	>
/* Search, the free list for a fit */ if ((bp = find_f it (asize)) != NULL) ■( place(bp, asize); return bp;
size.t asize;	/* Adjusted block size */
size.t extendsize; /* Amount to extend heap if no fit */
char *bp;
code/vm/malloc/mm.c
图9-47 mm_malloc:从空闲链表分配一个块
一旦分配器调整了请求的大小，它就会搜索空闲链表，寻找一个合适的空闲块(第18 行）。如果有合适的，那么分配器就放置这个请求块，并可选地分割出多余的部分(第19 行），然后返回新分配块的地址。
第9章虚拟内存 603
如果分配器不能够发现一个匹配的块，那么就用一个新的空闲块来扩展堆（第24〜26 行），把请求块放置在这个新的空闲块里，可选地分割这个块（第27行），然后返回一个指 针，指向这个新分配的块。
^练习题9. 8为9.9. 12节中描述的简单分配器实现一个find_fit函数。
static void *find_fit Csize_t asize)
你的解答应该对隐式空闲链表执行首次适配搜索。
练习题9. 9为示例的分配器编写一个place函数。 static void place(void *bp, size_t asize)
你的解答应该将请求块放置在空闲块的起始位置，只有当剩余部分的大小等于或 者超出最小块的大小时，才进行分割。
9. 9. 13 显式空闲链表
隐式空闲链表为我们提供了一种介绍一些基本分配器概念的简单方法。然而，因为块 分配与堆块的总数呈线性关系，所以对于通用的分配器，隐式空闲链表是不适合的（尽管 对于堆块数量预先就知道是很小的特殊的分配器来说它是可以的）。
一种更好的方法是将空闲块组织为某种形式的显式数据结构。因为根据定义，程序不 需要一个空闲块的主体，所以实现这个数据结构的指针可以存放在这些空闲块的主体里 面。例如，堆可以组织成一个双向空闲链表，在每个空闲块中，都包含一个pred(前驱） 和succ(后继）指针，如图9-48所示D
31
块大小	a/f	头部	块大小	a/f
			pred (祖先）	
有效载荷			SUCC (后继）	
				
填充（可选）			填充（可选）	
块大小	a/f	脚部	块大小	a/f
头部
、原来的有效载荷
脚部
a)分配块
b)空闲块
图9-48使用双向空闲链表的堆块的格式
使用双向链表而不是隐式空闲链表，使首次适配的分配时间从块总数的线性时间减少 到了空闲块数量的线性时间。不过，释放一个块的时间可以是线性的，也可能是个常数， 这取决于我们所选择的空闲链表中块的排序策略。
一种方法是用后进先出（LIFO)的顺序维护链表，将新释放的块放置在链表的开始处。 使用LIFO的顺序和首次适配的放置策略，分配器会最先检查最近使用过的块。在这种情 况下，释放一个块可以在常数时间内完成。如果使用了边界标记，那么合并也可以在常数 时间内完成。
另一种方法是按照地址顺序来维护链表，其中链表中每个块的地址都小于它后继的地 址。在这种情况下，释放一个块需要线性时间的搜索来定位合适的前驱^平衡点在于，按
604	第二部分在系统上运行程序
照地址排序的首次适配比LIFO排序的首次适配有更高的内存利用率，接近最佳适配的利 用率。
一般而言，显式链表的缺点是空闲块必须足够大，以包含所有需要的指针，以及头部 和可能的脚部。这就导致了更大的最小块大小，也潜在地提高了内部碎片的程度。
9.9.14分离的空闲链表
就像我们已经看到的，一个使用单向空闲块链表的分配器需要与空闲块数量呈线性关 系的时间来分配块。一种流行的减少分配时间的方法，通常称为分离存储（segregated storage),就是维护多个空闲链表，其中每个链表中的块有大致相等的大小。一般的思路 是将所有可能的块大小分成一些等价类，也叫做大小类（size class)。有很多种方式来定义 大小类。例如，我们可以根据2的幂来划分块大小：
{1}, {2}，{3,4}，{5 〜8},…，{1025 〜2048} ,{2049 〜4096} ,{4097 〜〇〇}
或者我们可以将小的块分派到它们自己的大小类里，而将大块按照2的幂分类：
{1}, {2}，{3}，…，{1023} ,{1024} ,{1025 〜2048} ,{2049 〜4096} ,{4097 ~
分配器维护着一个空闲链表数组，每个大小类一个空闲链表，按照大小的升序排列。 当分配器需要一个大小为《的块时，它就搜索相应的空闲链表。如果不能找到合适的块与 之匹配，它就搜索下一个链表，以此类推。
有关动态内存分配的文献描述了几十种分离存储方法，主要的区别在于它们如何定义 大小类，何时进行合并，何时向操作系统请求额外的堆内存，是否允许分割，等等。为了 使你大致了解有哪些可能性，我们会描述两种基本的方法：简单分离存储（simple segregated storage) 和分离适配 （segregated fit)。
1.简单分离存储
使用简单分离存储，每个大小类的空闲链表包含大小相等的块，每个块的大小就是这 个大小类中最大元素的大小。例如，如果某个大小类定义为U7〜32}，那么这个类的空闲 链表全由大小为32的块组成。
为了分配一个给定大小的块，我们检查相应的空闲链表。如果链表非空，我们简单地 分配其中第一块的全部。空闲块是不会分割以满足分配请求的。如果链表为空，分配器就 向操作系统请求一个固定大小的额外内存片（通常是页大小的整数倍），将这个片分成大小 相等的块，并将这些块链接起来形成新的空闲链表。要释放一个块，分配器只要简单地将 这个块插人到相应的空闲链表的前部。
这种简单的方法有许多优点。分配和释放块都是很快的常数时间操作。而且，每个片 中都是大小相等的块，不分割，不合并，这意味着每个块只有很少的内存开销。由于每个 片只有大小相同的块，那么一个已分配块的大小就可以从它的地址中推断出来。因为没有 合并，所以已分配块的头部就不需要一个已分配/空闲标记。因此已分配块不需要头部， 同时因为没有合并，它们也不需要脚部。因为分配和释放操作都是在空闲链表的起始处操 作，所以链表只需要是单向的，而不用是双向的。关键点在于，在任何块中都需要的唯一 字段是每个空闲块中的一个字的succ指针，因此最小块大小就是一个字.
一个显著的缺点是，简单分离存储很容易造成内部和外部碎片。因为空闲块是不会被 分割的，所以可能会造成内部碎片。更糟的是，因为不会合并空闲块，所以某些引用模式 会引起极多的外部碎片（见练习题9. 10)。
^练习题9. 10描述一个在基于简单分离存储的分配器中会导致严重外部碎片的引用模式。
第9章虚拟内存 605
2.	分离适配
使用这种方法，分配器维护着一个空闲链表的数组。每个空闲链表是和一个大小类相 关联的，并且被组织成某种类型的显式或隐式链表。每个链表包含潜在的大小不同的块， 这些块的大小是大小类的成员。有许多种不同的分离适配分配器。这里，我们描述了一种 简单的版本。
为了分配一个块，必须确定请求的大小类，并且对适当的空闲链表做首次适配，査找 一个合适的块。如果找到了一个，那么就（可选地)分割它，并将剩余的部分插人到适当的 空闲链表中。如果找不到合适的块，那么就搜索下一个更大的大小类的空闲链表。如此重 复，直到找到一个合适的块。如果空闲链表中没有合适的块，那么就向操作系统请求额外 的堆内存，从这个新的堆内存中分配出一个块，将剩余部分放置在适当的大小类中。要释 放一个块，我们执行合并，并将结果放置到相应的空闲链表中。
分离适配方法是一种常见的选择，C标准库中提供的GNU malloc包就是采用的这种 方法，因为这种方法既快速，对内存的使用也很有效率。搜索时间减少了，因为搜索被限 制在堆的某个部分，而不是整个堆。内存利用率得到了改善，因为有一个有趣的事实：对 分离空闲链表的简单的首次适配搜索，其内存利用率近似于对整个堆的最佳适配搜索的内 存利用率。
3.	伙伴系统
伙伴系统(buddy system)是分离适配的一种特例，其中每个大小类都是2的幂。基本 的思路是假设一个堆的大小为个字，我们为每个块大小2A维护一个分离空闲链表，其 中请求块大小向上舍人到最接近的2的幂。最开始时，只有一个大小为2m个字 的空闲块。
为了分配一个大小为V的块，我们找到第一个可用的、大小为W的块，其中 如果那么我们就完成了。否则，我们递归地二分割这个块，直到）=々。当我们进行这 样的分割时，每个剩下的半块(也叫做伙伴)被放置在相应的空闲链表中。要释放一个大小为 沪的块，我们继续合并空闲的伙伴。当遇到一个已分配的伙伴时，我们就停止合并。
关于伙伴系统的一个关键事实是，给定地址和块的大小，很容易计算出它的伙伴的地 址。例如，一个块，大小为32字节，地址为：
xrx *••〇:00000
它的伙伴的地址为
xr 工…：10000
换句话说，一个块的地址和它的伙伴的地址只有一位不相同。
伙伴系统分配器的主要优点是它的快速搜索和快速合并。主要缺点是要求块大小为2 的幂可能导致显著的内部碎片。因此，伙伴系统分配器不适合通用目的的工作负载。然 而，对于某些特定应用的工作负载，其中块大小预先知道是2的幂，伙伴系统分配器就很 有吸引力了。
9. 10垃圾收集
在诸如C malloc包这样的显式分配器中，应用通过调用malloc和free来分配和释 放堆块。应用要负责释放所有不再需要的已分配块。
未能释放已分配的块是一种常见的编程错误。例如，考虑下面的C函数，作为处理的 一部分，它分配一块临时存储：
606 第二部分在系统上运行程序
int *p = (int *)Malloc(15213);
return; /* Array p is garbage at this point */
因为程序不再需要p,所以在garbage返回前应该释放p。不幸的是，程序员忘了释 放这个块。它在程序的生命周期内都保持为已分配状态，毫无必要地占用着本来可以用来 满足后面分配请求的堆空间。
垃圾收集器（garbage collector)是一种动态内存分配器，它自动释放程序不再需要的 已分配块。这些块被称为垃圾（garbage)(因此术语就称之为垃圾收集器）。自动回收堆存 储的过程叫做垃级收集（garbage collection)。在一个支持垃圾收集的系统中，应用显式分 配堆块，但是从不显示地释放它们。在C程序的上下文中，应用调用malloc，但是从不 调用free。反之，垃圾收集器定期识别垃圾块，并相应地调用free,将这些块放回到空 闲链表中。
垃圾收集可以追溯到John McCarthy在20世纪60年代早期在MIT开发的Lisp系统。 它是诸如Java、ML、Perl和Mathematica等现代语言系统的一个重要部分，而且它仍然 是一个重要而活跃的研究领域。有关文献描述了大量的垃圾收集方法，其数量令人吃惊。 我们的讨论局限于McCarthy独创的Mark&Sweep(标记&清除）算法，这个算法很有趣， 因为它可以建立在已存在的malloc包的基础之上，为C和C++程序提供垃圾收集。
9. 10. 1垃圾收集器的基本知识
垃圾收集器将内存视为一张有向可达图（reachability graph)，其形式如图9-49所示。 该图的节点被分成一组根节点（root node)和一组堆节点（heap node)。每个堆节点对应于 堆中的一个已分配块。有向边意味着块f中的某个位置指向块9中的某个位置。根 节点对应于这样一种不在堆中的位置，它们中包含指向堆中的指针。这些位置可以是寄存 器、栈里的变量，或者是虚拟内存中读写数据区域内的全局变量。
当存在一条从任意根节点出发并到达P的有向路径时，我们说节点^是可达的 (reachable)。在任何时刻，不可达节点对应于垃圾，是不能被应用再次使用的。垃圾收集 器的角色是维护可达图的某种表示，并通过释放不可达节点且将它们返回给空闲链表，来 定期地回收它们。
像ML和Java这样的语言的垃圾收集器，对应用如何创建和使用指针有很严格的控 制，能够维护可达图的一种精确的表示，因此也就能够回收所有垃圾。然而，诸如C和
图9-49垃圾收集器将内存视为一张有向图
第9章虚拟内存 607
C++这样的语言的收集器通常不能维持可达图的精确表示。这样的收集器也叫做保守的 垃圾收集器（conservative garbage collector)。从某种意义上来说它们是保守的，即每个可 达块都被正确地标记为可达了，而一些不可达节点却可能被错误地标记为可达。
收集器可以按需提供它们的服务，或者它们可以作为一个和应用并行的独立线程，不 断地更新可达图和回收垃圾。例如，考虑如何将一个C程序的保守的收集器加人到已存在 的malloc包中，如图9-50所示。
动态内存分配器
图9-50将一个保守的垃圾收集器加入到C的malloc包中
无论何时需要堆空间时，应用都会用通常的方式调用malloc。如果malloc找不到一 个合适的空闲块，那么它就调用垃圾收集器，希望能够回收一些垃圾到空闲链表。收集器 识别出垃圾块，并通过调用free函数将它们返回给堆。关键的思想是收集器代替应用去 调用free。当对收集器的调用返回时，malloc重试，试图发现一个合适的空闲块。如果 还是失败了，那么它就会向操作系统要求额外的内存。最后，malloc返回一个指向请求 块的指针(如果成功）或者返回一个空指针（如果不成功）。
9.10.2	Mark & Sweep 垃圾收集器
Mark&Sweep垃圾收集器由标记（mark)阶段和清除（sweep)阶段组成，标记阶段标记 出根节点的所有可达的和已分配的后继，而后面的清除阶段释放每个未被标记的已分配 块。块头部中空闲的低位中的一位通常用来表示这个块是否被标记了。
我们对Mark&Sweep的描述将假设使用下列函数，其中ptr定义为typedef void *ptr:
.•ptrisPtr (ptrp>。如果p指向一个已分配块中的某个字，那么就返回一个指向 这个块的起始位置的指针b。否则返回NULL。
•	int blockMarked (ptr b)。如果块b是已标记的，那么就返回true。
•	int blockAllocated(ptr b)。如果块b是已分配的，那么就返回tme。
•	void markBlock (ptr b)。标记块 b〇
•	int length (b)。返回块b的以字为单位的长度（不包括头部）。
•	void unmarkBlock (ptr b)。将块b的状态由已标记的改为未标记的。
•	ptr nextBlock(ptr b) 0返回堆中块b的后继。
标记阶段为每个根节点调用一次图9-51a所示的mark函数。如果P不指向一个已分 配并且未标记的堆块，mark函数就立即返回。否则，它就标记这个块，并对块中的每个 字递归地调用它自己。每次对mark函数的调用都标记某个根节点的所有未标记并且可达 的后继节点。在标记阶段的末尾，任何未标记的已分配块都被认定为是不可达的，是垃 圾，可以在清除阶段回收。
清除阶段是对图9_51b所示的sweep函数的一次调用。sweep函数在堆中每个块上反 复循环，释放它所遇到的所有未标记的已分配块(也就是垃圾）。
图9-52展示了一个小堆的Mark&Sweep的图形化解释。块边界用粗线条表示。每个方 块对应于内存中的一个字。每个块有一个字的头部，要么是已标记的，要么是未标记的。
608	第二部分在系统上运行程序
void mark(ptr p) {		void sweep(ptr b, ptr end) {
if ((b = isPtr(p)) == NULL)		while (b < end) {
return;		if (blockMarked(b))
if (blockMarked(b))		unmarkBlock(b);
return;		else if (blockAllocated(b))
markBlock(b);		free(b);
len = length(b);		b = aextBlock(b);
for (i=0; i < len; i++)		>
markCb [i]);		return;
return; >		>
a) mark 函数	b) sweep 函数
图9-51 mark和sweep函数的伪代码
标记前：
标记后：1: ¾ I I丨和::刚M mi T1
□未标记的块头部 已标记的块头部
清除后：| |哞闲的1/|卜卜丨空闲的丨丨I I
v_>
阁9-52 Mark&Sweep示例。注意这个示例中的箭头表示内存引用，而不是空闲链表指针
初始情况下，图9-52中的堆由六个已分配块组成，其中每个块都是未分配的。第3 块包含一个指向第1块的指针。第4块包含指向第3块和第6块的指针。根指向第4块。 在标记阶段之后，第1块、第3块、第4块和第6块被做了标记，因为它们是从根节点可 达的。第2块和第5块是未标记的，因为它们是不可达的。在清除阶段之后，这两个不可 达块被回收到空闲链表。
9. 10. 3 C 程序的保守 Mark&Sweep
Mark&Sweep对C程序的垃圾收集是一种合适的方法，因为它可以就地工作，而不 需要移动任何块。然而，C语言为isPtr函数的实现造成了一些有趣的挑战。
第一，C不会用任何类型信息来标记内存位置。因此，对isPtr没有一种明显的方式 来判断它的输入参数P是不是一个指针。第二，即使我们知道P是一个指针，对isPtr也 没有明显的方式来判断P是否指向一个已分配块的有效载荷中的某个位置。
对后一问题的解决方法是将已分配块集合维护成一棵平衡二叉树，这棵树保持着这样一 个属性：左子树中的所有块都放在较小的地址处，而右子树中的所有块都放在较大的地址 处。如图9-53所示，这就要求每个已分配块的头部里有两个附加字段（left和right)。每 个字段指向某个已分配块的头部。isPtr(PtrP)函数用树来执行对已分配块的二分查找。在 每一步中，它依赖于块头部中的大小字段来判断P是否落在这个块的范围之内。
第9章虚拟内存	仰9
已分配块头部
Size	Left	Right	块剩余的部分
</ V
图9-53 —棵已分配块的平衡树中的左右指针
平衡树方法保证会标记所有从根节点可达的节点，从这个意义上来说它是正确的。这 是一个必要的保证，因为应用程序的用户当然不会喜欢把他们的已分配块过早地返回给空 闲链表。然而，这种方法从某种意义上而言又是保守的，因为它可能不正确地标记实际上 不可达的块，因此它可能不会释放某些垃圾。虽然这并不影响应用程序的正确性，但是这 可能导致不必要的外部碎片。
C程序的Mark & Sweep收集器必须是保守的，其根本原因是C语言不会用类型信息 来标记内存位置。因此，像int或者float这样的标量可以伪装成指针。例如，假设某 个可达的已分配块在它的有效载荷中包含一个int，其值碰巧对应于某个其他已分配块b 的有效载荷中的一个地址。对收集器而言，是没有办法推断出这个数据实际上是int而不 是指针。因此，分配器必须保守地将块b标记为可达，尽管事实上它可能是不可达的。
9. 11 C程序中常见的与内存有关的错误
对C程序员来说，管理和使用虚拟内存可能是个困难的、容易出错的任务。与内存有 关的错误属于那些最令人惊恐的错误，因为它们在时间和空间上，经常在距错误源一段距 离之后才表现出来。将错误的数据写到错误的位置，你的程序可能在最终失败之前运行了 好几个小时，且使程序中止的位置距离错误的位置已经很远了。我们用一些常见的与内存 有关错误的讨论，来结束对虚拟内存的讨论。
9. 11- 1间接引用坏指针
正如我们在9.7.2节中学到的，在进程的虚拟地址空间中有较大的洞，没有映射到任何有 意义的数据。如果我们试图间接引用一个指向这些洞的指针，那么操作系统就会以段异常中止 程序。而且，虚拟内存的某些区域是只读的。试图写这些区域将会以保护异常中止这个程序。
间接引用坏指针的一个常见示例是经典的scanf错误。假设我们想要使用scanf从 stdin读一个整数到一个变量。正确的方法是传递给scanf—个格式串和变量的地址： scanf ("7#d", &val)
然而，对于C程序员初学者而言（对有经验者也是如此！），很容易传递val的内容，而不 是它的地址：
scanf("%d", val)
在这种情况下，scanf将把val的内容解释为一个地址，并试图将一个字写到这个位置。 在最好的情况下，程序立即以异常终止。在最糟糕的情况下，val的内容对应于虚拟内存 的某个合法的读/写区域，于是我们就覆盖了这块内存，这通常会在相当长的一段时间以 后造成灾难性的、令人困惑的后果。
9. 11.2读未初始化的内存
虽然bss内存位置(诸如未初始化的全局C变量）总是被加载器初始化为零，但是对于 堆内存却并不是这样的。一个常见的错误就是假设堆内存被初始化为零：
610 第二部分在系统上运行程序
1	/* Return y = Ax */
2	int *matvec(int **k, int *x, int n)
3	{
4	int i, j;
5
6	int *y = (int *)Malloc(n * sizeof(int));
7
8	for (i = 0; i < n; i++)
9	for (j = 0; j < n; j++)
10	yti] += A[i] [j] * x[j];
n	return y;
12 >
在这个示例中，程序员不正确地假设向量y被初始化为零。正确的实现方式是显式地将 yU]设置为零，或者使用calloc。
9. 11.3 允许栈缓冲区溢出
正如我们在3. 10.3节中看到的，如果一个程序不检查输人串的大小就写入栈中的目 标缓冲区，那么这个程序就会有缓冲区溢出错误（buffer overflow bug)。例如，下面的函 数就有缓冲区溢出错误，因为gets函数复制一个任意长度的串到缓冲区。为了纠正这个 错误，我们必须使用fgets函数，这个函数限制了输人串的大小：
1	void bufoverflow()
2	{
3	char buf[64];
4
5	gets(buf); /* Here is the stack buffer overflow bug */
6	return;
7	}
9. 11.4假设指针和它们指向的对象是相同大小的
一种常见的错误是假设指向对象的指针和它们所指向的对象是相同大小的：
1	/* Create an nxm array */
2	int **raakeArrayl(int n, int m)
3	{
4	int	i;
5	int	**A =	(int **)Malloc(n
6
7	for	(i	= 0;	i < n;	i++)
8	A[i] = (int *)Malloc(m
9	return	A;
10 >
这里的目的是创建一个由〃个指针组成的数组，每个指针都指向一个包含m个int的数 组。然而，因为程序员在第5行将sizeof (int*)写成了 sizeof (int)，代码实际上创建 的是一个int的数组。
这段代码只有在int和指向int的指针大小相同的机器上运行良好。但是，如果我们 在像Core i7这样的机器上运行这段代码，其中指针大于int，那么第7行和第8行的循环将
* sizeof(int));
* sizeof(int));
第9章虚拟内存 611
写到超出A数组结尾的地方。因为这些字中的一个很可能是已分配块的边界标记脚部，所以 我们可能不会发现这个错误，直到在这个程序的后面很久释放这个块时，此时，分配器中的 合并代码会戏剧性地失败，而没有任何明显的原因。这是“在远处起作用（action at distance)” 的一个阴险的示例， 这类“在远处起作用”是与内存有关的编程错误的典型情况。
9. 11.5造成错位错误
错位（off-by-one)错误是另一种很常见的造成覆盖错误的来源：
1	/* Create an nxm array */
2	int **makeArray2(int n， int m)
3	{
4	int i;
5	int **A =	(int **)Malloc(n * sizeof(int *));
6
7	for (i = 0; i <= n; i++)
8	A[i] = (int *)Malloc(m * sizeof(int));
9	return A;
10 >
这是前面一节中程序的另一个版本。这里我们在第5行创建了一个《个元素的指针数 组，但是随后在第7行和第8行试图初始化这个数组的《 + 1个元素，在这个过程中覆盖 了 A数组后面的某个内存位置。
9. 11.6引用指针，而不是它所指向的对象
如果不太注意C操作符的优先级和结合性，我们就会错误地操作指针，而不是指针所 指向的对象。比如，考虑下面的函数，其目的是删除一个有*size项的二叉堆里的第一 项，然后对剩下的*size-l项重新建堆：
1	int *binh.GapDelete(int **binheap, int *size)
2	{
3	int *packet = binheap[0];
4
5	binheap [0] = biniieapC*size	-	1];
6	*size--; /* This	should,	be	(*size)-- */
7	heapifyCbinheap,	*size,	0);
8	return(packet);
9	>
在第6行，目的是减少size指针指向的整数的值。然而，因为一元运算符一一和* 的优先级相同，从右向左结合，所以第6行中的代码实际减少的是指针自己的值，而不是 它所指向的整数的值。如果幸运地话，程序会立即失败；但是更有可能发生的是，当程序 在执行过程后很久才产生出一个不正确的结果时，我们只有一头的雾水。这里的原则是当 你对优先级和结合性有疑问的时候，就使用括号。比如，在第6行，我们可以使用表达式 (*siZe)--，清晰地表明我们的意图。
9. 11.7误解指针运算
另一种常见的错误是忘记了指针的算术操作是以它们指向的对象的大小为单位来进行 的，而这种大小单位并不一定是字节。例如，下面函数的目的是扫描一个int的数组，并
612 第二部分在系统上运行程序
返回—个指针，指向val的首次出现：
1	int *search(int *p, int val)
2	{
3	while (*p && *p != val)
4	p += sizeof(int); /* Should be p++ */
5	return p;
6	>
然而，因为每次循环时，第4行都把指针加了 4(一个整数的字节数），函数就不正确地扫 描数组中每4个整数。
9-	11.8引用不存在的变量
没有太多经验的C程序员不理解栈的规则，有时会引用不再合法的本地变量，如下列 所示：
1	int *stackref ()
2	{
3	int val;
4
5	return &val;
6	>
这个函数返回一个指针（比如说是p)，指向栈里的一个局部变量，然后弹出它的栈 帧。尽管P仍然指向一个合法的内存地址，但是它已经不再指向一个合法的变量了。当以 后在程序中调用其他函数时，内存将重用它们的栈帧。再后来，如果程序分配某个值给 *p，那么它可能实际上正在修改另一个函数的栈帧中的一个条目，从而潜在地带来灾难性 的、令人困惑的后果。
9. 11.9引用空闲堆块中的数据
一个相似的错误是引用已经被释放了的堆块中的数据。例如，考虑下面的示例，这个示例 在第6行分配了一个整数数组x，在第10行中先释放了块X，然后在第14行中又引用了它：
1	int *heapref(int n, int m)
2	{
3	int	i;
4	int	*x,	*y;
5
6	x = (int *)Malloc(n * sizeof(int));
7
8	•	// Other calls to malloc and free go here
9
10	free(x);
11
12	y = (int *)Malloc(m * sizeof(int));
13	for	(i	=	0; i < m; i++)
14	y[i] = x[i]++; /* Oops! x[i] is a word in a free block */
15
16
17
return y;
第9章虚拟内存 613
取决于在第6行和第10行发生的malloc和free的调用模式，当程序在第14行引用 x[i]时，数组x可能是某个其他已分配堆块的一部分了，因此其内容被重写了。和其他许 多与内存有关的错误一样，这个错误只会在程序执行的后面，当我们注意到y中的值被破 坏了时才会显现出来。
9.11.10引起内存泄漏
内存泄漏是缓慢、隐性的杀手，当程序员不小心忘记释放已分配块，而在堆里创建了 垃圾时，会发生这种问题。例如，下面的函数分配了一个堆块X，然后不释放它就返回：
1	void leak(int n)
2	{
3	int *x = Cint *)Malloc(n * sizeof(int));
4
5	return; /* x is garbage at this point */
6	>
如果经常调用leak，那么渐渐地，堆里就会充满了垃圾，最糟糕的情况下，会占用 整个虚拟地址空间。对于像守护进程和服务器这样的程序来说，内存泄漏是特别严重的， 根据定义这些程序是不会终止的。
9. 12 小结
虚拟内存是对主存的一个抽象。支持虚拟内存的处理器通过使用一种叫做虚拟寻址的间接形式来引 用主存。处理器产生一个虚拟地址，在被发送到主存之前，这个地址被翻译成一个物理地址。从虚拟地 址空间到物理地址空间的戢址翻译要求硬件和软件紧密合作。专门的硬件通过使用页表来翻译虚拟地址， 而页表的内容是由操作系统提供的。
虚拟内存提供三个重要的功能。第一，它在主存中自动缓存最近使用的存放磁盘上的虚拟地址空间 的内容。虚拟内存缓存中的块叫做页。对磁盘上页的引用会触发缺页，缺页将控制转移到操作系统中的 一个_缺页处理程序。缺页处理程序将页面从磁盘复制到主存缓存，如果必要，将写回被驱逐的页。第二， 虚拟内存简化了内存管理，进而又简化了链接、在进程间共享数据、进程的内存分配以及程序加载=> 最 后，虚拟内存通过在每条页表条目中加人保护位，从而了简化了内存保护。
地址翻译的过程必须和系统中所有的硬件缓存的操作集成在一起。大多数页表条目位于L1高速缓 存中，但是一个称为TLB的页表条目的片上高速缓存，通常会消除访问在L1上的页表条目的开销。
现代系统通过将虚拟内存片和磁盘上的文件片关联起来，来初始化虚拟内存片，这个过程称为内存 映射。内存映射为共享数据、创建新的进程以及加载程序提供了一种高效的机制。应用可以使用_39函 数来手工地创建和删除虚拟地址空间的区域。然而，大多数程序依赖于动态内存分配器，例如malloc， 它管理虚拟地址空间区域内一个称为堆的区域。动态内存分配器是一个感觉像系统级程序的应用级程序， 它直接操作内存，而无需类型系统的很多帮助■■分配器有两种类型。显式分配器要求应用显式地释放它 们的内存块。隐式分配器(垃圾收集器）自动释放任何未使用的和不可达的块。
对于C程序员来说，管理和使用虚拟内存是一件困难和容易出错的任务D常见的错误示例包括：间 接引用坏指针，读取未初始化的内存，允许栈缓冲区溢出，假设指针和它们指向的对象大小相同，引用 指针而不是它所指向的对象，误解指针运算，引用不存在的变量，以及引起内存泄漏D
参考文献说明
Kilbuni和他的同事们发表了第一篇关于虚拟内存的描述[63]。体系结构教科书包括关于硬件在虚拟 内存中的角色的更多细节[46]。操作系统教科书包含关于操作系统角色的更多信息[102，106，113]。 Bovet和Cesati [11]给出了 Umax虚拟内存系统的详细描述D Intel公司提供了 IA处理器上32位和64位
614 第二部分在系统上运行程序
地址翻译的详细文档[52]。
Knuth在1968年编写了有关内存分配的经典之作[64]。从那以后，在这个领域就有了大量的文献。 Wilson、Johnstone、Neely和Boles编写了一篇关于显式分配器的漂亮综述和性能评价的文章[118]。本 书中关于各种分配器策略的吞吐率和利用率的一般评价就引自于他们的调查^ Jones和Lins提供了关于 垃圾收集的全面综述[56]。Kernighan和Ritchie [61]展示了一个简单分配器的完整代码，这个简单的分 配器是基于显式空闲链表的，每个空闲块中都有一个块大小和后继指针。这段代码使用联合（union)来消 除大量的复杂指针运算，这是很有趣的，但是代价是释放操作是线性时间（而不是常数时间）。Doug Lea 开发了广泛使用的开源malloc包，称为dlmalloc [67]a
家庭作业
*9- 11在下面的一系列问题中，你要展示9.6.4节中的示例内存系统如何将虚拟地址翻译成物理地址， 以及如何访问缓存。对于给定的虚拟地址，请指出访问的TLB条目、物理地址，以及返回的缓存 字节值。请指明是否TLB不命中，是否发生了缺页，是否发生了缓存不命中。如果有缓存不命 中，对于“返回的缓存字节”用来表示。如果有缺页，对于“PPN”用来表示，而C部分和D 部分就空着。
虚拟地址：0x027c
A.虚拟地址格式	•
13	12	11	10	9	8	7	6	5	4	3	2	1	0
B.地址翻译
参数	值
VPN	
TLB索引	
TLB标记	
TLB命中？（是/否）	
缺页？（是/否）	
PPN	
C.物理地址格式
11	10	9876543210
D.物理地址引用 *
参数	值
字节偏移	
缓存索引	
缓存标记	
缓存命中？（是/否）	
返回的缓存字节	
*9.12对于下面的地址，重复习题9.11: 虚拟地址：0x03a9
A.虚拟地址格式
第9章虚拟内存 615
13	12	11 10	9	8	7	6	5	4	3	2	1	0
B.地址翻译
参数	值
VPN	
TLB索引	
TLB标记	
TLB命中？（是/否）	
缺页？（是/否）	
PPN	
C.物理地址格式
11	10	9876543210
D.物理地址引用
参数	值
字节偏移	
缓存索引	
缓存标记	
缓存命中？（是/否）	
返回的缓存字节	
*9,13对于下面的地址，重复习题9.11:
虚拟地址：0x0040 * A.虚拟地址格式
13	12	11	10	9	8	7	6	5	4	3	2	1	0
B.地址翻译
参数	值
VPN	
TLB索引	
TLB标记	
TLB命中？（是/否）	
缺页？（是/否）	
PPN	
C.物理地址格式
11	10	9876543210
D.物理地址引用
616	第二部分在系统上运行程序
.*9. 14 *9. 15
.9. 16
*/9. 17 *:9. 18
* 9. 19
参数	值
字节偏移	
缓存索引	
缓存标记	
缓存命中？（是/否）	
返回的缓存字节	
假设有一个输人文件hello.txt,由字符串“Hello, w〇rld!\n”组成，编写一个C程序，使用 mmap 将 hello. txt 的内容改变为“Jello, world! \n”。
确定下面的malloc请求序列得到的块大小和头部值。假设：1)分配器保持双字对齐，使用隐式空 闲链表，以及图9-35中的块格式2)块大小向上舍入为最接近的8字节的倍数。
请求	块大小（十进制字节）	块头部（十六进制）
malloc(3)		
malloc(11)		
malloc(20)		
malloc(21)		
确定下面对齐要求和块格式的每个组合的最小块大小。假设：显式空闲链表、每个空闲块中有四宇 节的pred和succ指针、不允许有效载荷的大小为零，并且头部和脚部存放在一个四字节的字中。
对齐要求	已分配块	空闲块	最小块大小（字节）
单字	头部和脚部	头部和脚部	
单字	头部，但是没有脚部	头部和脚部	
双字	头部和脚部	头部和脚部	
双字	头部，但是没有脚部	头部和脚部	
开发9. 9. 12节中的分配器的一个版本，执行下一次适配搜索，而不是首次适配搜索^
9.9. 12节中的分配器要求每个块既有头部也有脚部，以实现常数时间的合并。修改分配器，使得 空闲块需要头部和脚部，而已分配块只需要头部。
下面给出了三组关于内存管理和垃圾收集的陈述。在每一组中，只有一句陈述是正确的。你的任 务就是判断哪一句是正确的。
1)	a)在一个伙伴系统中，最高可达50%的空间可以因为内部碎片而被浪费了。
b)	首次适配内存分配算法比最佳适配算法要慢一些（平均而言）。
c)	只有当空闲链表按照内存地址递增排序时，使用边界标记来回收才会快速。
d)	伙伴系统只会有内部碎片，而不会有外部碎片。
2)	a)在按照块大小递减顺序排序的空闲链表上，使用首次适配算法会导致分配性能很低，但是可 以避免外部碎片。
b)	对于最佳适配方法，空闲块链表应该按照内存地址的递增顺序排序D
c)	最佳适配方法选择与请求段匹配的最大的空闲块。
d)	在按照块大小递增的顺序排序的空闲链表上，使用首次适配算法与使用最佳适配算法等价.
3)	Mark&Sweep垃圾收集器在下列哪种情况下叫做保守的：
a)	它们只有在内存请求不能被满足时才合并被释放的内存。
b)	它们把一切看起来像指针的东西都当做指针^
c)	它们只在内存用尽时，才执行垃圾收集。
d)	它们不释放形成循环链表的内存块。
第9章虚拟内存
JJ9.20编写你自己的malloc和free版本，将它的运行时间和空间利用率与标准C库提供的malloc版 本进行比较。
练习题答案
9.1这道题让你对不同地址空间的大小有了些了解。曾几何时，一个32位地址空间看上去似乎是无法 想象的大。但是，现在有些数据库和科学应用需要更大的地址空间，而且你会发现这种趋势会继 续。在有生之年，你可能会抱怨个人电脑上那狭促的64位地址空间！
虚拟地址位数U)	虚拟地址数（A0	最大可能的虚拟地址
8	28 = 2 5 6	28- 1 =255
16	216=64K	216- 1 = 64K- 1
32	232 = 4G	232- 1 = 4G- 1
48	248=256T	2^-1=2561-1
64	2m= 16 384P	2m-1=I6 384P-1
9.2因为每个虚拟页面是P = 2f字节，所以在系统中总共有2"/2p = 2"〜个可能的页面，其中每个都需 要一个页表条目（PTE)。
n	P=2P	PTE的数量
16	4K	16
16	8K	8
32	4K	1M
32	8K	512K
9. 3为了完全掌握地址翻译，你需要很好地理解这类问题。下面是如何解决第一个子问题：我们有n = 32个虚拟地址位和m = 24个物理地址位.页面大小是P=1KB，这意味着对于VPO和PPO,我们 都需要l〇g£aK) = 10位^ (回想一下，VPO和PPO是相同的。）剩下的地址位分别是VPN和PPN。
P	VPN位数	VPO位数	PPN位数	PPO位数
1KB	22	10	14	10
2KB	21	11	13	11
4KB	20	12	12	12
8KB	19	13	11	13
9.4做一些这样的手工模拟，能很好地巩固你对地址翻译的理解。你会发现写出地址中的所有的位，然 后在不同的位字段上画出方框，例如VPN、TLBI等，这会很有帮助。在这个特殊的练习中，没有 任何类型的不命中：TLB有一份PTE的副本，而缓存有一份所请求数据字的副本。对于命中和不 命中的一些不同的组合，请参见习题9. 11、9. 12和9. 13。
A.	00 0011 1101 0111
参数	值
VPN	〇xf
TLB索引	0x3
TLB标记	0x3
TLB命中？堤/否）	是
缺页？逼/否）	否
PPN	Oxd
C. 0011 0101 0111
618 第二部分在系统上运行程序
参数	值
CO CI	0x3 0x5
CT	Oxd
高速缓存命中？（是/否）	是
高速缓存字节返回	Oxld
9.5解决这个题目将帮助你很好地理解内存映射。请自己独立完成这道题。我们没有讨论〇pen、fstat 或者write函数，所以你需要阅读它们的帮助页来看看它们是如何工作的。
-----------------------------------------code/vm/mmapcopy. c
#include "csapp.h"
/*
* mmapcopy - uses mmap to copy file fd to stdout */
void mmapcopyCint fd, int size)
■C
char *bufp; /* ptr to memory-mapped VM area */
bufp = Mmap(NULL, size, PR0T_READ, HAP_PRIVATE, fd, 0);
Write(1, bufp, size); return;
>
14
15	/* mmapcopy driver */
16	int main(int argc, char **argv)
17	{
18	struct stat stat;
19	int fd;
20 21 22
23
24
25
26
27	/* Copy the input argument to stdout */
28	fd - Open(argv[l], 0_RD0NLY, 0);
29	fstat(fd, &stat);
30	mmapcopy(fd,	stat.st_size);
31	exit(0);
32	>
/* Check for required command-line argument */ if Cargc != 2) {
printf("usage: %s <filename>\n", axgv[0]); exit(0);
2
5
4
5
6
7
8 9
10
11
12
13
code/vm/mmapcopy. c
9.6这道题触及了一些核心的概念，例如对齐要求、最小块大小以及头部编码。确定块大小的一般方法 是，将所请求的有效载荷和头部大小的和舍人到对齐要求（在此例中是8字节）最近的整数倍。比 如，malloc⑴请求的块大小是4 + 1 = 5,然后舍入到8。而malloc(13)请求的块大小是13 + 4 = 17,舍人到24。
请求	块大小（十进制字节）	块头部（十六进制）
malloc ⑴	8	0x9
malloc(5)	16	0x11
malloc(12)	16	0x11
malloc (13)	24	0x19
9.7最小块大小对内部碎片有显著的影响。因此，理解和不同分配器设计和对齐要求相关联的最小块大 小是很好的。很有技巧的一部分是，要意识到相同的块可以在不同时刻被分配或者被释放D因此， 最小块大小就是最小已分配块大小和最小空闲块大小两者的最大值。例如，在最后一个子问题中，
第9章虚拟内存 619
最小的已分配块大小是一个4字节头部和一个1字节有效载荷，舍入到8字节。而最小空闲块的大 小是一个4字节的头部和一个4字节的脚部，加起来是8字节，已经是8的倍数，就不需要再舍人 了。所以，这个分配器的最小块大小就是8字节。
对齐要求	已分配块	空闲块	最小块大小（字节）
单字	头部和脚部	头部和脚部	12
单字	头部，但是没有脚部	头部和脚部	8
双字	头部和脚部	头部和脚部	16
双字	头部，但是没有脚部	头部和脚部	S
这里没有特别的技巧但是解答此题要求你理解简单的隐式链表分配器的剩余部分是如何工作的， 是如何操作和遍历块的■=
-----------------------------------------------code/vm/malloc/mm.c
1	static void *find_fit(size_t asize)
2	{
3	/* First-fit	search */
4	void *bp;
5
6	for (bp = keap_listp; GET_SIZE(HDEP(bp>) > 0; bp = NEXT_BLKP(bp)) {
7	if (!GET_ALLOCCHDRPCbp)) && (asize <= GET_SXZE(HDRP(bp)))) ■{
8	return bp;
9	y
10	>
n	return NULL;	/*	No fit */
12	#endif
13	>
-----------------------------------------------code/vm/malloc/mm.c
这又是一个帮助你熟悉分配器的热身练习。注意对于这个分配器，最小块大小是16字节a如果分 割后剩下的块大于或者等于最小块大小，那么我们就分割这个块（第6〜10行）。这里唯一有技巧的 部分是要意识到在移动到下一块之前(第8行），你必须放置新的已分配块（第6行和第7行）。 -------------------------code/vm/malloc/mm. c
static void place(void *bp, size_t asize)
size_t csize * GET_SIZE(HDRP(bp));
if ((csize - asize) >~ (2*DSIZE)) { PUT(HDRP(bp)f PACK(asize, 1)); PUT(FTRP(bp), PACK(asize, 1)); bp = NEXT.BLKP(bp);
PUT(HDRP(bp), PACK(csize-asize, 0)); PUT(FTRP(bp), PACK(csize-asize, 0));
>
else ■(
PUT(HDRP(bp), PACKCcsize, 1)); PUT(FTRP(bp), PACK(csize, 1));
code/vm/malloc/mm.c
9. 10这里有一个会引起外部碎片的模式：应用对第一个大小类做大量的分配和释放请求，然后对第二 个大小类做大量的分配和释放请求，接下来是对第三个大小类做大量的分配和释放请求，以此类 推.对于每个大小类，分配器都创建了许多不会被回收的存储器，因为分配器不会合并，也因为 应用不会再向这个大小类再次请求块了。
第三部分
P	A	R	T	3
程序间的交互和通信
我们学习计算机系统到现在，一直假设程序是独立运行的， 只包含最小限度的输入和输出。然而，在现实世界里，应用程序 利用操作系统提供的服务来与I/O设备及其他程序通信。
本书的这一部分将使你了解Unix操作系统提供的基本1/◦服 务，以及如何用这些服务来构造应用程序，例如Web客户端和服 务器，它们是通过Internet彼此通信的。你将学习编写诸如Web 服务器这样的可以同时为多个客户端提供服务的并发程序。编写 并发应用程序还能使程序在现代多核处理器上执行得更快。当学 完了这个部分，你将逐渐变成一个很牛的程序员，对计算机系统 以及它们对程序的影响有很成熟的理解。
第10章
10
系统级I/O
输入/输出（I/O)是在主存和外部设备(例如磁盘驱动器、终端和网络）之间复制数据的过 程。输人操作是从I/O设备复制数据到主存，而输出操作是从主存复制数据到I/O设备。
所有语言的运行时系统都提供执行I/O的较高级别的工具。例如，ANSI C提供标准 I/O库，包含像pirintf和scanf这样执行带缓冲区的I/O函数。C++语言用它的重载操 作符<<(输人）和>>(输出）提供了类似的功能。在Linux系统中，是通过使用由内核提供的 系统级Unix I/O函数来实现这些较高级别的I/O函数的。大多数时候，高级别I/O函数 工作良好，没有必要直接使用Unix I/O。那么为什么还要麻烦地学习Unix I/O呢？
•	了解Unix I/O将帮助你理解其他的系统概念。I/O是系统操作不可或缺的一部分，因 此，我们经常遇到I/O和其他系统概念之间的循环依赖。例如，I/O在进程的创建和 执行中扮演着关键的角色。反过来，进程创建又在不同进程间的文件共享中扮演着关 键角色。因此，要真正理解VO,你必须理解进程，反之亦然。在对存储器层次结构、 链接和加载、进程以及虚拟内存的讨论中，我们已经接触了 I/O的某些方面。既然你 对这些概念有了比较好的理解，我们就能闭合这个循环，更加深人地研究I/O。
•有时你除了使用Unix I/O以外别无选择。在某些重要的情况中，使用高级I/O函 数不太可能，或者不太合适。例如，标准VO库没有提供读取文件元数据的方式， 例如文件大小或文件创建时间。另外，I/O库还存在一些问题，使得用它来进行网 络编程非常冒险。
这一章介绍Unix I/O和标准I/O的一般概念，并且向你展示在C程序中如何可靠地 使用它们。除了作为一般性的介绍之外，这一章还为我们随后学习网络编程和并发性奠定 坚实的基础。
10.	1 Unix I/O
一个Linux文件就是一个m个字节的序列：
B〇, Bi, •••, Bt, •••, Bm-,
所有的I/O设备(例如网络、磁盘和终端)都被模型化为文件，而所有的输人和输出都被当 作对相应文件的读和写来执行。这种将设备优雅地映射为文件的方式，允许Linux内核引 出一个简单、低级的应用接口，称为Unix I/O,这使得所有的输人和输出都能以一种统 一且一致的方式来执行：
*打开文件。一个应用程序通过要求内核打开相应的文件，来宣告它想要访问一个 I/O设备。内核返回一个小的非负整数，叫做描述符，它在后续对此文件的所有操 作中标识这个文件。内核记录有关这个打开文件的所有信息。应用程序只需记住这 个描述符。
•	Linux shell创建的毎个进程开始时都有三个打开的文件：标准输入(描述符为0)、标准 输出（描述符为1)和标准错误(描述符为2)。头文件< unistd.h>定义了常量STDIN_ FILENO、STDOOT FILENO和STDERR FILENO,它们可用来代替显式的描述符值。
第10章系统级I/O 623
*改变当前的文件位置。对于每个打开的文件，内核保持着一个文件位置々，初始为 〇。这个文件位置是从文件开头起始的字节偏移量。应用程序能够通过执行seek操 作，显式地设置文件的当前位置为是。
•读写文件。一个读操作就是从文件复制《>0个字节到内存，从当前文件位置々开 始，然后将々增加到6+心给定一个大小为m字节的文件，当々时执行读操作 会触发一个称为end-〇f-file(EOF)的条件，应用程序能检测到这个条件。在文件结 尾处并没有明确的“EOF符号”。
类似地，写操作就是从内存复制《>〇个字节到一个文件，从当前文件位置是 开始，然后更新办。
*关闭文件。当应用完成了对文件的访问之后，它就通知内核关闭这个文件。作为响 应，内核释放文件打开时创建的数据结构，并将这个描述符恢复到可用的描述符池 中。无论一个进程因为何种原因终止时，内核都会关闭所有打开的文件并释放它们 的内存资源。
10.2文件
每个Linux文件都有一个类型（type)来表明它在系统中的角色：
•普通文件（regular file)包含任意数据。应用程序常常要区分文本文件（text file)和二 进制文件（binary file)，文本文件是只含有ASCII或Unicode字符的普通文件；二 进制文件是所有其他的文件。对内核而言，文本文件和二进制文件没有区别。
Linux文本文件包含了一个文本行(text line)序列，其中每一行都是一个字符序列， 以一个新行符（“ \ n”)结束。新行符与ASCII的换行符(LF)是一样的，其数字值为0x0a。
•目录（directory)是包含一组链接（link)的文件，其中每个链接都将一个文件名 (filename)映射到一个文件，这个文件可能是另一个目录。每个目录至少含有两个 条目：是到该目录自身的链接，以及是到目录层次结构（见下文）中父目
-录（parent directory)的链接。你可以用mkdir命令创建一个目录，用Is查看其内 容，用rmdir删除该目录。
•套接字（socket)是用来与另一个进程进行跨网络通信的文件（11. 4节）。
其他文件类型包含命名通道（named pipe)、符号链接（symbolic link)，以及字符和块 设备（character and block device),这些不在本书的讨论范畴。
Linux内核将所有文件都组织成一"^目录居次结构（directory hierarchy)，由名为/(斜 杠）的根目录确定。系统中的每个文件都是根目录的直接或间接的后代。图10-1显示了 Lmujc系统的目录层次结构的一部分。
图10-1 Linux目录层次的一部分。尾部有斜杠表示是目录
624 第三部分程序间的交互和通信
作为其上下文的一部分，每个进程都有一个当前工作目录（current working directory) 来确定其在目录层次结构中的当前位置。你可以用cd命令来修改sheii中的当前工作 目录。
目录层次结构中的位置用路径名（pathname)来指定。路径名是一个字符串，包括一个 可选斜杠，其后紧跟一系列的文件名，文件名之间用斜杠分隔。路径名有两种形式：
•绝对路径名（absolute pathname)以一个斜杠开始，表7K从根节点开始的路径。例 如，在图10-1中，hello.c的绝对路径名为/home/droh/hello.c〇 •相对路径名（relative pathname)以文件名开始，表示从当前工作目录开始的路径。 例如，在图10-1中，如果/home/dr〇h是当前工作目录，那么hello.c的相对路径 名就是./1^11〇.0〇反之，如果/^101116/：6；1：73111：是当前工作目录，那么相对路径名 就是.• /home/droh/hello • c。
10.3打开和关闭文件
进程是通过调用open函数来打开一个已存在的文件或者创建一个新文件的：
#include <sys/types.h>	.
#include <sys/stat.h>
#include <fcntl.h>
int open (char *filenajne, int flags, mode_t mode);
返回：若成功则为新文件描述符，若出错为一U
open函数将filename转换为一个文件描述符，并且返回描述符数字。返回的描述符总 是在进程中当前没有打开的最小描述符。flags参数指明了进程打算如何访问这个文件：
•	0_RD0NLY:只读。
•	〇_WR〇NLY:只写。
•	0_RDWR:可读可写。
例如，下面的代码说明如何以读的方式打开一个已存在的文件：
fd = OpenC'foo.txt", Q.RDONLY, 0);
flags参数也可以是一个或者更多位掩码的或，为写提供给一些额外的指示：
•	0_CREAT:如果文件不存在，就创建它的一个截断的（truncated)(空）文件。
•	OJTRUNC:如果文件已经存在，就截断它。
*0_APPEND:在每次写操作前，设置文件位置到文件的结尾处。
例如，下面的代码说明的是如何打开一个已存在文件，并在后面添加一些数据：
fd = OpenC'foo.txt", O.WRONLY|O.APPEND, 0);
mode参数指定了新文件的访问权限位。这些位的符号名字如图1〇-2所示。
作为上下文的一部分，每个进程都有一个umask，它是通过调用urnask函数来设置 的。当进程通过带某个mode参数的open函数调用来创建一个新文件时，文件的访问权 限位被设置为mode &〜umask。例如，假设我们给定下面的mode和umask默认值：
#define DEF.MQDE S.IRUSRIS.IWUSRIS_IRGRPIS.IWGRPIS.IROTHIS.IWOTH #define DEF.UMASK S.IWGRPIS_IW0TH
接下来，下面的代码片段创建一个新文件，文件的拥有者有读写权限，而所有其他的
第川章系统鈒J/0	625
用户都有读权限：
umask(DEF_UMASK);
fd = OpenC'foo.txt", 0_CREAT|0_TRUNC|0_WR0NLY, DEF.MODE);
掩码	描述
SJRUSR	使用者（拥有者）能够读这个文件
SJWUSR	使用者（拥有者）能够写这个文件
S—IXUSR	使用者（拥有者）能够执行这个文件
SJRGRP	拥有者所在组的成员能够读这个文件
SJWGRP	拥有者所在组的成员能够写这个文件
S_IXGRP	拥有者所在组的成员能够执行这个文件
S_IROTH	其他人（任何人）能够读这个文件
S—IWOTH	其他人（任何人）能够写这个文件
SJXOTH	其他人（任何人）能够执行这个文件
图10-2访问权限位。中定义
最后，进程通过调用close函数关闭一个打开的文件。
#include <unistd.h> int close(int fd);
返回：若成功則为0，若出错則为一1。
关闭一个已关闭的描述符会出错。
@练习题10. 1下面程序的输出是什么？
1	#include "csapp.h"		
.3	int main0 s		
5	\ int fdl, fd2;		
7	fdl = Dpen("foo.txt",	O.RDONLY,	〇);
8	Close(fdl);		
9	fd2 = OpenC'baz.txt",	O.RDONLY,	〇);
10	printf("fd2 = %d\n",	fd2);	
11	exit(O);		
12	>		
10.4读和写文件
应用程序是通过分别调用read和write函数来执行输人和输出的。
#include <unistd.h.>
ssize_t read(int fd, void *buf, size_t n);
返回：若成功則为读的字节数，若EOF则为o,若出错为一is
ssize.t write(int fd, const void *buf, size_t n);
返回：若成功则为写的字节数，若出错则为一1。
626 第三部分程序间的交互和通信
read函数从描述符为fd的当前文件位置复制最多^个字节到内存位置buf。返回值一1 表示一个错误，而返回值0表示EOF。否则，返回值表示的是实际传送的字节数量。
write函数从内存位置bUf复制至多77个字节到描述符fd的当前文件位置。图10-3展 示了一个程序使用read和write调用一次一个字节地从标准输人复制到标准输出。
---------------------------------------code/io/cpstdin. c
^ #include "csapp.h."
2
3	int main(void)
4	{
5	char c;
6
7	while(Read(STDIN.FILENO,	&c, 1) != 0)
8	Write(STD0UT_FILEN0, &c, 1);
9	exit(0);
10 >
---------------------------------------code/io/cpstdin. c
图10-3	—次一个字节地从标准输人复制到标准输出
通过调用Iseek函数，应用程序能够显示地修改当前文件的位置，这部分内容不在我 们的讲述范围之内。
ssizej和size_t有些什么区别？
你可能已经注意到了，read函数有一个size_t的输入参数和一个ssize_t的返 回值。那么这两种类型之间有什么区别呢？在x86-64系统中，size_t被定义为unsigned long， 而 ssize_t( 有符号的大小 ） 被定义为 long。 read 函数返回一个有符号 的大小，而不是一个无符号大小，这是因为出错时它必须返回一1。有趣的是，返回一 个一1的可能性使得read的最大值减小了 一半。
在某些情况下，read和write传送的字节比应用程序要求的要少。这些不足值（short count)不表示有错误。出现这样情况的原因有：
•读时遇到EOF。假设我们准备读一个文件，该文件从当前文件位置开始只含有20 多个字节，而我们以50个字节的片进行读取。这样一来，下一个read返回的不足 值为20,此后的read将通过返回不足值0来发出EOF信号。
•从终端读文本行。如果打开文件是与终端相关联的（如键盘和显示器），那么每个 read函数将一次传送一个文本行，返回的不足值等于文本行的大小。
•读和写网络套接字（socket)。如果打开的文件对应于网络套接字（11.4节），那么内 部缓冲约束和较长的网络延迟会引起read和write返回不足值。对Linux管道 (pipe)调用read和write时，也有可能出现不足值，这种进程间通信机制不在我 们讨论的范围之内。
实际上，除了 EOF，当你在读磁盘文件时，将不会遇到不足值，而且在写磁盘文件时， 也不会遇到不足值。然而，如果你想创建健壮的（可靠的）诸如Web服务器这样的网络应用， 就必须通过反复调用read和write处理不足值，直到所有需要的字节都传送完毕。
旁注
10.5用RIO包健壮地读写
在这一小节里，我们会讲述一个I/O包，称为RICXRobust I/O,健壮的I/O)包，它
第10章系统级I/O 627
会自动为你处理上文中所述的不足值。在像网络程序这样容易出现不足值的应用中，RIO 包提供了方便、健壮和高效的I/O。RIO提供了两类不同的函数：
*无缓冲的输入输出函数。这些函数直接在内存和文件之间传送数据，没有应用级缓 冲。它们对将二进制数据读写到网络和从网络读写二进制数据尤其有用。
»带缓冲的输入函数。这些函数允许你高效地从文件中读取文本行和二进制数据，这 些文件的内容缓存在应用级缓冲区内，类似于为printf这样的标准1/0函数提供 的缓冲区。与[11〇]中讲述的带缓冲的I/O例程不同，带缓冲的RIO输人函数是线 程安全的（12. 7.1节），它在同一个描述符上可以被交错地调用。例如，你可以从一 个描述符中读一些文本行，然后读取一些二进制数据，接着再多读取一些文本行。
我们讲述RIO例程有两个原因。第一，在接下来的两章中，我们开发的网络应用中使用 了它们；第二，通过学习这些例程的代码，你将从总体上对Unix I/O有更深入的了解。
10.5. 1 Ri〇的无缓冲的输入输出函数
通过调用3：i〇_readn和rio_Writen函数，应用程序可以在内存和文件之间直接传送数据。
#include "csapp.h"
ssize_t rio_readn(int fd, void ^usrbuf, size_t n); ssize.t rio_writen(int fd, void *usrbuf, size_t n);
返回：若成功则为传送的字节数，若EOF则为0(只对rio_readn而言），若出错则为一1。
rio_readn函数从描述符fd的当前文件位置最多传送n个字节到内存位置usrbuf。 类似地，rio_writen函数从位置usrbuf传送n个字节到描述符fd。ri〇_read函数在遇 到EOF时只能返回一个不足值。rio_writen函数决不会返回不足值。对同一个描述符， 可以任意交错地调用rio_readn和rio_writent>
图 10-4 显75了 rio_readn 和 rio_writen 的代码。注意，如果 rio_readn 和 rio_ 函数被一个从应用信号处理程序的返回中断，那么每个函数都会手5地重启read^ write。为了尽可能有较好的可移植性，我们允许被中断的系统调用，且在必要时重启它们。
10.	5. 2 RI0的带缓冲的输入函数
假设我们要编写一个程序来计算文本文件中文本行的数量，该如何来实现呢？ 一种方 法就是用read函数来一次一个字节地从文件传送到用户内存，检查每个字节来查找换行 符。这个方法的缺点是效率不是很高，每读取文件中的一个字节都要求陷人内核。
—种更好的方法是调用一个包装函数（ric^readlineb),它从一个内部读缓冲区复制一个 文本行，当缓冲区变空时，会自动地调用read重新填满缓冲区。对于既包含文本行也包含二 进制数据的文件(例如11. 5. 3节中描述的HTTP响应），我们也提供了一个ri〇_readn带缓冲 区的版本，叫做rio readnb，它从和rio_readlineb—样的读缓冲区中传送原始字节。
#include "csapp.h"
void rio_readinitb(rio_t *rp, int fd);
返回：无。
ssize.t rio_readlineb Crio_t *rp, void *usrbuf, size_t maxlen); ssize_t rio_readnb(rio_t *rp, void *usrbuf, size_t n);
返回：若成功则为读的字节数，若EOF则为0，若出错则为一1。
628 第三部分程序间的交互和通信
1	ssize_t rio_readn(int fd, void *usrbuf, size_t n)
2	{
code/src/csapp.c
3	size_t nleft = n;	
4	ssize.t nread;	
5	char *bufp = usrbuf;	
7	while (nleft > 0) ■{	
8	if ((nread = read(fd, bufp, nleft))	< 0) {
9	if (errno == EINTR) /* Interrupted by sig heindler return */	
10	nread = 0; /* and call	read〇 again */
n	else	
12	return -1;
13	>
14	else	if	(nread == 0)
15	break;
16	nleft -= nread;
17	bufp	+-	nread;
18	>
19	return (n - nleft);
20	>
/* errno set by read() */
/* EOF */
/* Return >= 0 */
code/src/csapp.c
1
2
3
5
6
7
8 9
10
11
12
13
14
15
16
--------------------------------------------------------------------------code/src/csapp.c
ssize.t rio_writen(int fd, void *usrbuf, size_t n)
size_t nleft = n; ssize_t nwritten; char *bufp = usrbuf;
while (nleft > 0) {
if (Cnwritten = write(fd, bufp, nleft)) <= 0) {
if (errno == EINTR) /* Interrupted by sig handler return */ nwritten = 0;	/* and call writeC) again */
else
return -1;	/* errno set by write() */
y
nleft -= nwritten; bufp += nwritten;
>
^7	return n;
18 >
code/src/csapp.c
[冬1 10_4 rio_readn 和 rio_writen 函数
每打开一个描述符，都会调用一次rio_readinitb函数。它将描述符fd和地址rp 处的一个类型为rio_t的读缓冲区联系起来。
rio_readlineb函数从文件rp读出下一个文本行（包括结尾的换行符），将它复制到 内存位置usrbuf，并且用NULL(零）字符来结束这个文本行。rio_readlineb函数最多 读maxlen-1个字节，余下的一个字符留给结尾的NUI丄字符。超过maxlen-1字节的文
第10聿系统级I/O 629
本行被截断，并用一个NULL字符结束。
rio_readnb函数从文件rp最多读?7个字节到内存位置usrbuf。对同一描述符，对 ri〇_readlineb和rio_readnb的调用可以任意交叉进行。然而，对这些带缓冲的函数的 调用却不应和无缓冲的rio_readn函数交叉使用。
在本书剩下的部分中将给出大量的RIO函数的示例。图10-5展示了如何使用RIO函 数来一次一行地从标准输人复制一个文本文件到标准输出。
----------------------------------------------------code/io/cpfile.c
1	#include "csapp.h"
2
3	int main(int argc, char **argv)
4	{
5	int n;
6	rio_t rio;
7	char buf[MAXLINE];
8
9	Rio_readinitb(&rio,	STDIN_FILEN0);
10	while((n = Rio_readlineb(&rio,	buf, MAXLINE)) != 0)
11	Rio_writen(STD0UT_FXLEN0, buf, n);
12	>
code/io/cpfile. c
图10-5从标准输人复制一个文本文件到标准输出
图10-6展示了一个读缓冲区的格式，以及初始化它的rio readinitb函数的代码。 riojreadinitb函数创建了一个空的读缓冲区，并且将一个打开的文件描述符和这个缓 冲区联系起来。
-------------------------------------------------------------------------code/include/csapp. h
1	#define RIO.BUFSIZE 8192
2	• typedef struct {
3	int rio_fd;
4	int rio^cnt;
5	char *rio_bufptr;
6	char rio.buf[RI0_BUFSIZE]
7	> rio.t;
-------------------------------------------------------------------------code/include/csapp.h
/* Descriptor for this internal buf */ /* Unread bytes in internal buf */
/* Next unread byte in internal buf */ ;/* Internal buffer */
code/src/csapp. c
1	void rio_readinitb(rio_t *rp, int fd)
2	{
3	rp->rio_fd = fd;
4	rp->rio_cnt = 0;
5	rp->rio_bufptr =	rp->rio_buf;
6	>
code/src/csapp. c
图10-6 —个类型为rio_t的读缓冲区和初始化它的rio_readinitb函数
RIO读程序的核心是图10-7所示的rio_read函数。rio_read函数是Linux read函 数的带缓冲的版本。当调用rio_read要求读《个字节时，读缓冲区内有rp->rio_cnt
630 第三部分程序间的交互和通信
个未读字节。如果缓冲区为空，那么会通过调用read再填满它。这个read调用收到一 个不足值并不是错误，只不过读缓冲区是填充了一部分。一旦缓冲区非空，rio_read就 从读缓冲区复制n和rp->ri〇_Cnt中较小值个字节到用户缓冲区，并返回复制的字节数。
code/src/csapp.c
^ static ssize_t rio_read(rio_t *rp, char *usrbuf, size_t n)
2	{
3	int cnt;
4
5	while (rp->rio_cnt <= 0) {	/* Refill if buf is empty */
6	rp->rio_cnt = read(rp->rio_fd, rp->rio_buf,
7	sizeof(rp->rio_buf));
8	if (rp->rio_cnt < 0) {
9	if (errno != EINTR) /* Interrupted by sig handler return */
10	return -1;
11	>
12	else	if	(rp->rio_cnt == 0)	/*	EOF	*/
13	return 0;
14	else
15	rp->rio_bufptr = rp->rio_buf; /* Reset buffer ptr */
16	>
17
18	/* Copy min(n, rp->rio_cnt) bytes from internal buf to user buf */
19	cnt = n;
20	if (rp->rio_cnt < n)
21	cnt = rp->rio_cnt;
22	memcpy(usrbuf,	rp->rio_bufptr, cnt);
23	rp->rio_bufptr	+= cnt;
24	rp->rio_cnt -=	cnt;
25	return cnt;
26	>
图10-7 内部的rio_read函数
code/src/csapp.c
对于一个应用程序，rio_read函数和Linux read函数有同样的语义。在出错时，它 返回值一1，并且适当地设置errno。在EOF时，它返回值0。如果要求的字节数超过了 读缓冲E内未读的字节的数量，它会返回一个不足值。两个函数的相似性使得很容易通过 用rio_read代替read来创建不同类型的带缓冲的读函数。例如，用rio_read代替 read，图10-8中的ri〇_readnb函数和rio_readn有相同的结构。相似地，图10-8中的 rio_readlineb程序最多调用maxlen-1次rio_read。每次调用都从读缓冲区返回一个 字节，然后检查这个字节是否是结尾的换行符。
旁注
RIO包的起源
RIO函数的灵感来自于W. Richard Stevens在他的经典网络编程作品[110]中描述 的 readline、readn 和 writen 函数。rio_readn 和 rio_writen 函数与 Stevens 的 readn和writen函数是一样的。然而，Stevens的readline函数有一些局限性在RI0 中得到了糾正。第一，因为readline是带缓冲的，而readn不带，所以这两个函数不 能在同一描述符上一起使用。第二，因为它使用一个static缓冲区，Stevens的readline
第JO聿系统级I/O 631
函数不是线程安全的，这就要求Stevens引入一个不同的线程安全的版本，称为read-line_r。我们已经在rio_readlineb和rio_readnb函数中修改了这两个缺陷，使得 这两个函数是相互兼容和线程安全的。
-----------------------------------------------------------code/src/csapp.c
ssize_t rio_readlineb(rio_t *rp, void *usrbuf, size_t maxlen)
2	{	
3	int n,	rc;
4 5	char c	,*bufp = usrbuf;
6	for (n	» 1; n < maxlen; n++) {
7	if	((rc = rio_read(rp, kc,
8		*bufp++ = c;
9		if (c == '\n') {
10		n++;
n		break;
12		>
13	} else if (rc == 0) {	
14		if (n == 1)
15		return 0; /* EOF,】
16		else
17		break; /* EOF,:
18	} else	
19		return -1; /* Error
20	>	
21	*bufp :	=〇；
22	return	n-1;
23	>	
1) {
• code/src/csapp.c
ssize.t rio_readnb(rio_t *rp, void *usrbuf,
• code/src/csapp.c
2 3	{ size_t nleft = n;		
4	ssize_t nread;		
5	char *bufp = usrbuf;		
7	while (nleft > 0) {		
8	if ((nread = rio_read(rp, bufp, nleft)) < 0)		
9	return -1;	/* errno set	by read0
10	else if (nread == 0)		
11	break;	/* EOF */	
12	nleft -= nread;		
13	bufp += nread;		
14	>		
15	return (n - nleft);	/* Return >=	0 */
16 ；	}		
图 10-8 rio readlineb 和 rio readnb 函数
code/src/csapp.c
632 第三部分程序间的交互和通信
10.6读取文件元数据
应用程序能够通过调用stat和fstat函数，检索到关于文件的信息（有时也称为文 件的元数据（metadata))。
#include <unistd.li>
#include <sys/stat.h>
int stat(const chair ♦filename, struct stat *buf); int fstat(int fd, struct stat *buf);
返回：若成功则为0，若出错则为一 1。
stat函数以一个文件名作为输人，并填写如图10~9所示的一个stat数据结构中的 各个成员。fstat函数是相似的，只不过是以文件描述符而不是文件名作为输入。当我们 在11.5节中讨论界钆服务器时，会需要#杜数据结构中的#_1：1〇扣和31:_3：1找成员， 其他成员则不在我们的讨论之列。
-------------------------------statbuf.h (included by sys/stat.h)
/* Metadata returned by the stat and fstat functions */	•
struct stat •(
dev_t	st.dev;	/*	Device */	
ino_t	st_ino;	/*	inode */	
mode.t	st_mode;	/*	Protection and file type */	
nlink.t	st_nlink;	/* Number of hard links */		
uid.t	st.uid;	/*	User ID of owner */	
gid一t	st^gid;	/*	Group ID of owner */	
dev_t	st_rdev;	h	Device type (if inode device!)	
off _t	st.size;	/*	Total size, in bytes */	
unsigned long st_blksize;		A	Block size for filesystem i/o	*/
unsigned long st.blocks;		/*	Number of blocks allocated */	
	st.atime;	/* Time of last access */		
	st_mtime;	h	Time of last modification */	
time_t	st_ctime; /* Time of last change */
>；
----------------------------------------------------------statbuf.h (included by sys/stat.h)
阁10-9 stat数据结构
st_size成员包含了文件的字节数大小。st_mode成员则编码了文件访问许可位（图
10-2)和文件类型（10.2节）。Linux在sys/stat.h中定义了宏谓词来确定st_m〇de成员 的文件类型：
S_ISREG(m)。这是一个普通文件吗？
S_ISDIR(m)。这是一个目录文件吗？
S_lSSOCK(m)。这是一个网络套接字吗？
图10-10展示了我们会如何使用这些宏和stat函数来读取和解释一个文件的st_ mode 位。
第JO章系统级I/O 633
code/io/statcheck. c
1	#include "csapp.h"
2
3	int main (int argc, char **argv)
4	{
5	struct stat stat;
6	char *type, *readok;
7
8	Stat(argv[l] , festat);
9	if (S_ISREG(stat.st_mode))	/* Determine file type */
10	type - "regular";
11	else if (S_ISDIR(stat.st_mode))
12	type »	"directory";
13	else
14	type =	"other";
15	if ((stat.st_mode & S_IRUSR)) /* Check read access */
16	readok	= "yes";
17	else
18	readok	= "no";
19
20	printf("type: %s, read: %s\n", type, readok);
21	exit(0);
22	}
code/io/statcheck.c
图10-10 查询和处理一个文件的stjnode位
10.7读取目录内容
应用程序可以用readdir系列函数来读取目录的内容。
#include <sys/types.h>
#include <dirent.h>
DIR *opendir(const char *name);
返回：若成功，则为处理的指针；若出错，则为NULL。
函数opendir以路径名为参数，返回指向目录流（directory stream)的指针。流是对 条目有序列表的抽象，在这里是指目录项的列表。
#include <dirent.h>
struct dirent *readdir(DIR *dirp);
返回：若成功，则为指向下一个目录项的指针；若没有更多的目录项或出错，則为null。
每次对readdir的调用返回的都是指向流dirp中下一个目录项的指针，或者，如果 没有更多目录项则返回NULL。每个目录项都是一个结构，其形式如下： struct dirent {
ino_t d_ino;	/* inode number */
char d_name[256]; /* Filename */
>；
虽然有些Linux版本包含了其他的结构成员，但是只有这两个对所有系统来说都是标
634 第三部分程序间的交亙和通信
准的。成员d_name是文件名，d_ino是文件位置。
如果出错，则readdir返回NULL，并设置errno。可惜的是，唯一能区分错误和 流结束情况的方法是检查自调用readdir以来errno是否被修改过。
#include <dirent.li>	
int closedir(DIR *dirp);	返回：成功为0;错误为一1。
函数closedir关闭流并释放其所有的资源。图10-11展示了怎样用readdir来读取 目录的内容。
1	#include Mcsapp.h"	
3	int main(int argc, char **argv)	
5	DIR *streamp;	
6	struct dirent *dep;	
8	streamp = Opendir(argv[l]);	
10	errno = 0;	
n	while ((dep = readdir(streamp)) != NULL) {	
12	printf("Found file:	7〇s\n", dep~>d_name);
14	if (errno != 0)	
15	unix_error("readdir	error*');
17	Closedir(streajnp);	
18 19	exit(0); >	
	1?! 10-11	读取目录的内容
code/io/readdir.c
code/io/readdir.c
10.8 共享文件
可以用许多不同的方式来共享Linux文件。除非你很清楚内核是如何表示打开的文 件，否则文件共享的概念相当难懂。内核用三个相关的数据结构来表示打开的文件：
•描述符表（descriptor table)。每个进程都有它独立的描述符表，它的表项是由进程 打开的文件描述符来索引的。每个打开的描述符表项指向文件表中的一个表项。
*文件表(file table)。打开文件的集合是由一张文件表来表示的，所有的进程共享这 张表。每个文件表的表项组成（针对我们的目的）包括当前的文件位置、引用计数 (reference count)(即当前指向该表项的描述符表项数），以及一个指向v-node表中 对应表项的指针。关闭一个描述符会减少相应的文件表表项中的引用计数。内核不 会删除这个文件表表项，直到它的引用计数为零。
第JO聿系统级J/0	635
• v-node表(v-nodetable)。同文件表一样，所有的进程共孚这张v-node表。每个表 项包含stat结构中的大多数信息，包括st_mode和st_size成员。
图10-12展示了一个示例，其中描述符1和4通过不同的打开文件表表项来引用两个 不同的文件。这是一种典型的情况，没有共享文件，并且每个描述符对应一个不同的 文件。
描述符表	打开文件表	v-node表
(每个进程一张表）	（所有进程共享）	（所有进程共享）
阁HM2典型的打开文件的内核数据结构，在这个示例中，
两个描述符引用不同的文件。没有共享
如图10-13所示，多个描述符也可以通过不同的文件表表项来引用同一个文件。例 如，如果以同一个filename调用open函数两次，就会发生这种情况。关键思想是每个 描述符都有它自己的文件位置，所以对不同描述符的读操作可以从文件的不同位置获取 数据。
描述符表
文件位置 refcnt=l
文件位置
文件访问 文件大小 文件类型
文件访问 文件大小 文件类型
图 10-13
我们也能理解父子进程是如何共享文件的。假设在调用fork之前，父进程有如图10-12 所示的打开文件。然后，图10-14展示了调用fork后的情况。子进程有一个父进程描 述符表的副本。父子进程共享相同的打开文件表集合，因此共享相同的文件位置。一个 很重要的结果就是，在内核删除相应文件表表项之前，父子进程必须都关闭了它们的描 述符。
E)
打开文件表
(所有进程共享） 文件A
v-node表 (所有进程共享)
文件共享。这个例子展示了两个描述符通过两个 打开文件表表项共享同一个磁盘文件
636 第三部分程序间的交互和通信
图10-】4子进程如何继承父进程的打开文件。初始状态如图10-12所示 g练习题10. 2 假设磁盘文件foobar.txt由6个ASCII码字符“foobar”组成。那
么，	下列程序的输出是什么？		
1	#include "csapp.h'*		
3	int mainO i		
5	\ int fdl, fd2;		
6	char c;		
7 8	fdl = OpenC'f oobar.txt",	0_RD0NLY,	〇);
9	fd2 = OpenC'foobar .txt",	0_RD0NLY,	〇)；
10	Read(fdl, &c, 1);		
11	Read(fd2, &c, 1);		
12	printf(”c = %c\n", c);		
13	exit(0);		
14	>		
@练习题10. 3 就像前面那样，假设磁盘文件foobar.txt由6个ASCII码字符“foobar” 组成。那么下列程序的输出是什么？
1	#include "csapp.h"	
3	int	mainO
A		
5		int fd;
6 7		char c;
8		fd = OpenC'foobar .txt" , 0_RD0NLY,
9		if (Fork() == 0) {
10		ReadCfd, &c, 1);
11		exit(0);
12		>
13		Wait(NULL);
14		Read(fd， &c, 1);
15		printWc = %c\nN, c);
16		exit(0);
17	>	
描述符表 父进程的表
打开文件表
(所有进程共享） 文件A
v-node表 (所有进程共享)
文件访问 文件大小 文件类型
文件访问
文件大小 文件类型
文件位置 refcnt=2
文件B
生程的荖
文件位置！ refcnt=2
第70章系统级I/O 637
dup2函数复制描述符表表项oldfd到描述符表表项newfd，覆盖描述符表表项new-fd以前的内容。如果newfd已经打开了，dup2会在复制oldfd之前关闭newfd。
假设在调用duP2(4,l)之前，我们的状态如图10-12所示，其中描述符1(标准输出） 对应于文件A(比如一个终端），描述符4对应于文件B(比如一个磁盘文件）。A和B的引 用计数都等于1。图10-15显示了调用duP2(4,l>之后的情况。两个描述符现在都指向文 件B;文件A已经被关闭了，并且它的文件表和v-node表表项也已经被删除了；文件B 的引用计数已经增加了。从此以后，任何写到标准输出的数据都被重定向到文件B。
描述符表	打开文件表	v-node表
图KM5通过调用dup2(4,l)重定向标准输出之后的内核数据至
左边和右边的hoinkies
为了避免和其他括号类型操作符比如“]”和“[”相混淆，我们总是将shel丨的 “>”操作符称为“右hoinky”，而将“<”操作符称为“左hoinky”。
练习题10. 4 如何用dup2将标准输入重定向到描述符5?
练习题〗0.5 假设磁盘文件foobar.txt由6个ASCII码字符“foobar”组成，那 么下列程序的输出是什么？
1	#include "csapp.h"
2
3 int mainO
refcnt=2
(所有进程共享）
坚
!
\~xWmm
	文件访问
	文件大小
	文件类型
	
吉构。初始状态如图10-12所示
进程一张表）
(所有进程共享） 文件A
	: L
	\ |文件位置i
	\ !refcnt=〇!
	
10.9 I/O重定向
Lmux shell提供了 I/O重定向操作符，允许用户将磁盘文件和标准输入输出联系起 来。例如，键人
linux> Is > foo.txt
使得shell加载和执行Is程序，将标准输出重定向到磁盘文件foo.txt。就如我们将在
11.	5节中看到的那样，当一个Web服务器代表客户端运行CGI程序时，它就执行一种相 似类型的重定向。那么I/O重定向是如何工作的呢？ 一种方式是使用duP2函数。
#include <unistd.h>
int dup2(int oldfd, int newfd);
返回：若成功则为非负的描述符，若出错則为一1。
旁注
fdfdwfdfd
638 第三部分程序间的交互和通信
4			
5	int fdl, fd2;		
6	char c;		
7 8	fdl = Open (_'f oobar.txt"，	O.RDONLY,	〇)；
9	fd2 = OpenC'foobar .txt",	0_RD0NLY,	〇)；
10	Read(fd2, &c, 1);		
11	Dup2(fd2, fdl);		
12	Read(fdl, &c, 1);		
13	printf("c = %c\n", c);		
14	exit(0);		
15	>		
10.	10 标准 I/O
C语言定义了一组高级输人输出函数，称为标准I/O库，为程序员提供了 Unix I/O 的较高级别的替代。这个库（libc)提供了打开和关闭文件的函数（fopen和fclose)、读 和写字节的函数（fread和fwrite)、读和写字符串的函数（fgets和fputs),以及复杂 的格式化的I/O函数（scanf和printf)。	.
标准I/O库将一个打开的文件模型化为一个流。对于程序员而言，一个流就是一个指 向FILE类型的结构的指针。每个ANSIC程序开始时都有三个打开的流stdin、stdout 和stderr，分别对应于标准输人、标准输出和标准错误：
#include <stdio.h>
extern FILE *stdin; /* Standard input (descriptor 0)本/ extern FILE *stdout; /* Standard output (descriptor 1) */ extern FILE *stderr; /* Standard error (descriptor 2) */
类型为FILE的流是对文件描述符和流缓冲区的抽象。流缓冲区的目的和RIO读缓冲 区的一样：就是使开销较高的Linux I/O系统调用的数量尽可能得小。例如，假设我们有 一个程序，它反复调用标准丨/0的getc函数，每次调用返回文件的下一个字符。当第一 次调用getc时，库通过调用一次read函数来填充流缓冲区，然后将缓冲区中的第一个 字节返回给应用程序。只要缓冲区中还有未读的字节，接下来对getc的调用就能直接从 流缓冲区得到服务。
10.	11综合：我该使用哪些I/O函数？
图10-16总结了我们在这一章里讨论过的各种I/O包。
fopen	fdopen
fread	fwrite
fscanf	fprintf
sscanf	sprintf
fgets	fputs
fflush	f seek
fclose	
	C应用程序	
标准I/O函数		R10函数
Unix I/O 函数 (通过系统调用来访问）		
open	read
write	lseek
stat	close
rio_readn rio_writen .• rio_readini 匕 b rio_readlineb rio_readnb
图10-16 Unix I/O、标准I/O和RIO之间的关系
第20章系统级I/O 639
Unix I/O模型是在操作系统内核中实现的。应用程序可以通过诸如open、close、 lseek、read、write和stat这样的函数来访问Unix I/O。较高级别的RI〇和标准I/O 函数都是基于（使用）Unix I/O函数来实现的。RIO函数是专为本书开发的read和write 的健壮的包装函数。它们自动处理不足值，并且为读文本行提供一种高效的带缓冲的方 法。标准I/O函数提供了 Unix I/O函数的一个更加完整的带缓冲的替代品，包括格式化 的 I/O 例程，如 printf 和 scanf。
那么，在你的程序中该使用这些函数中的哪一个呢？下面是一些基本的指导原则：
•G1:只要有可能就使用标准I/O。对磁盘和终端设备I/O来说，标准I/O函数是首 选方法。大多数C程序员在其整个职业生涯中只使用标准1/0,从不受较低级的 Unix I/O函数的困扰（可能stat除外，因为在标准I/O库中没有与它对应的函 数）。只要可能，我们建议你也这样做。
•	G2:不要使用scanf或rio_readlineb来读二进制文件。像scanf或rio_read-lineb这样的函数是专门设if来读取文本文件的。学生通常会犯的一个错误^是用 这些函数来读取二进制文件，这就使得他们的程序出现了诡异莫测的失败。比如， 二进制文件可能散布着很多Oxa字节，而这些字节又与终止文本行无关。
•	G3:对网络套接字的I/O使用RI◦函数。不幸的是，当我们试着将标准1/◦用于 网络的输人输出时，出现了一些令人讨厌的问题。如同我们将在11.4节所见， Linux对网络的抽象是一种称为套接字的文件类型。就像所有的Linux文件一样， 套接字由文件描述符来引用，在这种情况下称为套接字描述符。应用程序进程通过 读写套接字描述符来与运行在其他计算机的进程实现通信。
标准〗/〇流，从某种意义上而言是全双工的，因为程序能够在同一个流上执行输人和 输出。然而，对流的限制和对套接字的限制，有时候会互相冲突，而又极少有文档描述这 些现象：
•限制一：跟在输出函数之后的输入函数。如果中间没有插人对fflush、fseek、
_ fsetpos或者rewind的调用，一个输人函数不能跟随在一个输出函数之后。 fflush函数清空与流相关的缓冲区。后三个函数使用Unix I/O lseek函数来重置 当前的文件位置。
•限制二：跟在输入函数之后的输出函数。如果中间没有插人对fseek、fsetpos或 者rewind的调用，一个输出函数不能跟随在一个输人函数之后，除非该输人函数 遇到了一个文件结束。
这些限制给网络应用带来了一个问题，因为对套接字使用Iseek函数是非法的。对流 I/O的第一个限制能够通过采用在每个输人操作前刷新缓冲区这样的规则来满足。然而， 要满足第二个限制的唯一办法是，对同一个打开的套接字描述符打开两个流，一个用来 读，一个用来写：
FILE pin, *fpout;
fpin. = fdopen(sockfd, "r");
fpout = fdopen(sockfd, "w");
但是这种方法也有问题，因为它要求应用程序在两个流上都要调用fclose，这样才 能释放与每个流相关联的内存资源，避免内存泄漏：
fclose(fpin);
fclose(fpout);
640 第三部分程序间的交互和通信
这些操作中的每一个都试图关闭同一个底层的套接字描述符，所以第二个close操作 就会失败。对顺序的程序来说，这并不是问题，但是在一个线程化的程序中关闭一个已经 关闭了的描述符是会导致灾难的（见12. 7. 4节）。
因此，我们建议你在网络套接字上不要使用标准I/O函数来进行输人和输出，而要使 用健壮的RIO函数。如果你需要格式化的输出，使用sprintf函数在内存中格式化一个 字符串，然后用ri〇_writen把它发送到套接口。如果你需要格式化输人，使用rio_ readlineb来读一个完整的文本行，然后用sscanf从文本行提取不同的字段。
10.	12 小结
Linux提供了少量的基于Unixl/O模型的系统级函数，它们允许应用程序打开、关闭、读和写文件， 提取文件的元数据，以及执行I/O重定向a Linux的读和写操作会出现不足值，应用程序必须能正确地 预计和处理这种情况。应用程序不应直接调用Unix I/O函数，而应该使用RIO包，RIO包通过反复执行 读写操作，直到传送完所有的请求数据，自动处理不足值。
Linux内核使用三个相关的数据结构来表示打开的文件。描述符表中的表项指向打开文件表中的表 项，而打开文件表中的表项又指向v-node表中的表项。每个进程都有它自己单独的描述符表，而所有的 进程共享同一个打开文件表和v-node表。理解这些结构的一般组成就能使我们清楚地理解文件共享和 I/O重定向。	’
标准I/O库是基于Unix I/O实现的，并提供了一组强大的高级I/O例程。对于大多数应用程序而 言，标准I/O更简单，是优于Unix I/O的选择。然而，因为对标准I/O和网络文件的一些相互不兼容的 限制，Unix I/O比之标准I/O更该适用于网络应用程序。
参考文献说明
Kenrisk撰写了关于Unix I/O和Linux文件系统的综述[62]。Stevens编写了 Unix VO的标准参考 文献[m]。Kernighan和Ritchie对于标准I/O函数给出了清晰而完整的讨论[61]。
家庭作业
*10.6 下面程序的输出是什么？
1	#include "csapp.h"
2
3	int main()
4	i
5	int fdl, fd2;
6
7	fdl = OpenC'foo.txt", O.RDONLY, 0);
8	fd2 =* Open("bar.txt", O.RDONLY, 0);
9	Close (fd2)；
10	fd2 = OpenC'baz.txt", 0_RD0NLY, 0);
11	printf("fd2 = %d\n\ fd2);
12	exit(O);
13	>
10.7修改图10-5中所示的cpfile程序，使得它用RIO函数从标准输人复制到标准输出，—次MAX-BUF个字节。
10.8 编写图10-10中的statcheck程序的一个版本，叫做fstatcheck，它从命令行上取得一个描述符 数字而不是文件名。
10.9考虑下面对作业题10.8中的fstatcheck程序的调用：
lin\xx> fstatcheck 3 < foo.txt
你可能会预想这个对fstatcheck的调用将提取和显示文件f00.txt的元数据。然而，当我们在
第川章系统鈒J/0	641
系统上运行它时，它将失败，返回“坏的文件描述符”。根据这种情况，填写出shell在fork和 execve调用之间必须执行的伪代码：
if (Fork() == 0) { /* child */
/* What code is the shell executing right here? */
ExecveC'fstatcheck", axgv, envp);
>
10.	10修改图10-5中的cpfile程序，使得它有一个可选的命令行参数infile。如果给定了 infile， 那么复制infile到标准输出，否则像以前那样复制标准输人到标准输出。一个要求是对于两种 情况，你的解答都必须使用原来的复制循环(第9〜：L1行）。只允许你插人代码，而不允许更改任 何已经存在的代码。
练习题答案
10.	1 Unix进程生命周期开始时，打开的描述符赋给了 stdin(描述符0)、stdout(描述符1)和stderr (描述符2)。open函数总是返回最低的未打开的描述符，所以第一次调用open会返回描述符3。 调用close函数会释放描述符3。最后对open的调用会返回描述符3,因此程序的输出是“fd2=3”D 10.2描述符fdl和fd2都有各自的打开文件表表项，所以每个描述符对于foobar.txt都有它自己的 文件位置。因此，从fd2的读操作会读取foobar.txt的第一个字节，并输出 c = f
而不是像你开始可能想的
C = 〇
10.3回想一下，子进程会继承父进程的描述符表，以及所有进程共享的同一个打开文件表。因此，描 述符fd在父子进程中都指向同一个打开文件表表项。当子进程读取文件的第一个字节时，文件位 置加1。因此，父进程会读取第二个字节，而输出就是
C = 〇
10. 4重定向标准输人（描述符0)到描述符5，我们将调用dup2(5,0>或者等价的dup2(5,STDIN_FILE-N0)o
10.5第一眼你可能会想输出应该是 c » f
但是因为我们将fdl重定向到了 fd2,输出实际上是
第11章
网络编程
网络应用随处可见。任何时候浏览Web、发送email信息或是玩在线游戏，你就正在 使用网络应用程序。有趣的是，所有的网络应用都是基于相同的基本编程模型，有着相似 的整体逻辑结构，并且依赖相同的编程接口。
网络应用依赖于很多在系统研究中已经学习过的概念。例如，进程、信号、字节顺 序、内存映射以及动态内存分配，都扮演着重要的角色。还有一些新概念要掌握。我们需 要理解基本的客户端-服务器编程模型，以及如何编写使用因特网提供的服务的客户端-服 务器程序。最后，我们将把所有这些概念结合起来，开发一个虽小但功能齐全的Web服 务器，能够为真实的Web浏览器提供静态和动态的文本和图形内容。
11.	1客户端-服务器编程模型	.
每个网络应用都是基于客户端-服务器模型的。采用这个模型，一个应用是由一个服 务器进程和一个或者多个客户端进程组成。服务器管理某种资源，并且通过操作这种资源 来为它的客户端提供某种服务。例如，一个Web服务器管理着一组磁盘文件，它会代表 客户端进行检索和执行。一个FTP服务器管理着一组磁盘文件，它会为客户端进行存储 和检索。相似地，一个电子邮件服务器管理着一些文件，它为客户端进行读和更新。
客户端-服务器模型中的基本操作是事务（transaction)(见图11-1)。一个客户端-服务 器事务由以下四步组成。
1)	当一个客户端需要服务时，它向服务器发送一个请求，发起一个事务。例如，当 Web浏览器需要一个文件时，它就发送一个请求给Web服务器。
2)	服务器收到请求后，解释它，并以适当的方式操作它的资源。例如，当Web服务 器收到浏览器发出的请求后，它就读一个磁盘文件。
3)	服务器给客户端发送一个响应，并等待下一个请求。例如，Web服务器将文件发 送回客户端。
4)	客户端收到响应并处理它。例如，当Web浏览器收到来自服务器的一页后，就在 屏幕上显示此页。
认识到客户端和服务器是进程，而不是常提到的机器或者主机，这是很重要的。一台 主机可以同时运行许多不同的客户端和服务器，而且一个客户端和服务器的事务可以在同 一台或是不同的主机上。无论客户端和服务器是怎样映射到主机上的，客户端-服务器模 型都是相同的。
图11-1 一个客户端-服务器事务
第11章网络编程 643
旁注
客户端-服务器事务与数据库事务
客户端4反务器事务不是数据库事务，没有数据库事务的任何特性，例如原子性。 在我们的上下文中，事务仅仅是客户端和服务器执行的一系列步骤。
11.2	网络
客户端和服务器通常运行在不同的主机上，并且通过计算机网络的硬件和软件资源来 通信。网络是很复杂的系统，在这里我们只想了解一点皮毛。我们的目标是从程序员的角 度给你一个切实可行的思维模型。
对主机而言，网络只是又一种I/O设备，是数据源和数据接收方，如图11-2所示。
—个插到I/O总线扩展槽的适配器提供了到网络的物理接口。从网络上接收到的数据 从适配器经过I/O和内存总线复制到内存，通常是通过DMA传送。相似地，数据也能从 内存复制到网络。
CPU芯片
图11-2	—个网络主机的硬件组成
物理上而言，网络是一个按照地理远近组成的层次系统。最低层是LAN(Local Area Network，局域网），在一个建筑或者校园范围内。选今为止，最流行的局域网技术是以 太网（Ethernet),它是由施乐公司帕洛阿尔托研究中心（Xerox PARC)在20世纪70年代 中期提出的。以太网技术被证明是适应力极强的，从3Mb/S演变到lOGb/s。
一个以太网段（Ethernet segment)包括一些电缆（通常是双绞线）和一个叫做集线器的 小盒子，如图11-3所示。以太网段通常跨越一些小的区域，例如某建筑物的一个房间 或者一个楼层。每根电缆都有相同的最大位带宽，通常是l〇〇Mb/S或者lGb/s。一端连 接到主机的适配器，而另一端则连接到集线器的一个 端口上。集线器不加分辨地将从一个端口上收到的每 个位复制到其他所有的端口上。因此，每台主机都能 看到每个位。
每个以太网适配器都有一个全球唯一的48位地址，
它存储在这个适配器的非易失性存储器上。一台主机可
m 11-3以太网段
644	第三部分程序间的交互和通信
以发送一段位(称为帧（frame))到这个网段内的其他任何主机。每个帧包括一些固定数量 的头部（header)位，用来标识此帧的源和目的地址以及此帧的长度，此后紧随的就是数据 位的有效载荷（payload)。每个主机适配器都能看到这个帧，但是只有目的主机实际读 取它。
使用一些电缆和叫做网桥（bridge)的小盒子，多个以太网段可以连接成较大的局域网， 称为桥接以太网（bridged Ethernet),如图11-4所示。桥接以太网能够跨越整个建筑物或 者校区。在一个桥接以太网里，一些电缆连接网桥与网桥，而另外一些连接网桥和集线 器。这些电缆的带宽可以是不同的。在我们的示例中，网桥与网桥之间的电缆有IGb/s的 带宽，而四根网桥和集线器之间电缆的带宽却是l〇〇Mb/S。
A	B
C
图11-4桥接以太网
网桥比集线器更充分地利用了电缆带宽。利用一种聪明的分配算法，它们随着时间自 动学习哪个主机可以通过哪个端口可达，然后只在有必要时，有选择地将帧从一个端口复 制到另一个端口。例如，如果主机A发送一个帧到同网段上的主机B，当该帧到达网桥X 的输入端口时，X就将丢弃此帧，因而节省了其他网段上的带宽。然而，如果主机A发送 一个帧到一个不同网段上的主机C,那么网桥X只会把此帧复制到和网桥Y相连的端口 上，网桥Y会只把此帧复制到与主机C的网段连接的端口。
为了简化局域网的表示，我们将把集线器和网桥以及连接它们的电缆画成一根水平 线，如图11-5所示。
在层次的更高级别中，多个不兼容的局域网可以通过叫做路由器（router)的特殊计算 机连接起来，组成一个internet(互联网络）。每台路由器对于它所连接到的每个网络都有 一个适配器（端口）。路由器也能连接高速点到点电话连接，这是称为WAN(Wide-Area Network,广域网）的网络示例，之所以这么叫是因为它 们覆盖的地理范围比局域网的大。一般而言，路由器可以 用来由各种局域网和广域网构建互联网络。例如，图11-6 展示了一个互联网络的示例，3台路由器连接了一对局域 网和一对广域网。
第11章网络编程 645
图11-6 —个小型的互联网络。三台路由器连接起两个局域网和两个广域网
旁注
我们总是用小写字母的internet描述一般概念，而用大写字母的Internet来描述一 种具体的实现，也就是所谓的全球IP因特网。
互联网络至关重要的特性是，它能由采用完全不同和不兼容技术的各种局域网和广域 网组成。每台主机和其他每台主机都是物理相连的，但是如何能够让某台源主机跨过所有 这些不兼容的网络发送数据位到另一台目的主机呢？
解决办法是一层运行在每台主机和路由器上的协议软件，它消除了不同网络之间的差 异。这个软件实现一种协议，这种协议控制主机和路由器如何协同工作来实现数据传输。 这种协议必须提供两种基本能力：
•命名机制。不同的局域网技术有不同和不兼容的方式来为主机分配地址。互联网络 协议通过定义一种一致的主机地址格式消除了这些差异。每台主机会被分配至少一 个这种互联网络地址（internet address)，这个地址唯一地标识了这台主机。
•传送机制。在电缆上编码位和将这些位封装成帧方面，不同的联网技术有不同的和 不兼容的方式。互联网络协议通过定义一种把数据位捆扎成不连续的片（称为包）的 统一方式，从而消除了这些差异。一个包是由包头和有效载荷组成的，其中包头包 括包的大小以及源主机和目的主机的地址，有效载荷包括从源主机发出的数据位。
.图11-7展示了主机和路由器如何使用互联网络协议在不兼容的局域网间传送数据的 一个示例。这个互联网络示例由两个局域网通过一台路由器连接而成。一个客户端运行在 主机A上，主机A与LAN1相连，它发送一串数据字节到运行在主机B上的服务器端， 主机B则连接在LAN2上。这个过程有8个基本步骤：
1)	运行在主机A上的客户端进行一个系统调用，从客户端的虚拟地址空间复制数据 到内核缓冲区中。
2)	主机A上的协议软件通过在数据前附加互联网络包头和LAN1帧头，创建了一个 LAN1的帧。互联网络包头寻址到互联网络主机B。LAN1帧头寻址到路由器。然后它传 送此帧到适配器。注意，：LAN1帧的有效载荷是一个互联网络包，而互联网络包的有效载 荷是实际的用户数据。这种封装是基本的网络互联方法之一。
3)	LAN1适配器复制该帧到网络上。
4)	当此帧到达路由器时，路由器的LAN1适配器从电缆上读取它，并把它传送到协 议软件。
5)	路由器从互联网络包头中提取出目的互联网络地址，并用它作为路由表的索引， 确定向哪里转发这个包，在本例中是LAN2。路由器剥落旧的LAN1的帧头，加上寻址到 主机B的新的LAN2帧头，并把得到的帧传送到适配器。
6)	路由器的LAN2适配器复制该帧到网络上。
646	第三部分程序间的交互和通信
7)	当此帧到达主机B时，它的适配器从电缆上读到此帧，并将它传送到协议软件。
8)	最后，主机B上的协议软件剥落包头和帧头。当服务器进行一个读取这些数据的 系统调用时，协议软件最终将得到的数据复制到服务器的虚拟地址空间。
	主机A	主机B		
	客户端		服务端	
(1)丨数据丨		：		(8)1数据I
互联网络包	协议软件	|协议软件		
(2)丨数据 |PH |FHl|				(7)丨数据丨PH |FH2|
LAN1 帧	LAN1 适配器		LAN2 适配器	
LAN1
LAN1		LAN2
适配器		适配器
j (6) |数据|PH丨而习
+W邊發热卿難、.如说絲私妯
			
(4)丨数据 |PH |FHl|			
	协议软件		
LAN2 帧
LAN2
|数据丨PH (5)
m 11-7在互联网络上，数据是如何从一台主机传送到另一台主机的（PH:互联网络包头； FH1: LAN1的帧头；FH2: LAN2的帧头）
当然，在这里我们掩盖了许多很难的问题。如果不同的网络有不同帧大小的最大值，该怎 么办呢？路由器如何知道该往哪里转发帧呢？当网络拓扑变化时，如何通知路由器？如果一个 包丟失了又会如何呢？虽然如此，我们的示例抓住了互联网络思想的精髓，封装是关键。
11.3 全球IP因特网
全球IP因特网是最著名和最成功的互联网络实现。从1969年起，它就以这样或那样 的形式存在了。虽然因特网的内部体系结构复杂而且不断变化，但是自从20世纪80年代 早期以来，客户端-服务器应用的组织就一直保持着相当的稳定。图11-8展示了一个因特 网客户端-服务器应用程序的基本硬件和软件组织。
互联网络客户端主机
互联网络服务器主机
套接字接口 (系统调用）
硬件接口（中断)
图11-8 —个因特网应用程序的硬件和软件组织
每台因特网主机都运行实现 TCP/IP 协议（Transmission Control Protocol/lnternet
第n章网络编程 m
Protocol，传输控制协议/互联网络协议）的软件，几乎每个现代计算机系统都支持这个协 议。因特网的客户端和服务器混合使用套接字接口函数和Unix I/O函数来进行通信（我们 将在11.4节中介绍套接字接口）。通常将套接字函数实现为系统调用，这些系统调用会陷 入内核，并调用各种内核模式的TCP/IP函数。
TCP/IP实际是一个协议族，其中每一个都提供不同的功能。例如，IP协议提供基本 的命名方法和递送机制，这种递送机制能够从一台因特网主机往其他主机发送包，也叫做 数据报(datagram)。IP机制从某种意义上而言是不可靠的，因为，如果数据报在网络中丢 失或者重复，它并不会试图恢复。UDPCUnreliable Datagram Protocol，不可靠数据报协 议)稍微扩展了 IP协议，这样一来，包可以在进程间而不是在主机间传送。TCP是一个构 建在IP之上的复杂协议，提供了进程间可靠的全双工（双向的）连接。为了简化讨论，我 们将TCP/IP看做是一个单独的整体协议。我们将不讨论它的内部工作，只讨论TCP和 IP为应用程序提供的某些基本功能。我们将不讨论UDP。
从程序员的角度，我们可以把因特网看做一个世界范围的主机集合，满足以下特性：
•主机集合被映射为一组32位的IP地址。
•这组IP地址被映射为一组称为因特网域名（Internet domain name)的标识符。
•因特网主机上的进程能够通过连接(connection)和任何其他因特网主机上的进程通信。
接下来三节将更详细地讨论这些基本的因特网概念。
旁注
最相的因特网协议，使用32位地址，称为因特网协议版本4(Internet Protocol Version 4，IPv4)。1996 年，因特网工程任务组织（Internet Engineering Task Force， IETF)提出了一个新版本的IP,称为因特网协议版本6(IPv6),它使用的是128位地址， 意在替代IPv4。但是直到2015年，大约20年后，因特网流量的绝大部分还是由IPv4 网络承载的。例如，只有4%的访问Google服务的用户使用IPv6 [42]。
.因为IPv6的使用率较低，本书不会讨论IPv6的细节，而只是集中注意力于IPv4 背后的概念。当我们谈论因特网时，我们指的是基于IPv4的因特网。但是，本章后面 介绍的书写客户端和服务器的技术是基于现代接口的，与任何特殊的协议无关。
11.	3. 1 IP 地址
一个IP地址就是一个32位无符号整数。网络程序将IP地址存放在如图11-9所示的 IP地址结构中。
-----------------------------------------------------------------------code/netp/netpfragments, c
/* IP address structure */ struct in.addr {
uint32_t s_addr; /* Address in network byte order (big-endian) */
>；
-----------------------------------------------------------------------code/netp/netpfragments. c
图11-9 IP地址结构
把一个标量地址存放在结构中，是套接字接口早期实现的不幸产物。为IP地址定义一 个标量类型应该更有意义，但是现在更改已经太迟了，因为已经有大量应用是基于此的。
因为因特网主机可以有不同的主机字节顺序，TCP/IP为任意整数数据项定义了统一的 网络字节顺序(network byte order)(大端字节顺序），例如IP地址，它放在包头中跨过网络被
648 第三部分程序间的交互和通信
携带。在IP地址结构中存放的地址总是以（大端法）网络字节顺序存放的，即使主机字节顺序 (host byte order)是小端法。Unix提供了下面这样的函数在网络和主机字节顺序间实现转换。
#include <arpa/inet .h.>	
uint32_t htonl(uint32_t hostlong); uintl6_t hton.s(uintl6_t hostshort);	返回：按照网络字节顺序的值=
uint32_t ntolil(uint32_t netlong); uintl6_t ntohs(unitl6_t netshort);	返回：按照主机字节顺序的值。
hotnl函数将32位整数由主机字节顺序转换为网络字节顺序。ntohl函数将32位整 数从网络字节顺序转换为主机字节。htons和ntohs函数为16位无符号整数执行相应的 转换。注意，没有对应的处理64位值的函数。
IP地址通常是以一种称为点分十进制表示法来表示的，这里，每个字节由它的十进 制值表示，并且用句点和其他字节间分开。例如，128.2.194.242就是地址Ox80〇2c2f2 的点分十进制表示。在Linux系统上，你能够使用HOSTNAME命令来确定你自己•主机 的点分十进制地址：
linux> hostname -i 128.2.210.175
应用程序使用inet_pt〇n和inet_ntop函数来实现IP地址和点分十进制串之间的转换。
#include <arpa/inet.h>
int inet_ptonCAF_INET, const char *src, void *dst);
返回：若成功则为1,若Six为非法点分十进制地址则为0，若出错则为一 u const char *inet_ntop(AF_INET, const void *src, char *dst, socklen_t size);
返回：若成功则指向点分十进制字符串的指针，若出错则为NULL,
在这些函数名中，“n”代表网络，“p”代表表示。它们可以处理32位IPV4地址（AF_IN-ET)(就像这里展示的那样），或者128位IPv6地址（AF_INET6)(这部分我们不讲）。
inetjton函数将一个点分十进制串（src)转换为一个二进制的网络字节顺序的IP地 址（dst)。如果src没有指向一个合法的点分十进制字符串，那么该函数就返回〇。任何 其他错误会返回一 1，并设置errno。相似地，inet_nt〇P函数将一个二进制的网络字节 顺序的IP地址（src)转换为它所对应的点分十进制表示，并把得到的以null结尾的字符串 的最多size个字节复制到dst。 g练习题11.1完成下表：
十六进制地址	点分十进制地址
0x0	
Oxffffffff	
0x7f000001	
	205.188.160.121
	64.12.149.13
	205.188.146.23
第11章网络编程 649
&练习题11.2编写程序hex2dd.c，将它的十六进制参数转换为点分十进制串并打印 出结果。例如
linux> ./hex2dd 0x8002c2f2 128.2.194.242
g练习题11.3编写程序dd2hex.c，将它的点分十进制参数转换为十六进制数并打印 出结果。例如
linux> ./dd2hex 128.2.194.242 0x8002c2f2
11.3.2因特网域名
因特网客户端和服务器互相通信时使用的是IP地址。然而，对于人们而言，大整数 是很难记住的，所以因特网也定义了一组更加人性化的域名（domain name)，以及一种将 域名映射到IP地址的机制。域名是一串用句点分隔的单词（字母、数字和破折号），例如
whaleshark.ics.cs.cmu.edu。
域名集合形成了一个层次结构，每个域名编码了它在这个层次中的位置。通过一个示 例你将很容易理解这点。图11-10展示了域名层次结构的一部分。层次结构可以表示为一 棵树。树的节点表示域名，反向到根的路径形成了域名。子树称为子域（subdomain)。层 次结构中的第一层是一个未命名的根节点。下一层是一组一级域名（first-level domain name)，由非营利组织 ICANN(Internet Corporation for Assigned Names and Numbers， 因特网分配名字数字协会）定义。常见的第一层域名包括com、edu、gov、org和net。
未命名的根
mit emu berkeley
amazon
176.32.98.166
第一层域名 第二层域名 第三层域名
m li-io因特网域名层次结构的一部分
下一层是二级（second-level)域名，例如emu. edu，这些域名是由ICANN的各个授权 代理按照先到先服务的基础分配的。一旦一个组织得到了一个二级域名，那么它就可以在 这个子域中创建任何新的域名了，例如cs.cmu.edu。
因特网定义了域名集合和IP地址集合之间的映射。直到1988年，这个映射都是通过 一个叫做H0STS.TXT的文本文件来手工维护的。从那以后，这个映射是通过分布世界范 围内的数据库(称为DNSCDomainNameSystem，域名系统））来维护的。从概念上而言， DNS数据库由上百万的主机条目结构（host entry structure)组成，其中每条定义了一组域 名和一组IP地址之间的映射。从数学意义上讲，可以认为每条主机条目就是一个域名和
650 第三部分程序间的交互和通信
IP地址的等价类。我们可以用Linux的NSLOOKUP程序来探究DNS映射的一些属性， 这个程序能展示与某个IP地址对应的域名。e
每台因特网主机都有本地定义的域名localhost，这个域名总是映射为回送地址 (loopback address) 127.0.0.1：
linux> nslookup localhost Address: 127.0.0.1
localhost名字为引用运行在同一台机器上的客户端和服务器提供了一种便利和可移植 的方式，这对调试相当有用。我们可以使用HOSTNAME来确定本地主机的实际域名：
linux> hostname whaleshcirk. ics. cs. emu. edu
在最简单的情况中，一个域名和一个IP地址之间是一一映射：
linux> nslookup whalesha^k.ics.cs. emu.edu Address: 128.2.210.175
然而，在某些情况下，多个域名可以映射为同一个IP地址：
linux> nslookup cs.mit.edu Address: 18.62.1.6
linux> nslookup eecs.mit.edu Address: 18.62.1.6
在最通常的情况下，多个域名可以映射到同一组的多个IP地址：
linux> nslookup ww.twitter.com Address: 199.16.156.6 Address: 199.16.156.70 Address: 199.16.156.102 Address: 199.16.156.230
limix> nslookup twitter.com Address: 199.16.156.102 Address: 199.16.156.230 Address: 199.16.156.6 Address: 199.16.156.70
最后，我们注意到某些合法的域名没有映射到任何IP地址:
linux> nslookup edu
*** Can't find edu: No answer
linux> nslookup ics.cs.cmu.edu
*** Can't find ics.cs.cmu.edu: No answer
旁注
有多少因特网主机？
因特网软件协会(Internet Software Consortium，www. isc*org)自从1987年以后，每年进 行两次因特网域名调查。这个调查通过计算已经分配给一个域名的IP地址的数量来估算因特 网主机的数量，展示了一种令人吃惊的趋势。自从1987年以来，当时一共大约有20 000台因特 网主机，主机的数量已经在指数性增长。到2015年，已经有大约1000000000台因特网主机了。
㊀我们重新调整了 NSLOOKUP的输出以提髙可读性。
第11章网络编程 651
11. 3. 3因特网连接
因特网客户端和服务器通过在连接上发送和接收字节流来通信。从连接一对进程的意 义上而言，连接是点对点的。从数据可以同时双向流动的角度来说，它是全双工的。并且 从(除了一些如粗心的耕锄机操作员切断了电缆引起灾难性的失败以外）由源进程发出的字 节流最终被目的进程以它发出的顺序收到它的角度来说，它也是可靠的。
一个套接字是连接的一个端点。每个套接字都有相应的套接字地址，是由一个因特网 地址和一个16位的整数端口 e组成的，用“地址：端口”来表示。
当客户端发起一个连接请求时，客户端套接字地址中的端口是由内核自动分配的，称 为临时端口（ephemeral port)。然而，服务器套接字地址中的端口通常是某个知名端口， 是和这个服务相对应的。例如，Web服务器通常使用端口 80,而电子邮件服务器使用端 口 25。每个具有知名端口的服务都有一个对应的知名的服务名。例如，Web服务的知名 名字是http，email的知名名字是smtp。文件/etc/services包含一张这台机器提供的 知名名字和知名端口之间的映射。
一个连接是由它两端的套接字地址唯一确定的。这对套接字地址叫做套接字对（socket pair),由下列元组来表示：
(cliaddr: cliport, servaddr: servport)
其中cliaddr是客户端的IP地址，cliport是客户端的端口，servaddr是服务器的IP 地址，而servport是服务器的端口。例如，图11-11展示了一个Web客户端和一个Web 服务器之间的连接。
客户端套接字地址	服务器套接字地址
128.2.194.242:51213	208.216.181.15:80
客户端主机地址	服务器主机地址
128.2.194.242	208.216.181.15
图11-11因特网连接分析
在这个示例中，Web客户端的套接字地址是 128.2.194.242:51213
其中端口号51213是内核分配的临时端口号。Web服务器的套接字地址是 208.216.181.15:80
其中端口号80是和Web服务相关联的知名端口号。给定这些客户端和服务器套接字地 址，客户端和服务器之间的连接就由下列套接字对唯一确定了：
(128.2.194.242:51213, 208.216.181.15:80)
旁注
因特网的起源
因特网是政府、学校和工业界合作的最成功的示例之一。它成功的因素很多，但是 我们认为有两点尤其重要：美国政府30年持续不变的投资，以及充满激情的研究人员
©这些软件端口与网络中交换机和路由器的硬件端口没有关系。
652 第三部分程序间的交互和通信
对麻省理工学院的Dave Clarke提出的“粗略一致和能用的代码”的投入。
因特网的种子是在1957年播下的，其时正值冷战的高峰，苏联发射Sputnik，第一颗人 造地球卫星，震惊了世界。作为响应，美国政府创建了高级研究计划署（ARPA)，其任务就 是重建美国在科学与技术上的领导地位。1967年，ARPA的Lawrence Roberts提出了 一个计 划，建立一个叫做ARPANET的新网络。第一个ARPANET节点是在1969年建立并运行的。 到1971年，已有13个ARPANET节点，而且email作为第一个重要的网络应用涌现出来。
1972年，Robert Kahn概括了网络互联的一般原则：一组互相连接的网络，通过叫 做“路由器”的黑盒子按照“以尽力传送作为基础”在互相独立处理的网络间实现通 信。1974年，Kahri和Vinton Cerf发表了 TCP/IP协议的第一本详细资料，到1982年 它成为了 ARPANET的标准网络互联协议。1983年1月1日，ARPANET的每个节点 都切换到TCP/IP，标志着全球1P因特网的诞生。
1985年，PaulMockapetris发明了 DNS，有1000多台因特网主机。1986年，国家 科学基金会（NSF)用56KB/s的电话线连接了 I3个节点，构建了 NSFNET的骨干网。 其后在1988年升级到1.5MB/sTl的连接速率，1991年为45MB/sT3的连接速率。到 1988年，有超过50 000台主机。1989年，原始的ARPANET正式退休了。199彳年， 已经有几乎10 000 000台因特网主机了，NSF取消了 NSFNET，并且用基于由公众网 络接入点连接的私有商业骨干网的现代因特网架构取代了它。
11.4 套接字接口
套接字接口（socket interface)是一组函数，它们和Unix I/O函数结合起来，用以创建 网络应用。大多数现代系统上都实现套接字接口，包括所有的Unix变种、Windows和 Macintosh系统。图11-12给出了一个典型的客户端-服务器事务的上下文中的套接字接口 概述。当讨论各个函数时，你可以使用这张图来作为向导图。
客户端	服务器
图11-12 基于套接字接口的网络应用概述
第11章网络编程 653
旁注
套接字接口是加州大学伯克利分校的研究人员在20世纪80年代早期提出的。因为 这个原因，它也经常被叫做伯克利套接字。伯克利的研究者使得套接字接口适用于任何 底层的协议。第一个实现的就是针对TCP/IP协议的，他们把它包括在Unix 4. 2BSD的 内核里，并且分发给许多学校和实验室。这在因特网的历史上是一个重大事件。几乎一 夜之间，成千上万的人们接触到了 TCP/IP和它的源代码。它引起了巨大的轰动，并激 发了新的网络和网络互联研究的浪潮。
11.4. 1套接字地址结构
从Linux内核的角度来看，一个套接字就是通信的一个端点。从Unmc程序的角度来 看，套接字就是一个有相应描述符的打开文件。
因特网的套接字地址存放在如图11-13所示的类型为S〇ckaddr_in的16字节结构中。 对于因特网应用，sin_family成员是AF_INET，sin_port成员是一个16位的端口号， 而sin_addr成员就是一个32位的：IP地址。IP地址和端口号总是以网络字节顺序（大端 法)存S的。
/木 IP socket address structure */
code/netp/netpfragments. c
struct sockaddr_in {
uintl6_t	sin_family;	/*
uintl6_t	sin_port;	/*
struct in_addr	sin_addr;	/*
unsigned char	sin.zero [8];	/*
h
Protocol family (always AF_INET) */ Port number in network byte order */ IP address in network byte order */ Pad to sizeof(struct sockaddr) */
/* Generic socket address structure (for connect, bind, and accept) */ struct sockaddr {
uintl6_t sa_family; /* Protocol family */ char	sa_data[14];	/* Address data */
y；
----------------------------------------------------------code/netp/netpfragments.c
图11-13 套接字地址结构
_in后缀意味什么？
.in后缀是互联网络（internet)的缩写，而不是输入（input)的缩写。
connect、bind和accept函数要求一个指向与协议相关的套接字地址结构的指针。 套接字接口的设计者面临的问题是，如何定义这些函数，使之能接受各种类型的套接字地 址结构。今天我们可以使用通用的void*指针，但是那时在C中并不存在这种类型的指 针。解决办法是定义套接字函数要求一个指向通用sockaddr结构（图1KL3)的指针，然 后要求应用程序将与协议特定的结构的指针强制转换成这个通用结构。为了简化代码示 例，我们跟随Steven的指导，定义下面的类型： typedef struct sockaddr SA;
然后无论何时需要将sockaddr_in结构强制转换成通用sockaddr结构时，我们都使用 这个类型。
旁注
654 第三部分程序间的交互和通信
11.	4. 2 socket 函数
客户端和服务器使用socket函数来创建一个套接字描述符（socket descriptor)。
#include <sys/types.h>
#include <sys/socket.h>
int socket(int domain, int type, int protocol);
返回：若成功则为非负描述符，若出错则为一 1。
如果想要使套接字成为连接的一个端点，就用如下硬编码的参数来调用socket函数： clientfd = Socket(AF_INET, SOCK_STREAM, 0);
其中，AF_INET表明我们正在使用32位IP地址，而SOCK_STREAM表示这个套接字 是连接的一个端点。不过最好的方法是用getaddrinfo函数（11. 4. 7节）来自动生成这些 参数，这样代码就与协议无关了。我们会在II.4. 8节中向你展示如何配合socket函数来 使用 getaddrinfo。
socket返回的clientfd描述符仅是部分打开的，还不能用于读写。如何完成.打开 套接字的工作，取决于我们是客户端还是服务器。下一节描述当我们是客户端时如何完成 打开套接字的工作。
11.	4. 3 connect 函数
客户端通过调用connect函数来建立和服务器的连接。
#include <sys/socket.h>
int connect(int clientfd, const struct sockaddr *addr, socklen_t addrlen);
返回：若成功则为0,若出错則为一1。
connect函数试图与套接字地址为addr的服务器建立一个因特网连接，其中addrlen 是sizeof (sockaddr_in)。connect函数会阻塞，一直到连接成功建立或是发生错误。如果 成功，clientfd描^符现在就准备好可以读写了，并且得到的连接是由套接字对 (x:y, addr.sin_addr:addr.sin.port)
刻画的，其中x表示客户端的IP地址，而y表示临时端口，它唯一地确定了客户端主机 上的客户端进程。对于socket，最好的方法是用getaddrinfo来为connect提供参数 (见 11.4.8 节）。
11. 4. 4 bind 函数
剩下的套接字函数----bind、listen和accept，服务器用它们来和客户端建立连接。
#include <sys/socket.h>
int bind(int sockfd, const struct sockaddr *addr, socklen_t addrlen);
返回：若成功则为〇,若出错则为一1。
第11章网络编程 655
bind函数告诉内核将addr中的服务器套接字地址和套接字描述符sockfd联系起 来。参数 addrlen 就是 sizeof(sockaddr_in)。对于 socket 和 connect，最好的方法 是用getaddrinfo来为bind提供参数（见11. 4. 8节）。
11.4.5	listen 函数
客户端是发起连接请求的主动实体。服务器是等待来自客户端的连接请求的被动实 体。默认情况下，内核会认为socket函数创建的描述符对应于主动套接字（active socket)， 它存在于一个连接的客户端。服务器调用 listen 函数告诉内核，描述符是被服务器 而不是客户端使用的。
#include <sys/socket.h>
int listenCint sockfd, int backlog);
返回：若成功则为0,若出错则为一1。
listen函数将sockfd从一个主动套接字转化为一个监听套接字（listening socket)， 该套接字可以接受来自客户端的连接请求。backlog参数暗示了内核在开始拒绝连接请求 之前，队列中要排队的未完成的连接请求的数量。backlog参数的确切含义要求对TCP/ IP协议的理解，这超出了我们讨论的范围。通常我们会把它设置为一个较大的值，比 如 1024。
11.4.6	accept 函数
服务器通过调用accept函数来等待来自客户端的连接请求。
#include <sys/socket.h>
int accept(int listenfd, struct sockaddr *addr, int ♦addrlen);
返回：若成功则为非负连接描述符，若出错则为一1。
accept函数等待来自客户端的连接请求到达侦听描述符listenfd，然后在addr中 填写客户端的套接字地址，并返回一个已连接描述符（connected descriptor)，这个描述符 可被用来利用Unix I/O函数与客户端通信。
监听描述符和已连接描述符之间的区别使很多人感到迷惑。监听描述符是作为客户端 连接请求的一个端点。它通常被创建一次，并存在于服务器的整个生命周期。已连接描述 符是客户端和服务器之间已经建立起来了的连接的一个端点。服务器每次接受连接请求时 都会创建一次，它只存在于服务器为一个客户端服务的过程中。
图11-14描绘了监听描述符和已连接描述符的角色。在第一步中，服务器调用 accept，等待连接请求到达监听描述符，具体地我们设定为描述符3。回忆一下，描述符 〇〜2是预留给了标准文件的。
在第二步中，客户端调用connect函数，发送一个连接请求到listenfd。第三步， accept函数打开了一个新的已连接描述符connfd(我们假设是描述符4)，在clientfd 和connfd之间建立连接，并且随后返回connfd给应用程序。客户端也从connect返回， 在这一点以后，客户端和服务器就可以分别通过读和写clientfd和cormfd来回传送数 据了。
656	第三部分程序间的交互和通信
客户端
listenfd(3)
服务器
clientfd
连接请求
listenfd(3)
客户端
-*6
服务器
clientfd
listenfd(3)
clientfd
connfd(4)
1.服务器阻塞在accept，等待监听 描述符listenfd上的连接请求，
2.客户端通过调用和阻塞在connect, 创建连接请求。
3.服务器从accept返回connfd,客户端 从connect返回。现在在clientfd和 connfd之间已经建立起了连接。
图11-14监听描述符和已连接描述符的角色
旁注
为何要有监听描述符和已连接描述符之间的区别？
你可能很想知道为什么套接字接口要区别监听描述符和已连接描述符。乍一看，这 像是不必要的复杂化。然而，区分这两者被证明是很有用的，因为它使得我们可以，建立 并发服务器，它能够同时处理许多客户端连接。例如，每次一个连接请求到达监听描述 符时，我们可以派生（fork)—个新的进程，它通过已连接描述符与客户端通信。在第12 章中将介绍更多关于并发服务器的内容。
11.4.7主机和服务的转换
Linux提供了一■些强大的函数(称为getaddrinfo和getnameinfo)实现二进制套接字地 址结构和主机名、主机地址、服务名和端口号的字符串表示之间的相互转化。当和套接字接 口一起使用时，这些函数能使我们编写独立于任何特定版本的IP协议的网络程序。
1.	getaddrinfo 函数
getaddrinfo函数将主机名、主机地址、服务名和端口号的字符串表示转化成套接 字地址结构。它是已弃用的gethostbyname和getservbyname函数的新的替代品。和以 前的那些函数不同，这个函数是可重入的（见12. 7.2节），适用于任何协议。
#include <sys/types.h>
#include <sys/socket.h>
#include <netdb.h>
int getaddrinfo(const char *host, const char ^service, const struct addrinfo *hints, struct addrinfo **result);
返回：如果成功則为〇，如果错误则为非零的错误代码。
void freeaddrinfo(struct addrinfo ^result);
const char *gai_strerror(int errcode);
返回：无。 返回：错误消息。
给定host和service(套接字地址的两个组成部分），getaddrinfo返回result， result —个指向addrinfo结构的链表，其中每个结构指向一个对应于host和service 的套接字地址结构（图11-15)。
第11章网络编程 657
图11-15 getaddrinfo返回的数据结构
在客户端调用了 getaddrinfo之后，会遍历这个列表，依次尝试每个套接字地址，直到调 用socket和connect成功，建立起连接。类似地，服务器会尝试遍历列表中的每个套接字地 址，直到调用socket和bind成功，描述符会被绑定到一个合法的套接字地址。为了避免内存 泄漏，应用程序必须在最后调用freeaddrinfo,释放该链表。如果getaddrinfo返回非零的 错误代码，应用程序可以调用gai_Streer〇r，将该代码转换成消息字符串。
getaddrinfo的host参数可以是域名，也可以是数字地址（如点分十进制IP地址）。 service参数可以是服务名（如http),也可以是十进制端口号。如果不想把主机名转换成地 址，可以把host设置为NULL。对service来说也是一样。但是必须指定两者中至少一个。
可选的参数hints是一个addrinfo结构（见图11-16)，它提供对getaddrinfo返回 的套接字地址列表的更好的控制。如果要传递hints参数，只能设置下列字段：以_1^111-ily、ai_socktype、ai_protocol和ai_flags字.段。其他字段必须设置为〇(或 NULL);实际中，我们用memset将整个结兵清零，然后有选择地设置一些字段：
•	getaddrinfo默认可以返回IPv4和IPv6套接字地址。ai_family设置为AF_IN-ET会将列表限制为IPv4地址；设置为AF _ INET6则限制为IPv6地址。
•对于host关联的每个地址，getaddrinfo函数默认最多返回三个addrinfo结构， 每个的ai_s〇cktype字段不同：一个是连接，一个是数据报（本书未讲述），一个 是原始套-字（本书未讲述）。ai_S〇cktyPe设置为SOCK_STREAM将列表限制为 对每个地址最多一个addrinfo结构，该结构的套接字地址可以作为连接的一个端 点。这是所有示例程序所期望的行为。
•	ai_f；UgS字段是一个位掩码，可以进一步修改默认行为。可以把各种值用OR组 合起来得到该掩码。下面是一些我们认为有用的值：
ALADDRCONFIG。如果在使用连接，就推荐使用这个标志[34]。它要求只有当 本地主机被配置为IPv4时，getaddrinfo返回IPv4地址。对IPv6也是类似。
AI—CANONNAME。ai_canonname字段默认为NULL。如果设置了该标志， 就是告诉getaddrinfo将列表中第一个addrinfo结构的ai_canonname字段指向 host的权威（官方）名字（见图11-15)。
658 第三部分程序间的交互和通信
AI_NUMERICSERV。参数service默认可以是服务名或端口号。这个标志 强制参数service为端口号。
AI_PASSIVE。getaddrinfo默认返回套接字地址，客户端可以在调用connect 时用作主动套接字。这个标志告诉该函数，返回的套接字地址可能被服务器用作监 听套接字。在这种情况中，参数host应该为NULL。得到的套接字地址结构中的 地址字段会是通配符地址（wildcard address)，告诉内核这个服务器会接受发送到该 主机所有IP地址的请求。这是所有示例服务器所期望的行为。
struct addrinf〇 {
int		ai_flags;	/*
int		ai_family;	/*
int		ai.socktype;	/*
int		ai_protocol;	/*
char		*ai_canonname;	h
size_t		ai_addrlen;	/木
struct	sockaddr	*ai_addr;	/*
struct	addrinfo	*ai_next;	/*
>J
-----------------------code/netp/netpfragments. c
Hints argument flags */
First arg to socket function */
Second arg to socket function */
Third arg to socket function */ Canonical hostname */
Size of ai.addr struct */
Ptr to socket address structure */
Ptr to next item in linked list */
-----------------------code/netp/netpfragments. c
图 11-16 getaddrinfo 使用的 addrinfo 结构
当getaddrinfo创建输出列表中的addrinfo结构时，会填写每个字段，除了 ai_ flags。ai_addr字段指向一个套接字地址结构，ai_addrlen字段给出这个套接字地址 结构的大小，而ai_next字段指向列表中下一个addrinfo结构。其他字段描述这个套接 字地址的各种属性。
getaddrinfo —个很好的方面是addrinfo结构中的字段是不透明的，即它们可以直 接传递给套接字接口中的函数，应用程序代码无需再做任何处理。例如，ai_family、ai_ socktype 和 ai_protocol 可以直接传递给 socket。类似地，ai_addr 和 ai_addrlen 可以直接传递给connect和bind。这个强大的属性使得我们编写的客户端和服务器能够 独立于某个特殊版本的IP协议。
2.	getnameinfo 函数
getnameinfo函数和getaddrinfo是相反的，将一个套接字地址结构转换成相应的 主机和服务名字符串。它是已弃用的gethostbyaddr和getservbyport函数的新的替代 品，和以前的那些函数不同，它是可重人和与协议无关的。
#include <sys/socket.h>
#include <netdb.h>
int getnameinfo(const struct sockaddr *sa, socklen_t salen, char *host, size_t hostlen, char ^service, size_t servlen, int flags);
返回：如果成功则为〇，如果错误则为非零的错误代码。
参数sa指向大小为salen字节的套接字地址结构，host指向大小为hostlen字节的缓 冲区，service指向大小为servlen字节的缓冲区^ getnameinfo函数将套接字地址结构sa 转换成对应的主机和服务名字符串，并将它们复制到host和servcice缓冲区。如果getnam-
第11章网络编程 659
einfo返回非零的错误代码，应用程序可以调用gai_Strerror把它转化成字符串。
如果不想要主机名，可以把host设置为NULL，hostlen设置为0。对服务字段来 说也是一样。不过，两者必须设置其中之一。
参数flags是一个位掩码，能够修改默认的行为。可以把各种值用OR组合起来得到 该掩码。下面是两个有用的值：
•	NI_NUMERICHOST。getnameinfo默认试图返回host中的域名。设置该标志会 使该函数返回一个数字地址字符串。
•	NI—NUMERICSERV。getnameinfo 默认会检查/etc/services，如果可肯巨，会返回 服务名而不是端口号。设置该标志会使该函数跳过查找，简单地返回端口号。
图11-17给出了一个简单的程序，称为HOSTINFO，它使用getaddrinfo和getnameinfo 展示出域名到和它相关联的IP地址之间的映射。该程序类似于11.3.2节中的NSLOOKUP 程序。
---------------------------------------------------code/netp/hostinfo.c
^ #include "csapp.h"
2
3	int main(int axgc, char **argv)
4	{
5	struct addrinfo *p, *listp, hints;
6	char buf [MAXLINE];
7	int rc, flags;
8
9	if (argc != 2)	{
10	fprintf(stderr, "usage: %s <domain name>\n", argv[0]);
11	exit(0);
12	>
13
14	/* Get a list of addrinfo records */
15	memsetC&hints,	0， sizeof(struct addrinfo));
16	hints.ai_family = AF_INET;	/* IPv4 only */
17	hints.ai_socktype = S0CK_STREAM; /* Connectioxis only */
18	if C(rc = getaddrinfo(argv[1], NULL, &hints, felistp)) != 0) {
19	fprintf (stderr, "getaddrinfo error: °/〇s\n", gai_strerror(rc));
20	exit(l);
21	>
22
23	/* Walk the	list	and display each IP address */
24	flags = NI_NUMERICH0ST; /* Display address string instead of domain name */
25	for (p = listp; p; p = p->ai—next) {
26	Getnameinfo(p->ai_addr, p->ai_addrlen, buf, MAXLINE, NULL, 0, flags);
27	printf("XsNri",	buf);
28	}
29
30	/* Clean up	*/
Bi	FreeaddrinfoClistp);
32
33	exit(0);
34	>
---------------------------------------------------code/netp/hostinfo.c
罔11-17 HOSTINFO展示出域名到和它相关联的IP地址之间的映射
660 第三部分程序间的交互和通信
首先，初始化hints结构，使getaddrinfo返回我们想要的地址。在这里，我们想 查找32位的IP地址(第16行），用作连接的端点（第17行）。因为只想getaddrinfo转换 域名，所以用service参数为NULL来调用它。
调用getaddrinfo之后，会遍历addrinfo结构，用getnameinfo将每个套接字地 址转换成点分十进制地址字符串。遍历完列表之后，我们调用freeaddrinfo小心地释放 这个列表（虽然对于这个简单的程序来说，并不是严格需要这样做的）。
运行HOSTINFO时，我们看到twitter.com映射到了四个IP地址，和11. 3.2节用 NSLOOKUP的结果一样。
linux> ./hostinfo twitter.com
199.16.156.102
199.16.156.230
199.16.156.6
199.16.156.70
练习题 11. 4 函数 getaddrinf◦和 getnameinfo 分别包含了 inet_pton 和 inet_ntop 的功能，提供了更高级别的、独立于任何特殊地址格式的抽象。想看看这到底有多方 便，编写HOSTINFO(图11-17)的一个版本，用inetjiton而不是getnameinfo将每个 套接字地址转换成点分十进制地址字符串。
11. 4. 8套接字接口的辅助函数
初学时，getnameinfo函数和套接字接口看上去有些可怕。用高级的辅助函数包装 一下会方便很多，称为open_clientfd和open_listenfd，客户端和服务器互相通信时 可以使用这呰函数。
1. open_clientfd 函数
客户端调用〇pen_clientfd建立与服务器的连接。
#include "csapp.h"
int open_clientf d(char *hostn.«ime, char *port);
返回：若成功则为描述符，若出错则为一1。
〇pen_Clientfd函数建立与服务器的连接，该服务器运行在主机hostname上，并在 端口号port上监听连接请求。它返回一个打开的套接字描述符，该描述符准备好了，可 以用1111丨乂1/0函数做输人和输出。图11-18给出了〇9611_<:1161^£(1的代码。
我们调用getaddrinfo，它返回addrinfo结构的列表，每个结构指向一个套接字地 址结构，可用于建立与服务器的连接，该服务器运行在hostname上并监听port端口。 然后遍历该列表，依次尝试列表中的每个条目，直到调用socket和connect成功。如果 connect失败，在尝试下一个条目之前，要小心地关闭套接字描述符。如果connect成 功，我们会释放列表内存，并把套接字描述符返回给客户端，客户端可以立即开始用 Unix I/O与服务器通信了。
注意，所有的代码都与任何版本的IP无关。socket和connect的参数都是用 getaddrinfo自动产生的，这使得我们的代码干净可移植。
2. openjistenfd 函数
调用〇pen_listenfd函数，服务器创建一个监听描述符，准备好接收连接请求。
第11章网络编程 661
#include "csapp.h"
int open_listenfd(char *port);
返回：若成功则为描述符，若出错则为一1。
---------------------------------------------------------code/src/csapp. c
1	int open_clientfd(char *hostname, char *port) {
2	int clientfd;
3	struct addrinfo hints, *listp, *p;
4
5	/* Get a list of potential server addresses */
6	memsetC&hints, 0, sizeof(struct addrinfo));
7	hints.ai_socktype = S0CK_STREAM;	/*	Open a connection */
8	hints.ai_flags = AI_NUMERICSERV;	/*	... using a numeric port arg. */
9	hints.ai_flags |= AI^ADDRCONFIG;	/*	Recommended for connections	*/
10	Getaddrinfo(hostname, port, fchints,	felistp);
11
12	/* Walk the list for one that we	can	successfully connect to */
13	for (p = listp; p; p = p->ai_next) {
14	/* Create a socket descriptor */
15	if ((clientfd = socket(p->ai_family, p->ai_socktype, p->ai_protocol))
16	< 〇) continue; /* Socket failed, try the next */
17
18
19
20 21
22	>
23
24	/* Clean up */
25 •	Freeaddrinfo(listp);
26	if (!p) /* Ail connects failed */
27	return -1;
28	else	/* The last connect succeeded */
29	return clientfd;
30	>
---------------------------------------------------------code/src/csapp. c
图n-〗8 open_ciientfd:和服务器建立连接的辅助函数。它是可重人和与协议无关的
openjistenfd函数打开和返回一个监听描述符，这个描述符准备好在端口 port上 接收连接请求。图11-19展示了 open_listenfd的代码。
open_listenfd的风格类似于open_clientfd。调用getaddrinfo，然后遍历结果列 表，直到调用socket和bind成功。注意，在第20行，我们使用setsockopt函数（本书中 没有讲述)来配置服务器，使得服务器能够被终止、重启和立即开始接收连接请求。一个重 启的服务器默认将在大约30秒内拒绝客户端的连接请求，这严重地阻碍了调试。
因为我们调用getaddrinfo时，使用了 AI_PASSIVE标志并将host参数设置为 NULL,每个套接字地址结构中的地址字段会被设置为通配符地址，这告诉内核这个服务 器会接收发送到本主机所有1P地址的请求。
/* Connect to the server */
if (connect(clientfd, p->ai_addr, p->ai_addrlen) != -1) break; /* Success */
Close(clientfd); /* Connect failed, try another */
662 第三部分程序间的交互和通信
code/src/csapp.c
1	int open_listenfd(char 本port)
2	{
3	struct addrinfo hints, *listp, *p;
4	int listenfd, optval=l;
5
6	/* Get a list of potential server addresses */
7	memset(&hints, 0, sizeof(struct addrinfo));
8	hints.ai_socktype = S0CK_STREAM;	/*	Accept	connections */
9	hints.ai_flags = AI_PASSIVE I AI.ADDRCONFIG;	/*	...	on	any IP address	*/
10	hints.ai_flags 1= AI_NUMEHICSERV;	/*	...	using port number	*/
11	Getaddrinfo(NULL, port, fehints, &listp);
12
13	/* Walk the list for one that we can	bind	to	*/
14	for (p = listp; p； p = p->ai_next) {
15	/* Create a socket descriptor */
16	if (Clistenfd = socket(p->ai_family, p->ai_socktype, p->ai_protocol))
17	< 0) continue; /* Socket failed, try the next */
18	_
19	/* Eliminates ’’Address already in use'1 error from bind */
20	Setsockopt(listenfd, S0L_S0CKET, S0_REUSEADDR,
21	(const void *)&optval ， sizeof(int));
22
23	/* Bind the descriptor to the address */
24	if (bind(listenfd, p->ai_addr, p->ai_addrlen) == 0)
25	break; /* Success */
26	Close(listenfd); /* Bind failed, try the next */
27	>
28
29	/* Clean up */
30	FreeaddrinfoClistp);
31	if (!p) /* No address	worked */
32	return -1;
33
34	/*	Make it a listening	socket	ready	to accept connection requests */
35	if	(listenClistenfd,	LISTENQ)	<	0)	{
36	Close(listenfd);
37	return -1;
38	>
39	return listenfd;
40	>
code/src/csapp.c
图n-19 〇pen_iistenfd:打开并返回监听描述符的辅助函数。它是可重人和与协议无关的
最后，我们调用listen函数，将listenfd转换为一个监听描述符，并返回给调用 者。如果listen失败，我们要小心地避免内存泄漏，在返回前关闭描述符。
1. 4. 9 echo客户端和服务器的示例
学习套接字接口的最好方法是研究市例代码。图11-20展示了 —个echo客户端的代
第11章网络编程 663
码。在和服务器建立连接之后，客户端进入一个循环，反复从标准输入读取文本行，发送 文本行给服务器，从服务器读取回送的行，并输出结果到标准输出。当fgets在标准输人 上遇到EOF时，或者因为用户在键盘上键人Ctd+D，或者因为在一个重定向的输人文件 中用尽了所有的文本行时，循环就终止。
---------------------------------code/netp/echodient.c
1
2
3
4
5
6
7
8 9
20
21
22
23
24
25
26
#include "csapp.h11
int main(int argc, char **argv)
{
int clientfd;
char *host, *port, buf[MAXLINE]; rio_t rio;
if (argc ! = 3) ■(
fprintf(stderr, "usage: %s <host> <port>\n", argv[0]); exit(0);
>
host = argv[l]; port = argv [2];
clientfd = Open_clientfd(host, port);
Rio_readinitb(&rio, clientfd);
while (Fgets(buf, MAXLINE, stdin) != NULL) {
Rio^writen(clientfd, buf, strlen(buf)); Rio_readlineb(&rio, buf, MAXLINE);
Fputs(buf, stdout);
>
Close(clientfd); exit(0);
code/netp/echodient.c
图11-20 echo客户端的主程序
循环终止之后，客户端关闭描述符。这会导致发送一个EOF通知到服务器，当服务 器从它的re〇_readliiieb函数收到一个为零的返回码时，就会检测到这个结果。在关闭 它的描述符后，客户端就终止了。既然客户端内核在一个进程终止时会自动关闭所有打开 的描述符，第24行的close就没有必要了。不过，显式地关闭已经打开的任何描述符是 一个良好的编程习惯。
图11-21展示了 echo服务器的主程序。在打开监听描述符后，它进人一个无限循环。 每次循环都等待一个来自客户端的连接请求，输出已连接客户端的域名和IP地址，并调 用echo函数为这些客户端服务。在echo程序返回后，主程序关闭已连接描述符。一旦客 户端和服务器关闭了它们各自的描述符，连接也就终止了。
第9行的clientaddr变量是一个套接字地址结构，被传递给accept。在accept返 回之前，会在clientaddr中填上连接另一端客户端的套接字地址。注意，我们将cli-entaddr 声明为 struct sockaddr_storage 类型，而不是 struct sockaddr_in 类型。 根据定义，sockaddr^torage结构足够大能够装下任何类型的套接字地址，以保持代码 的协议无关性。
664 第三部分程序间的交互和通信
code/netp/echoserveri. c
1	#include "csapp.h"
2
3	void echo(int connfd);
4
5	int main(int argc, char **argv)
6	{
7	int listenfd, connfd;
8	socklen_t clientlen;
9	struct sockaddr.storage	clientaddr;	/*	Enough	space for any address */
10	char client.hostname[MAXLINE],	client_port[MAXLINE];
11
12	if Cargc	!=	2)	{
13	fprintf (stderr, "usage: 7,s <port>\n" , axgv[0]);
14	exit(0);
15	>
16
17	listenfd	= Open_listenfd(argv[i]);
18	while (1)	{
19	clientlen = sizeof(struct sockaddr.storage);
20	connfd = Accept(listenfd, (SA *)&clientaddr, &clientlen);
21	Getnameinfo((SA *) &clientaddr, clientlen, client_h.ostname, MAXLINE,
22	client_port, MAXLINE, 0);
23	printf("Connected to (%s, %s)\n", client_hostname, client.port);
24	echo(connfd);
25	Close(connfd);
26	>
27	exit(0);
28	>
code/netp/echoserveri. c
图11-21迭代echo服务器的主程序
注意，简单的echo服务器一次只能处理一个客户端。这种类型的服务器一次一个地 在客户端间迭代，称为迭代服务器（iterative server)。在第12章中，我们将学习如何建立 更加复杂的并发服务器（concurrent server)，它能够同时处理多个客户端。
最后，图11-22展示了 echo程序的代码，该程序反复读写文本行，直到ri〇_readlineb 函数在第10行遇到EOF。
---------------------------------------------code/netp/echo. c
1	#include "csapp.h"
2
3	void echo(int connfd)
4	{
5	size_t n;
6	char buf[MAXLINE];
7	rio_t rio;
8
9	Rio_readinitb(&rio, connfd);
10	while((n = Rio_readlineb(&rio, buf, MAXLINE)) != 0) {
11	printf("server received %d bytes\n", (int)n);
12	Rio_writen(connfd, buf, n);
13	>	■
14	>
图11-22读和回送文本行的echo函数
code/netp/echo.c
第11章网络编程 665
旁注
在连接中EOF意味什么？
EOF的概念常常使人们感到迷惑，尤其是在因特网连接的上下文中。首先，我们 需要理解其实并没有像EOF字符这样的一个东西。进一步来说，EOF是由内核检测到 的一种条件。应用程序在它接收到一个由read函数返回的零返回码时，它就会发现出 EOF条件。对于磁盘文件，当前文件位置超出文件长度时，会发生EOF。对于因特网 连接，当一个进程关闭连接它的那一端时，会发生EOF。连接另一端的进程在试图读取 流中最后一个字节之后的字节时，会检测到EOF。
11.5 Web服务器
迄今为止，我们已经在一个简单的echo服务器的上下文中讨论了网络编程。在这一 节里，我们将向你展示如何利用网络编程的基本概念，来创建你自己的虽小但功能齐全的 Web服务器。
11. 5. 1 Web 基础
Web客户端和服务器之间的交互用的是一个基于文本的应用级协议，叫做HTTP (Hypertext Transfer Protocol，超文本传输协议）。HTTP是一个简单的协议。一个Web 客户端（即浏览器）打开一个到服务器的因特网连接，并且请求某些内容。服务器响应所请 求的内容，然后关闭连接。浏览器读取这些内容，并把它显示在屏幕上。
Web服务和常规的文件检索服务（例如FTP)有什么区别呢？主要的区别是Web内容 可以用一种叫做HTMLCHypertext Markup Language,超文本标记语言）的语言来编写。 一个HTML程序（页)包含指令(标记），它们告诉浏览器如何显示这页中的各种文本和图 形对象。例如，代码
<b> Make me bold! </b>
告诉浏览器用粗体字类型输出<b>和</1〇>标记之间的文本。然而，HTML真正的强大 之处在于一个页面可以包含指针（超链接），这些指针可以指向存放在任何因特网主机上的 内容。例如，一个格式如下的HTML行
<a href="http://www. emu.edu/index.html">Carnegie Mellon</a>
告诉浏览器高亮显示文本对象“Carnegie Mellon”，并且创建一个超链接，它指向存放 在CMU Web服务器上叫做index.html的HTML文件。如果用户单击了这个高亮文本 对象，浏览器就会从CMU服务器中请求相应的HTML文件并显示它。
旁注
万维网是TimBemertLee发明的，他是一位在瑞典物理实验室CERN(欧洲粒子物理研 究所）工作的软件工程师。1989年，Bemers-Lee写了一个内部备忘录，提出了一个分布式超文 本系统，它能连接“用链接组成的笔记的网（web of notes with links)'提出这个系统的目的是 帮助CERN的科学家共享和管理信息。在接下来的两年多里，Bemers^Lee实现了第一个Web服 务器和Web浏览器之后，在CERN内部以及其他一些网站中，Web发展出了小规模的拥护者。 1993年一个关键事件发生了，Marc Andreesen(他后来创建了 Netscape)和他在NCSA的同事发布 了一种图形化的浏览器，叫做MOSAIC，可以在三种主要的平台上所使用：Unix、Windows和 Macintosh。在MOSAIC发布后，对Web的兴趣爆发了，Web网站以每年10倍或更高的数量增 长。到2015年，世界上已经有超过975 000 000个Web网站了（源自NetcraftWeb Survey)。
666 第三部分程序间的交互和通信
11.5.2	Web 内容
对于Web客户端和服务器而言，内容是与一个MIME(Multipurpose Internet Mail Extensions,多用途的网际邮件扩充协议）类型相关的字节序列。图11-23展示了一些常用 的MIME类型。
MIME类型	描述
text/html text/plain application/postscript image/gif image/png image/jpeg	HTML页面 无格式文本 Postscript 文档 GIF格式编码的二进制图像 PNG格式编码的二进制图像 JPEG格式编码的二进制图像
m 11-23 MIME类型示例
Web服务器以两种不同的方式向客户端提供内容：
•取一个磁盘文件，并将它的内容返回给客户端。磁盘文件称为静态内容（static content)， 而返回文件给客户端的过程称为服务静态内容 （serving static content)。，
*运行一个可执行文件，并将它的输出返回给客户端。运行时可执行文件产生的输出 称为动态内容（dynamic content)，而运行程序并返回它的输出到客户端的过程称为 服务动态内容（serving dynamic content) 0
每条由Web服务器返回的内容都是和它管理的某个文件相关联的。这些文件中的每一个都 有一个唯一的名字，叫做URL(Universal Resource Locator，通用资源定位符)。例如，URL http: //www. google. com: 80/index. iitml
表示因特网主机www.google .com上一个称为/index.html的HTML文件，它是由一个 监听端口 80的Web服务器管理的。端口号是可选的，默认为知名的HTTP端口 80。可 执行文件的URL可以在文件名后包括程序参数。“？”字符分隔文件名和参数，而且每个 参数都用“&”字符分隔开。例如，URL
http://bluefish.ics.cs. emu.edu:8000/cgi-bin/adder?15000&213
标识了一个叫做/cgi- bin/adder的可执行文件，会带两个参数字符串15000和213来调用 它。在事务过程中，客户端和服务器使用的是URL的不同部分。例如，客户端使用前缀 http://www. google. com:80
来决定与哪类服务器联系，服务器在哪里，以及它监听的端口号是多少。服务器使用后缀 /index.html
来发现在它文件系统中的文件，并确定请求的是静态内容述是动态内容。
关于服务器如何解释一个URL的后缀，有几点需要理解：
*确定一个URL指向的是静态内容还是动态内容没有标准的规则。每个服务器对它 所管理的文件都有自己的规则。一种经典的（老式的）方法是，确定一组目录，例如 cgi-bin，所有的可执行性文件都必须存放这些目录中。
•后缀中的最开始的那个“/”不表示Linux的根目录。相反，它表示的是被请求内容 类型的主目录。例如，可以将一个服务器配置成这样：所有的静态内容存放在目录/ usr/httpd/html下，而所有的动态内容都存放在目录/usr/httpd/cgi-bin下。
第11章网络编程 667
_最小的URL后缀是“/”字符，所有服务器将其扩展为某个默认的主页，例如/index, html。这解释了为什么简单地在浏览器中键入一个域名就可以取出一个网站的主 页。浏览器在URL后添加缺失的“/”，并将之传递给服务器，服务器又把“/”扩 展到某个默认的文件名。
11.5.3	HTTP 事务
因为HTTP是基于在因特网连接上传送的文本行的，我们可以使用Linux的TELNET 程序来和因特网上的任何 Web 服务器执行事务。 对于调试在连接上通过文本行来与 客户端对话的服务器来说，TELNET程序是非常便利的。例如，图11-24使用TELNET 向AOL Web服务器请求主页。
	linux> telnet www.aol.com 80	Client: open connection to server
2	Trying 205.188.146.23...	Telnet prints 3 lines to the terminal
	Connected to aol.com.	
4	Escape character is * .	
5	GET / HTTP/1.1	Client： request line
6	Host: www.aol.com	Client： required HTTP/1.1 header
7		Client: empty line terminates headers
8	HTTP/1.0 200 OK	Server: response line
9	MIME-Version: 1.0	Server: followed by five response headers
10	Date: Mon, 8 Jan 2010 4:59:42 GMT	
11	Server: Apache-Coyote/1.1	
12	Content-Type: text/html	Server: expect HTML in the response body
13	Content-Length: 42092	Server: expect 42,092 bytes in the response body
14		Server: empty line terminates response headers
15	<html>	Server: first HTML line in response body
16		Server: 766 lines of HTML not shown
17	</html>	Server: last HTML line in response body
18 -	Connection closed by foreign host.	Server: closes connection
19	linux>	Client: closes connection and terminates
图11-24 —个服务静态内容的HTTP事务
在第1行，我们从Linux shell运行TELNET，要求它打开一个到AOL Web服务器的连 接。TELNET向终端打印三行输出，打开连接，然后等待我们输人文本(第5行）。每次输人 一个文本行，并键入回车键，TELNET会读取该行，在后面加上回车和换行符号（在C的表 示中为“\r\n”），并且将这一行发送到服务器。这是和HTTP标准相符的，HTTP标准要 求每个文本行都由一对回车和换行符来结束。为了发起事务，我们输人一个HTTP请求（第 5〜7行）。服务器返回HTTP响应(第8〜17行），然后关闭连接(第18行）。
1. HTTP请求
—个HTTP请求的组成是这样的：一个请求行（request line)(第5行），后面跟随零 个或更多个请求报头（request header)(第6行），再跟随一个空的文本行来终止报头列表 (第7行）。一个请求行的形式是 method URI version
HTTP 支持许多不同的方法，包括 GET、POST、OPTIONS、HEAD、PUT、DELETE 和TRACE：。我们将只讨论广为应用的G£丁方法，大多数H丁TP请求都是这种类型的。
668 第三部分程序间的交互和通信
GET方法指导服务器生成和返回URICUniform Resource Identifier,统一资源标识符）标 识的内容。URI是相应的URL的后缀，包括文件名和可选的参数。e
请求行中的version字段表明了该请求遵循的HTTP版本。最新的HTTP版本是 HTTP/1. 1[37]。HTTP/1.0是从1996年沿用至今的老版本[6]。HTTP/1. 1定义了一 些附加的报头，为诸如缓冲和安全等高级特性提供支持，它还支持一种机制，允许客户端 和服务器在同一条持久连接（persistent connection)上执行多个事务。在实际中，两个版本 是互相兼容的，因为HTTP/1. 0的客户端和服务器会简单地忽略HTTP/1. 1的报头。
总的来说，第5行的请求行要求服务器取出并返回HTML文件/index.html。它也 告知服务器请求剩下的部分是HTTP/1. 1格式的。
请求报头为服务器提供了额外的信息，例如浏览器的商标名，或者浏览器理解的 MIME类型。请求报头的格式为
header-name i header-data
针对我们的目的，唯一需要关注的报头是Host报头（第6行），这个报头在HTTP/1. 1请 求中是需要的，而在HTTP/1.0请求中是不需要的。代理缓存（proxy cache)会使用Host 报头，这个代理缓存有时作为浏览器和管理被请求文件的原始服务器（origin server)的中 介。客户端和原始服务器之间，可以有多个代理，即所谓的代理链（Proxy chain)。H〇st 报头中的数据指示了原始服务器的域名，使得代理链中的代理能够判断它是否可以在本地 缓存中拥有一个被请求内容的副本。
继续图11-24中的示例，第7行的空文本行（通过在键盘上键人回车键生成的）终止了 报头，并指示服务器发送被请求的HTML文件。
2. HTTP响应
HTTP响应和HTTP请求是相似的。一个HTTP响应的组成是这样的：一个响应行 (response line)(第8行），后面跟随着零个或更多的响应报头（response header)(第9~ 13 行），再跟随一个终止报头的空行(第14行），再跟随一个响应主体(response body)(第15~17 行）。一个响应行的格式是
version status-code status-message
version字段描述的是响应所遵循的HTTP版本。状态码（status-code)是一个3位的正整数， 指明对请求的处理。状态消息（status message)给出与错误代码等价的英文描述。图11-25列 出了一些常见的状态码，以及它们相应的消息。
状态代码	状态消息	描述
200	成功	处理请求无误
301	永久移动	内容已移动到location头中指明的主机上
400	错误请求	服务器不能理解请求
403	禁止	服务器无权访问所请求的文件
404	未发现	服务器不能找到所请求的文件
501	未实现	服务器不支持请求的方法
505	HTTP版本不支持	服务器不支持请求的版本
图11-25 —些HTTP状态码
©实际上，只有当浏览器请求内容时，这才是真的。如果代理服务器请求内容，那么这个URI必须是完整的 URL。
第11章网络编程 669
第9〜13行的响应报头提供了关于响应的附加信息。针对我们的目的，两个最重要的 报头是Content-Type(第12行），它告诉客户端响应主体中内容的MIME类型；以及 Content-Length(第13行），用来指7K响应主体的字节大小。
第14行的终止响应报头的空文本行，其后跟随着响应主体，响应主体中包含着被请 求的内容。	■
11.5.4服务动态内容
如果我们停下来考虑一下，一个服务器是如何向客户端提供动态内容的，就会发现一 些问题。例如，客户端如何将程序参数传递给服务器？服务器如何将这些参数传递给它所 创建的子进程？服务器如何将子进程生成内容所需要的其他信息传递给子进程？子进程将 它的输出发送到哪里？ 一个称为CGI(Common Gateway Interface,通用网关接口）的实际 标准的出现解决了这些问题。
1.客户端如何将程序参数传递给服务器
GET请求的参数在URI中传递。正如我们看到的，一个“?”字符分隔了文件名和参 数，而每个参数都用一个“&”字符分隔开。参数中不允许有空格，而必须用字符串“％20” 来表示。对其他特殊字符，也存在着相似的编码。
旁注
在HTTP POST请求中传递参数
HTTP POST请求的参数是在请求主体中而不是URI中传递的。
2.	服务器如何将参数传递给子进程
在服务器接收一个如下的请求后
GET /cgi-bin/adder?15000&213 HTTP/1.1
它调用fork来创建一个子进程，并调用execve在子进程的上下文中执行/cgi-bin/ad-def程序。像adder这样的程序，常常被称为CGI程序，因为它们遵守CGI标准的规则。 而且，因为许多CGI程序是用Perl脚本编写的，所以CGI程序也常被称为CGI脚本。在 调用execve之前，子进程将CGI环境变量QUERY_STRING设置为“15000&213”，adder 程序在运行时可以用 Linux getenv 函数来引用它。
3.	服务器如何将其他信息传递给子进程
CGI定义了大量的其他环境变量，一个CGI程序在它运行时可以设置这些环境变量。 图11-26给出了其中的一部分。
环境变量	描述
QUERY_STRING SERVER_PORT REQUEST_METHOD REMOTE_HOST REMOTE_ADDR CONTENTJTYPE CONTENT_LENGTH	程序参数 父进程侦听的端口 GET 或 POST 客户端的域名 客户端的点分十进制IP地址 只对POST而言：请求体的MINIE类型 只对POST而言：请求体的字节大小
图11-26 CGI环境变量示例
4.子进程将它的输出发送到哪里
一个CG1程序将它的动态内容发送到标准输出。在子进程加载并运行CGI程序之前，
670 第三部分程序间的交互和通信
它使用Linux dup2函数将标准输出重定向到和客户端相关联的已连接描述符。因此，任 何CGI程序写到标准输出的东西都会直接到达客户端。
注意，因为父进程不知道子进程生成的内容的类型或大小，所以子进程就要负责生成 Content- type和Content- length响应报头，以及终止报头的空行。
图11-27展示了一个简单的CGI程序，它对两个参数求和，并返回带结果的HTML 文件给客户端。图11-28展示了一个HTTP事务，它根据adder程序提供动态内容。
code/netp/tiny/cgi-bin/adder. c
1	#include "csapp.h"
2
3	int main(void) {
4	char *buf, *p;
5	char argl[MAXLINE], arg2[MAXLINE], content[MAXLINE];
6	int nl=0, n2=0;
8
12
13
15
16
17
18
19
20 21 22
23
24
25
27
29
30
32
33
34
/* Extract the two arguments */ if ((buf = getenv("QUERY_STRINGM>) != NULL) { p = strchr(buf,
*p = '\0_;
strcpy(argl, buf); strcpy(arg2, p+1); nl = atoi(argl); n2 = atoi(arg2);
>
/* Make the response body */
sprintf(content, "QUERY_STRING=%s", buf);
sprintf (content, "Welcome to add.com: ’’〉；
sprintf(content, "%sTHE Internet addition portal.\r\n<p>", content); sprintf (content, "7*sThe answer is: %d + %d = %d\r\n<p>", content, nl, n2, nl + n2);
sprintf(content, "%sThanks for visiting!\r\n", content);
/* Generate the HTTP response */ printf("Connection: close\r\n");
printf ("Content-length: %d\r\n", (iiit)strleii(coiitent)); printf("Content-type: text/html\r\n\r\n"); printf("%s", content); fflush(stdout);
exit(0);
图11-27 对两个整数求和的CGI程序
code/netp/tiny/cgi-bin/adder.c
第J]章河络编程 671
	linux> telnet kittyhawk.cmcl.cs.cmu.edu 8000		Client: open connection
2	Trying 128.2.194.242...		
	Connected to kittyh.awk.cuicl.cs.cmu.edu		
4	Escape character is		
5	GET /cgi-bin/adder?15000&213 HTTP/1.0	Client	request line
6		Client	empty line terminates headers
7	HTTP/1.0 200 OK	Server	response line
8	Server: Tiny Web Server	Server	identify server
9	Content-length: 115	Adder:	expect 115 bytes in response body
10	Content-type: text/html	Adder:	expect HTML in response body
11		Adder:	empty line terainates headers
12	Welcome to add.com: THE Internet addition portal. Adder： first HTML line		
13	<p>The answer is: 15000 + 213 = 15213	Adder:	second HTML Hue in response body
14	<p>Thanks for visiting!	Adder:	third HTML line in response body
15	Connection closed by foreign host.	Server	closes connection
16	linux>	Client	closes connection and terminates
图11-28 —个提供动态HTML内容的HTTP事务
旁注
将HTTP POST请求中的参数传递给CGI程序
对于POST请求，子进程也需要重定向标准输入到已连接描述符。然后，CGI程序 会从标准输入中读取请求主体中的参数。
g练习题11. 5在10. 11节中，我们警告过你关于在网络应用中使用C标准I/O函数的 危险。然而，图11-27中的CGI程序却能没有任何问题地使用标准1/(\为什么呢？
11.6综合：TINY Web服务器
我们通过开发一个虽小但功能齐全的称为TINY的Web服务器来结束对网络编程的 讨论。TINY是一个有趣的程序。在短短250行代码中，它结合了许多我们已经学习到的 思想，例如进程控制、Unix 1/0、套接字接口和HTTP。虽然它缺乏一个实际服务器所具 备的功能性、健壮性和安全性，但是它足够用来为实际的Web浏览器提供静态和动态的 内容。我们鼓励你研究它，并且自己实现它。将一个实际的浏览器指向你自己的服务器， 看着它显示一个复杂的带有文本和图片的Web页面，真是非常令人兴奋（甚至对我们这些 作者来说，也是如此！）。
1.	TINY 的 main 程序
图11-29展示了 TINY的主程序。TINY是一个迭代服务器，监听在命令行中传递来 的端口上的连接请求。在通过调用〇pen_liStenfd函数打开一个监听套接字以后，TINY 执行典型的无限服务器循环，不断地接受连接请求（第32行），执行事务（第36行），并关 闭连接的它那一端(第37行）。
2.	doit函数
图11-30中的doit函数处理一个HTTP事务。首先，我们读和解析请求行（第11〜 14行）。注意，我们使用图11-8中的ri〇_readlineb函数读取请求行。
TINY只支持GET方法。如果客户端请求其他方法（比如POST)，我们发送给它一 个错误信息，并返回到主程序（第15〜19行），主程序随后关闭连接并等待下一个连接请 求。否则，我们读并且(像我们将要看到的那样)忽略任何请求报头（第20行）。
672 第三部分程序间的交互和通信
----------------------------------------------------------------------code/netp/tiny/tiny.c
1 /*
2	* tiny.c - A simple, iterative HTTP/1.0 Web server that uses the
3	* GET method to serve static and dynamic content
4	*/
5	#include "csapp.h"
6
7	void doit(int fd);
8	void read_requesthdrs(rio_t *rp);
9	int parse_uri(cliar *uri, char 本filename， char *cgiargs);
10	void serve_static(int fd, char ^filename, int filesize);
11	void get_filetype(char ^filename, char iletype);
12	void serve_dynamic(int fd, char *filename, char 木cgiargs);
13	void clienterror(int fd, char *cause, char *errmnn,
14	char *shortmsg, char *longmsg);
15
16	int main(int argc, char **axgv)
17	{
18	int listenfd, connfd;
19	char hostname[MAXLINE],	port[MAXLINE];	•
20	socklen_t clientlen;
21	struct sockaddr_storage	clientaddr;
22
23	/* Check command-line args */
24	if (argc != 2) {
25	f printf (stderr, "usage: 7〇s <port>\n", argv [0]);
26	exit(l);
27	>
28
29	listenfd = Open_listenfd(argv[l]);
30	while (1) {
31	clientlen = sizeof(clientaddr);
32	connfd = Accept(listenfd, (SA *)&clientaddr, &clientlen);
33	Getnameinfo((SA *) &clientaddr, clientlen, hostname, MAXLINE,
34	port, MAXLINE, 0);
35	printf ("Accepted	connection	from (%s, %s)\n’_, hostname, port);
B6	doit(connfd);
37	Close(connfd);
38	>
39	>
code/netp/tiny/tiny.c
图11-29 TINY Web服务器
然后，我们将URI解析为一个文件名和一个可能为空的CGI参数字符串，并且设置 一个标志，表明请求的是静态内容还是动态内容（第23行）。如果文件在磁盘上不存在， 我们立即发送一个错误信息给客户端并返回。
最后，如果请求的是静态内容，我们就验证该文件是一个普通文件，而我们是有读权 限的（第31行）。如果是这样，我们就向客户端提供静态内容（第36行）。相似地，如果请 求的是动态内容，我们就验证该文件是可执行文件(第39行），如果是这样，我们就继续, 并且提供动态内容（第44行）。
第11章网络编程 673
code/netp/tiny/tiny. c
1
2
5
6
7
8
10
11
12
1B
14
15
16
17
18
19
20 21 22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
void doit(int fd)
int is_static; struct stat sbuf;
char buf [MAXLINE], method[MAXLINE], uri[MAXLINE], version[MAXLINE]; char filename[MAXLINE], cgiargs[MAXLINE]; rio_t rio;
/* Read request line and headers */ Rio_readinitb(&rio, fd);
Rio_readlinebC&rio, buf, MAXLINE); printf("Request headers:\n"); printf("%s", buf);
sscanf(buf, "%s %s %s", method, uri, version); if (strcasecmp(method, "GET")) {
clienterror(fd, method, "501", "Not implemented", "Tiny does not implement this method");
return;
>
read_requesthdrs(&rio);
/* Parse URI from GET request */
is_static - parse.uri(uri, filename, cgiargs);
if (stat(filename, fesbuf) < 0) {
clienterror(fd, filename, "404", "Not found", "Tiny couldn't find this file");
return;
>
if (is.static) { /* Serve static content */
if (! (S_ISREG(sbuf .st_mode))丨丨! (S_IRUSR & sbxif . st_mode) ) { clienterror(fd, filename, "403", "Forbidden",
"Tiny couldn't read the file");
return;
>
serve_static(fd, filename, sbuf.st_size);
}
else { /* Serve dynamic content */
if (!(S_ISREG(sbuf.st_mode)) II !(S_IXUSR & sbuf.st_mode)) { clienterror(fd, filename, "403", "Forbidden",
"Tiny couldn't run the CGI program");
return;
>
serve_dynamic(fd, filename, cgiargs);
>
code/netp/tiny/tiny. c
图11-30 TINY doit处理一个HTTP事务
3. clienterror 函数
TINY缺乏一个实际服务器的许多错误处理特性。然而，它会检查一些明显的错误， 并把它们报告给客户端。图11-31中的clienterror函数发送一个HTTP响应到客户端， 在响应行中包含相应的状态码和状态消息，响应主体中包含一个HTML文件，向浏览器
674 第三部分程序间的交互和通信
的用户解释这个错误。
---------------------------------------------------------------------code/netp/tiny/tiny.c
1	void clienterror(int fd, char *cause, char *errnum,
2	char *shortmsg, char *longmsg)
3	{
4	char buf[MAXLINE], body[MAXBUF];
5
6	/* Build the HTTP response body */
l	sprintf (body, ’_<html><title>Tiny Error</t;itle>");
8	sprintf(body, "%s<body bgcolor=""ffffff"">\r\n", body);
9	sprintf (body, "7〇s#/〇s: 7〇s\r\n", body, errnum, stiortmsg);
10	sprintf (body, ,,#/〇s<p>%s: %s\r\n", body, longmsg, cause);
11	sprintf(body, "%s<hr><em>The Tiny Web sGrver</em>\r\n", body);
12
13	/* Print the HTTP response */
14	sprintf(buf, "HTTP/1.0 %s %s\r\n", errnum, shortmsg);
15	Rio_writen(fd, buf, strlen(buf));
16	sprintf(buf, "Content-type: text/html\r\n");
17	Rio_writen(fd, buf， strlen(buf));	.
18	sprintf (buf, "Content-lengttL： 7ad\r\n\r\ii" ,	(int)strlen(body));
19	Rio_writen(fd, buf, strlen(buf));
20	Rio_writen(fd, body, strlen(body));
21	>
code/netp/tiny/tiny.c
图1卜31 TINY clienterror向客户端发送一个出错消息
回想一下，HTML响应应该指明主体中内容的大小和类型。因此，我们选择创建 HTML内容为一个字符串，这样一来我们可以简单地确定它的大小。还有，请注意我们 为所有的输出使用的都是图10-4中健壮的rio_Writen函数。
4.	read_requesthdrs 函数
TINY不使用请求报头中的任何信息。它仅仅调用图11-32中的read_requesthdrs 函数来读取并忽略这些报头。注意，终止请求报头的空文本行是由回车和换行符对组成 的，我们在第6行中检查它。
------------------------------------------------code/netp/tiny/tiny.c
1	void read_requestMrs(rio_t *rp)
2	{
3	char buf[MAXLINE];
4
5	Rio_readlineb(rp,	buf,	MAXLINE);
6	while(strcmp(buf,	"\r\n"))	{
7	Rio.readlinebCrp, buf, MAXLINE);
8	printf("%s", buf);
9	>
10	return;
11	>
code/netp/tiny/tiny.c
1¾ 11-32 TINY read_requesthdrs读取并忽略请求报头
第11章网络编程 675
5.	parse_uri 函数
TINY假设静态内容的主目录就是它的当前目录，而可执行文件的主目录是./cgi-bin。 任何包含字符串cgi-bin的URI都会被认为表示的是对动态内容的请求。默认的文件名是 ./home.htmlo
图11-33中的parse_Uri函数实现了这些策略。它将URI解析为一个文件名和一个 可选的CGI参数字符串。如果请求的是静态内容（第5行），我们将清除CGI参数字符串 (第6行），然后将URI转换为一个Linux相对路径名，例如.Zindex.html(第7〜8行）。 如果URI是用“/”结尾的（第9行），我们将把默认的文件名加在后面(第10行）。另一方 面，如果请求的是动态内容(第13行），我们就会抽取出所有的CGI参数（第14〜20行）， 并将UR1剩下的部分转换为一个Linux相对文件名（第21〜22行
--------------------------------------code/netp/tiny/tiny. c
1	int parse_uri(char ♦uri, char *filename, char *cgiargs)
2	{
3	chcir *ptr;
5
6
7
8 9
10
if (!strstr(uri, "cgi-bin")) {	/* Static content */
strcpy(cgiargs,""); strcpy(filename, strcat(filename, uri); if (uri[strlen(uri)-l] == '/')
strcat(filename, "home.html");
It	return 1;
12	>
13	else {	/* Dynamic content */
14	ptr = index(uri, _?丨）；
15	if (ptr) {
16	strcpy(cgiargs, ptr+l);
17	*ptr = '\0';
18	>
19	else
20	strcpy(cgiargs,"
21	strcpy(filename,".)
22	strcat (filename,	uri)
23	return 0;
24	>
25	>
-------------------------------------------------code/netp/tiny/tiny. c
图 11-33 TINY parse_uri 解析一个 HTTP URI
6.	serve_static 函数
TINY提供五种常见类型的静态内容：HTML文件、无格式的文本文件，以及编码 为GIF、PNG和JPG格式的图片。
图11-34中的servejtatic函数发送一个HTTP响应，其主体包含一个本地文件的 内容。首先，我们通过检查文件名的后缀来判断文件类型（第7行），并且发送响应行和响 应报头给客户端(第8〜13行）。注意用一个空行终止报头。
676 第三部分程序间的交互和通信
-----------------------------------------------------------code/netp/tiny/tiny.c
1	void serve_static(int fd, char *filename, int filesize)
2	{
3
4
5
6
7
8 9
10 n 12
13
14
15
16
17
18
19
20 21 22
23	>
24
25	/*
26	* get^filetype - Derive file type from filename
27	*/
28	void get_f iletype(char *f ilenanie, char *f iletype)
29	{
30	if (strstr(filename, ".html"))
31	strcpy(filetype,	"text/html");
32	else	if	(strstr(filename,	".gif"))
33	strcpy(filetype,	"image/gif");
34	else	if	(strstr(filename,	11 .png"))
35	strcpy(filetype,	"image/png");
36	else	if	(strstr(filename,	"■jpg"))
37	strcpy(filetype,	"image/jpeg");
38	else
39	strcpy(filetype,	"text/plain");
40	>
int srcfd;
char *srcp, filetype[MAXLINE], buf[MAXBUF];
/* Send response headers to client */
get_filetype(filename, filetype);
sprintf(buf, "HTTP/1.0 200 DK\r\n");
sprintf(buf, "%sServer: Tiny Web Server\r\n", buf);
sprintf(buf, ”％sConnection: close\r\n", buf);
sprintf (buf, "7〇sContent-lengtli: %d\r\n", buf, f ilesize);
sprintf (buf, My〇sContent-type: %s\r\n\r\n" , buf, f iletype);
Rio_writen(fd, buf, strlen(buf));
printf("Response headers:\nn);
printf("%s", buf);
/* Send response body to client */ srcfd = 0pen(filename, 0_RD0NLY, 0);
srcp = Mmap(0, filesize, PR0T_READ, MAP.PRIVATE, srcfd, 0); Close(srcfd);
Rio_writen(fd, srcp, filesize);
Murunap(srcp, f ilesize);
code/netp/tiny/tiny.c
n-34 TINY serve_static为客户端提供静态内容
接着，我们将被请求文件的内容复制到已连接描述符fd来发送响应主体。这里的代 码是比较微妙的，需要仔细研究。第18行以读方式打开filename,并获得它的描述符。 在第19行，Linux mmap函数将被请求文件映射到一个虚拟内存空间。回想我们在第9.8 节中对mmap的讨论，调用ramap将文件srcfd的前filesize个字节映射到一个从地址 srcp开始的私有只读虚拟内存区域。
第聿网络编程 677
一旦将文件映射到内存，就不再需要它的描述符了，所以我们关闭这个文件（第20 行）。执行这项任务失败将导致潜在的致命的内存泄漏。第21行执行的是到客户端的实际 文件传送。rio^riten函数复制从srcp位置开始的filesize个字节（它们当然已经被 映射到了所请求的文件）到客户端的已连接描述符。最后，第22行释放了映射的虚拟内存 区域。这对于避免潜在的致命的内存泄漏是很重要的。
7.	serve_dynamic 函数
TINY通过派生一个子进程并在子进程的上下文中运行一个CGI程序，来提供各种类 型的动态内容。
图11-35中的serve_dynamic函数一开始就向客户端发送一个表明成功的响应行* 同时还包括带有信息的Server报头。CGI程序负责发送响应的剩余部分。注意，这并不 像我们可能希望的那样健壮，因为它没有考虑到CGI程序会遇到某些错误的可能性。
—-------------------------------------------code/netp/tiny/tiny.c
^ void serve_dynamic(int fd, char *filename, char *cgiargs)
2 {
3	char buf [MAXLINE], *emptylist [] = {, NULL >;
5
6
7
8 9
10
11
12
13
14
15
16
18
/* Return first part of HTTP response */ sprintfCbuf, "HTTP/1.0 200 QK\r\nM);
Rio_writen(fd, buf, strlen(buf));
sprintf(buf, "Server: Tiny Web Server\r\n");
Rio_writen(fd, buf, strlen(buf));
if (ForkO == 0) { /* Child */
/* Real server would set all CGI vars here */ setenv("QUERY_STRING", cgiargs, 1);
Dup2(fd, STD0UT_FILEN0);	/* Redirect stdout to client */
Execve(filename, emptylist, environ); /* Run CGI program */
>
Wait(NULL); /* Parent waits for and reaps child */
code/netp/tiny/tiny.c
图U-35 TINY serve_dynamic为客户端提供动态内容
在发送了响应的第一部分后，我们会派生一个新的子进程（第ii行）。子进程用来自 请求URI的CGI参数初始化QUERY _ STRING环境变量（第13行）。注意，一个真正的 服务器还会在此处设置其他的CGI环境变量。为了简短，我们省略了这一步。
接下来，子进程重定向它的标准输出到已连接文件描述符(第14行），然后加载并运行 CGI程序(第15行）。因为CGI程序运行在子进程的上下文中，它能够访问所有在调用execve 函数之前就存在的打开文件和环境变量。 因此， CGI 程序写到标准输出上的任何东西都 将直接送到客户端进程，不会受到任何来自父进程的干涉。其间，父进程阻塞在对wait的 调用中，等待当子进程终止的时候，回收操作系统分配给子进程的资源(第17行）。
旁注
处理过早关闭的连接
尽管一个Web服务器的基本功能非常简单，但是我们不想给你一个假象，以为编写一个 实际的Web服务器是非常简单的。构造一个长时间运行而不崩溃的健壮的Web服务器是一 件困难的任务，比起在这里我们已经学习了的内容，它要求对Linux系统编程有更加深入的
678 第三部分程序间的交互和通信
理解。例如，如果一个服务器写一个已经被客户端关闭了的连接（比如，因为你在浏览器上 单击了 “Stop”按钮），那么第一次这样的写会正常返回，但是第二次写就会引起发送SIG~ PIPE信号，这个信号的默认行为就是终止这个进程。如果捕获或者忽略SIGPIPE信号，那 么第二次写操作会返回值一1，并将errno设置为EPIPE。strerr和perror函数将EPIPE 错误报告为“Broken pipe”，这是一个迷惑了很多人的不太直观的信息。总的来说，一个健壮 的服务器必须捕获这些SIGPIPE信号，并且检查write函数调用是否有EPIPE错误。
11.7小结
每个网络应用都是基于客户端-服务器模型的，根据这个模型，一个应用是由一个服务器和一个或多 个客户端组成的。服务器管理资源，以某种方式操作资源，为它的客户端提供服务。客户端-服务器模型 中的基本操作是客户端-服务器事务，它是由客户端请求和跟随其后的服务器响应组成的。
客户端和服务器通过因特网这个全球网络来通信。从程序员的观点来看，我们可以把因特网看成是一个全 球范围的主机集合，具有以下几个属性：1)每个因特网主机都有一个唯一的32位名字，称为它的IP地址。2) IP地址的集合被映射为一个因特网域名的集合。3)不同因特网主机上的进程能够通过连接互相通信。
客户端和服务器通过使用套接字接口建立连接。一个套接字是连接的一个端点，连接以文件描述符 的形式提供给应用程序。套接字接口提供了打开和关闭套接字描述符的函数。客户端和服务器通过读写 这些描述符来实现彼此间的通信。
Web服务器使用HTTP协议和它们的客户端（例如浏览器）彼此通信。浏览器向服务器请求静态或者 动态的内容。对静态内容的请求是通过从服务器磁盘取得文件并把它返回给客户端来服务的。对动态内 容的请求是通过在服务器上一个子进程的上下文中运行一个程序并将它的输出返回给客户端来服务的。 CGI标准提供了一组规则，来管理客户端如何将程序参数传递给服务器，服务器如何将这些参数以及其 他信息传递给子进程，以及子进程如何将它的输出发送回客户端。只用几百行C代码就能实现一个筒单 但是有功效的Web服务器，它既可以提供静态内容，也可以提供动态内容。
参考文献说明
有关因特网的官方信息源被保存在一系列的可免费获取的带编号的文档中，称为RFC(RequeStS for Comments,请求注解，Internet标准(草案））。在以下网站可获得可搜索的RFC的索引： http://rfc-editor.org
RFC通常是为因特网基础设施的开发者编写的，因此，对于普通读者来说，往往过于详细了。然 而，要想获得权威信息，没有比它更好的信息来源了。HTTP/1.1协议记录在RFC 2616中。MIME类 型的权威列表保存在：
http://www.iana.org/assignments/media-types
Kerrisk是全面Linux编程的圣经，提供了现代网络编程的详细讨论[62]。关于计算机网络互联有大量 很好的通用文献[65, 84, 114]。伟大的科技作家W. Richard Stevens编写了一系列相关的经典文献，如高级 Unix编程[111]、因特网协议[109, 120, 107]，以及Unix网络编程[108, 110]。认真学习Unix系统编程 的学生会想要研究所有这些内容。不幸的是，Stevens在1999年9月1日逝世。我们会永远纪住他的贡献。
家庭作业
11.6	A.修改TINY使得它会原样返回每个请求行和请求报头。
B.	使用你喜欢的浏览器向TINY发送一个对静态内容的请求。把TINY的输出记录到一个文件中。
C.	检査TINY的输出，确定你的浏览器使用的HTTP的版本^
D.	参考RFC 2616中的HTTP/1.1标准，确定你的浏览器的HTTP请求中每个报头的含义。你可 以从 www.rfc-editor.org/rfc.html 获得 RFC 2616d
117扩展TINY，使得它可以提洪MPG视频文件。用一个真正的浏览器来检验你的工作D
第J]章网络编程 679
8修改TINY，使得它在SIGCHLD处理程序中回收操作系统分配给CGI子进程的资源，而不是显 式地等待它们终止。
**11.9 修改TINY,使得当它服务静态内容时，使用malloc、rio_readn和rio_writen，而不是mmap 和ri〇_writen来复制被请求文件到已连接描述符。	_
*•11.10 A.写出图11-27中CGI adder函数的HTML表单s你的表单应i包括两个文本框，用户将需要 相加的两个数字填在这两个文本框中。你的表单应该使用GET方法请求内容。
B.用这样的方法来检査你的程序：使用一个真正的浏览器向TINY请求表单，向TINY提交填 写好的表单，然后显示adder生成的动态内容。
**11.11扩展TINY，以支持HTTP HEAD方法。使用TELNET作为Web客户端来验证你的工作。 Y11.12扩展TINY,使得它服务以HTTPPOST方式请求的动态内容。用你喜欢的Web浏览器来验证你 的工作。
V 11. 13修改TINY,使得它可以干净地处理（而不是终止）在write函数试图写一个过早关闭的连接时发 生的SIGPIPE信号和EPIPE错误，
练习题答案
11.1
十六进制地址	点分十进制地址
0x0	0.0.0.0
Oxffffffff	255.255.255.255
0x7f000001	127.0.0.1
0xcdbca079	205.188.160.121
0x400c950d	64.12.149.13
0xcdbc9217	205.188.146.23
11.2
3
6
8
9
10
12
13
15
16
18
20
21
------------------------------------------------------code/netp/hex2dd.c
tinclude "csapp.h"
int main(int argc, char **argv)
<
struct in.addr inaddr;	/*	Address in	network byte order */
uint32_t addr;	/*	Address in	host byte order */
char buf[MAXBUF];	/*	Buffer for	dotted-decimal string	*/
if (argc != 2) {
fprintf (stderr, "usage: 7,s <hex number>\n" , argv[0]); exit(O);
>
sscanf(axgv[l3, "%x", ftaddr); inaddr.s_addr = htonl(addr);
if C!inet_ntop(AF_INET, ftinaddr, buf, MAXBUF)) unix„error("inet_ntop"); printfC"7.s\n", buf);
exit(0);
>
-----------------------------------------------------code/netp/hex2dd. c
11.3
1	#include "csapp.h"
2
code/netp/dd2hex. c
3	int main(int argc, char **argv)
680 第三部分程序间的交互和通信
5	struct in_addr inaddr;	/* Address in network byte order */
6	int rc;
7
8	if (argc != 2) {
9	fprintf (stderr, "usage: °/,s <dotted-decimal>\n" , axgv [0]);
to	exit(0);
n	>
11.4
n
20
21
rc = inet_pton(AF_INET, argv[l], fcinaddr);
if (re == 0)
app_error("inet_pton error: invalid dotted-decimal address"); else if (rc < 0)
printf ("0x%x\n'*, ntohl(inaddr.s_addr)); exit(0);
code/netp/dd2hex. c
下面是解决方案。注意，使用inet_ntop要困难多少，它要求很麻烦的强制类型转换和深层嵌套 结构引用6 getnameinfo函数要简单许多，因为它为我们完成了这些工作. --------------------------code/netp/hostinfo-ntop.c
1	finclude "csapp.h"
2
3	iat main(int argc, char **argv)
4	{
5	stmct addrinfo *p, *listp, hints;
6	struct sockaddr_in *sockp;
7	char buf [MAXLINE];
8	int rc;
9
10	if (argc != 2) {
n	fprintf(stderr, "usage: %s <domain name>\n", argv[0]);
12	exit(0);
13	>
14
15	/* Get a list of addrinfo records */
16	memset(&hints, 0, sizeof(struct addrinfo));
17	hints.ai_family = AF_INET;	/* IPv4 only */
18	h.ints.ai_socktype = S0CK_STRE1AM; /* Connections only */
19	if (Crc = getaddrinfo(argv[1], NULL, fehints, fclistp)) != 0) {
20	fprintf (stderr,	"getaddrinfo	error:	7,s\n", gai_strerror(rc));
21	exit ⑴；
22	>
23
24	/* Walk the list and display each associated IP address */
25	for (p ** listp; p; p = p->ai_next) {
26	sockp = (struct	sockaddr_in	*)p->ai_addr;
27	Inet_ntop(AF_INET, &(sockp->sin_addr), buf, MAXLINE);
28	priatf("%s\n", buf);
29	>
30
31	/* Clean	up	*/
32	Freeaddrinfo(listp);
33
34	exit(0);
35	>
--------------------------------code/netp/hostinfo-ntop.c
11.5标准I/O能在CGI程序里工作的原因是，在子进程中运行的CGI程序不需要显式地关闭它的输人 输出流。当子进程终止时，内核会自动关闭所有描述符。
第12章
并发编程
12
正如我们在第8章学到的，如果逻辑控制流在时间上重叠，那么它们就是并发的 (concurrent)。这种常见的现象称为并发（concurrency)，出现在计算机系统的许多不同层 面上。硬件异常处理程序、进程和Linux信号处理程序都是大家很熟悉的例子。
到目前为止，我们主要将并发看做是一种操作系统内核用来运行多个应用程序的机 制。但是，并发不仅仅局限于内梭。它也可以在应用程序中扮演重要角色。例如，我们已 经看到Linux信号处理程序如何允许应用响应异步事件，例如用户键人Ctrl + C，或者程 序访问虚拟内存的一个未定义的区域。应用级并发在其他情况下也是很有用的：
■访问慢速I/O设备。当一个应用正在等待来自慢速VO设备（例如磁盘）的数据到达 时，内核会运行其他进程，使CPU保持繁忙。每个应用都可以按照类似的方式， 通过交替执行V0请求和其他有用的工作来利用并发。
•与人交互。和计算机交互的人要求计算机有同时执行多个任务的能力。例如，他们 在打印一个文档时，可能想要调整一个窗口的大小。现代视窗系统利用并发来提供 这种能力。每次用户请求某种操作（比如通过单击鼠标）时，一个独立的并发逻辑流 被创建来执行这个操作。
*通过推迟工作以降低延迟。有时，应用程序能够通过推迟其他操作和并发地执行它 们，利用并发来降低某些操作的延迟。比如，一个动态内存分配器可以通过推迟合 并，把它放到一个运行在较低优先级上的并发“合并”流中，在有空闲的CPU周 期时充分利用这些空闲周期，从而降低单个free操作的延迟。
•服务多个网络客户端。我们在第11章中学习的迭代网络服务器是不现实的，因为它 *	们一次只能为一个客户端提供服务。因此，一个慢速的客户端可能会导致服务器拒绝
为所有其他客户端服务。对于一个真正的服务器来说，可能期望它每秒为成百上千的 客户端提供服务，由于一个慢速客户端导致拒绝为其他客户端服务，这是不能接受 的。一个更好的方法是创建一个并发服务器，它为每个客户端创建一个单独的逻辑 流。这就允许服务器同时为多个客户端服务，并且也避免了慢速客户端独占服务器。
*在多核机器上进行并行计算。许多现代系统都配备多核处理器，多核处理器中包含 有多个CPU。被划分成并发流的应用程序通常在多核机器上比在单处理器机器上运 行得快，因为这些流会并行执行，而不是交错执行。
使用应用级并发的应用程序称为并发程序（concurrent program)。现代操作系统提供 了三种基本的构造并发程序的方法：
■进程。用这种方法，每个逻辑控制流都是一个进程，由内核来调度和维护。因为进 程有独立的虚拟地址空间，想要和其他流通信，控制流必须使用某种显式的进程间 通信（interprocess communication，IPC)机制 0
*1/0多路复用。在这种形式的并发编程中，应用程序在一个进程的上下文中显式地 调度它们自己的逻辑流。逻辑流被模型化为状态机，数据到达文件描述符后，主程 序显式地从一个状态转换到另一个状态。因为程序是一个单独的进程，所以所有的 流都共享同一个地址空间。
682 第三部分程序间的交互和通信
•线程。线程是运行在一个单一进程上下文中的逻辑流，由内核进行调度。你可以把 线程看成是其他两种方式的混合体，像进程流一样由内核进行调度，而像V◦多路 复用流一样共享同一个虚拟地址空间。
本章研究这三种不同的并发编程技术。为了使我们的讨论比较具体，我们始终以同一 个应用为例——11. 4. 9节中的迭代echo服务器的并发版本。
12.	1基于进程的并发编程
构造并发程序最简单的方法就是用进程，使用那些大家都很熟悉的函数，像fork、 exec和waitpid。例如，一个构造并发服务器的自然方法就是，在父进程中接受客户端 连接请求，然后创建一个新的子进程来为每个新客户端提供服务。
为了了解这是如何工作的，假设我们有两个客户端和一个服务器，服务器正在监听一 个监听描述符（比如指述符3)上的连接请求。现在假设服务器接受了客户端1的连接请求， 并返回一个已连接描述符（比如指述符4)，如图12-1所示。在接受连接请求之后，服务器 派生一个子进程，这个子进程获得服务器描述符表的完整副本。子进程关闭它的副本中的 监听描述符3,而父进程关闭它的已连接描述符4的副本，因为不再需要这些描述符了。 这就得到了图12-2中的状态，其中子进程正忙于为客户端提供服务。 .
客户端1 /'、-、^连接请求
clientf d	''', istenfdH)
4服务器
a
_______ connfd(4)
客户端2 >
clientfd
clientfd
客户端2 _
clientfd
子进程1
connfd(4)
listenfdQ) e服务器
阍12-1第一步：服务器接受客户端的连接请求	阁12-2第二步：服务器派生一个子进程为这个客户端服务
因为父、子进程中的已连接描述符都指向同一个文件表表项，所以父进程关闭它的已 连接描述符的副本是至关重要的。否则，将永不会释放已连接描述符4的文件表条目，而 且由此引起的内存泄漏将最终消耗光可用的内存，使系统崩溃。
现在，假设在父进程为客户端1创建了子进程之后，它接受一个新的客户端2的连接请 求，并返回一个新的已连接描述符（比如描述符5)，如图12-3所示。然后，父进程又派生另 一个子进程，这个子进程用已连接描述符5为它的客户端提供服务，如图12-4所示。此时， 父进程正在等待下一个连接请求，而两个子进程正在并发地为它们各自的客户端提供服务。
clientfd	connfd{5)
图12-3第三步：服务器接受另一个连接请求	图12-4第四步：服务器派生另一个子进程为新的客户端服务
第12章并发编程 6S3
12. 1. 1基于进程的并发服务器
图12-5展示了一个基于进程的并发echo服务器的代码。第29行调用的echo函数来 自于图11-21。关于这个服务器，有几点重要内容需要说明：
*首先，通常服务器会运行很长的时间，所以我们必须要包括一个SIGCHLD处理程 序，来回收僵死（zombie)子进程的资源（第4〜9行）。因为当SIGCHLD处理程序 执行时，SIGCHLD信号是阻塞的，而Linux信号是不排队的，所以SIGCHLD处 理程序必须准备好回收多个僵死子进程的资源。
*其次，父子进程必须关闭它们各自的connfd(分别为第33行和第30行）副本。就 像我们已经提到过的，这对父进程而言尤为重要，它必须关闭它的已连接描述符， 以避免内存泄漏。
_最后，因为套接字的文件表表项中的引用计数，直到父子进程的comifd都关闭了， 到客户端的连接才会终止。
------------------------------------------------code/conc/echoserverp. c
1	#include "csapp.h*1
2	void echo(int connfd);
3
4	void sigchld_handler(int sig)
5	{
6	while (waitpid(-l, 0, WNOHANG) > 0)
7	；
8	return;
9	>
10
11	int main(int argc, char **argv)
12	{
13	int listenfd, connfd;
14	socklen_t clientlen;
15.	struct sockaddr_storage clientaddr;
16
17	if (argc != 2) {
18	fprintf(stderr, ”usage: %s <port>\n", argv[0]);
19	exit(0);
20	>
21
22	Signal(SIGCHLD, sigchld_handler);
23	listenfd = Open_listenfd(argv[l]);
24	while	(1) {
25	clientlen	=	sizeof(struct	sockaddr.storage);
26	connfd =	Accept(listenfd,	(SA	*)	feclientaddr, Ssclientlen);
27	if (Fork() == 0) {
28	Close(listenfd); /*	Child	closes its listening	socket	*/
29	echo(connfd);	/*	Child	services client */
30	Close(connfd);	/*	Child	closes connection with	client */
31	exit(0);	/*	Child	exits */
32	>
33	Close(connfd); /* Parent closes connected socket (important!) */
34	>
35	>
------------------------------------------------code/conc/echoserverp. c
[fi 12-5基于进程的并发echo服务器。父进程派生一个子进程来处理每个新的连接请求
684 第三部分程序间的交互和通信
12.1.2进程的优劣
对于在父、子进程间共享状态信息，进程有一个非常清晰的模型：共享文件表，但是不共 享用户地址空间。进程有独立的地址空间既是优点也是缺点。这样一来，一个进程不可能不小 心覆盖另一个进程的虚拟内存，这就消除了许多令人迷惑的错误——这是一个明显的优点。
另一方面，独立的地址空间使得进程共享状态信息变得更加困难。为了共享信息，它 们必须使用显式的IPC(进程间通信）机制。（参见下面的旁注。）基于进程的设计的另一个 缺点是，它们往往比较慢，因为进程控制和IPC的开销很高。
旁注
在本书中，你已经遇到好几个IPC的例子了。第8章中的waitpid函数和信号是 基本的IPC机制，它们允许进程发送小消息到同一主机上的其他进程。第11章的套接 字接口是IPC的一种重要形式，它允许不同主机上的进程交换任意的字节流。然而，术 语Unix IPC通常指的是所有允许进程和同一台主机上其他进程进行通信的技术。其中 包括管道、先进先出（FIFO)、系统V共享内存，以及系统V信号量（semaphore)。这 些机制超出了我们的讨论范围。Kerrisk的著作[62]是很好的参考资料。
&练习题12.1在图12-5中，并发服务器的第33行上，父进程关闭了已连接描述符 ^后，子进程仍然能够使用该描述符和客户端通信。为什么？ g练习题12.2如果我们要删除图12-5中关闭已连接描述符的第30行，从没有内存泄 漏的角度来说，代码将仍然是正确的。为什么？
12.2基于丨/〇多路复用的并发编程
假设要求你编写一个echo服务器，它也能对用户从标准输人键入的交互命令做出响 应。在这种情况下，服务器必须响应两个互相独立的I/O事件：1)网络客户端发起连接请 求，2)用户在键盘上键入命令行。我们先等待哪个事件呢？没有哪个选择是理想的。如果 在accept中等待一个连接请求，我们就不能响应输人的命令。类似地，如果在read中 等待一个输入命令，我们就不能响应任何连接请求。
针对这种困境的一个解决办法就是I/O多路复用（I/O multiplexing)技术。基本的思 路就是使用select函数，要求内核挂起进程，只有在一个或多个I/O事件发生后，才将 控制返回给应用程序，就像在下面的示例中一样：
•当集合{〇, 4}中任意描述符准备好读时返回。
*当集合{1，2, 7}中任意描述符准备好写时返回。
*如果在等待一个I/O事件发生时过了 152. 13秒，就超时。
select是一个复杂的函数，有许多不同的使用场景。我们将只讨论第一种场景：等 待一组描述符准备好读。全面的讨论请参考[62，110]。
#include <sys/select.h.>
int select(int n, fd_set *fdset, NULL, NULL, NULL);
返回已准备好的描述符的非零的个教，若出错则为一1。 FD_ZER0(fd_set *fdset);	/* Clear all bits in fdset */
FD_CLR(int fd, fd_set *fdset);	/* Clear bit fd in fdset */
FD_SET(int fd, fd_set *fdset);	/* Turn on bit fd in fdset */
FD_ISSET(int fd, fd_set *fdset);	/* Is bit fd in fdset on? */
处理描述符集合的宏。
第12章并发编程 685
select函数处理类型为fd_set的集合，也叫做描述符集合。逻辑上，我们将描述符 集合看成一个大小为《的位向量（在2. 1节中介绍过）：
b„~\ »* * ■»6] ib〇
每个位h对应于描述符h当且仅当~ = 1，描述符A才表明是描述符集合的一个元素。只 允许你对描述符集合做三件事：1)分配它们，2)将一个此种类型的变量赋值给另一个变 量，3)用FD_ZERO、FD_SET、FD_CLR和FDJSSET宏来修改和检查它们。
针对我们的目的，select函数有两个输人：一个称为读集合的描述符集合（fdset) 和该读集合的基数（n)(实际上是任何描述符集合的最大基数）。select函数会一直阻塞， 直到读集合中至少有一个描述符准备好可以读。当且仅当一个从该描述符读取一个字节的 请求不会阻塞时，描述符々就表示准备好可以读了。select有一个副作用，它修改参数 fdset指向的fd_set，指明读集合的一个子集，称为准备好集合（ready set)，这个集合 是由读集合中准i好可以读了的描述符组成的。该函数返回的值指明了准备好集合的基 数。注意，由于这个副作用，我们必须在每次调用select时都更新读集合。
理解select的最好办法是研究一个具体例子。图12-6展示了可以如何利用select 来实现一个迭代echo服务器，它也可以接受标准输入上的用户命令。一开始，我们用 图11-19中的〇pen_listenfd函数打开一个监听描述符（第16行），然后使用FD_ZERO 创建一个空的读集合(第18行）：
listenfd	stdin
3	2	10
read_set (0): [ 0 | 0 | 0
接下来，在第19和20行中，我们定义由描述符0(标准输人）和描述符3(监听描述 符)组成的读集合：
listenfd	stdin
3	2	10
•	read_set ({0,3}): | 1	| 0 丨 0 | 1	|
在这里，我们开始典型的服务器循环。但是我们不调用accept函数来等待一个连接 请求，而是调用select函数，这个函数会一直阻塞，直到监听描述符或者标准输人准备 好可以读(第24行）。例如，下面是当用户按回车键，因此使得标准输人描述符变为可读 时，select会返回的ready_set的值：
listenfd	stdin
3	2	10
ready.set ({0}) :	f〇]"〇 [ 0 ~f 1~|
一旦select返回，我们就用FD_ISSET宏指令来确定哪个描述符准备好可以读了。 如果是标准输人准备好了（第25行），我们就调用command函数，该函数在返回到主程序 前，会读、解析和响应命令。如果是监听描述符准备好了（第27行），我们就调用accept 来得到一个已连接描述符，然后调用图11-22中的echo函数，它会将来自客户端的每一 行又回送回去，直到客户端关闭这个连接中它的那一端。
虽然这个程序是使用select的一个很好示例，但是它仍然留下了一些问题待解决。问 题是一旦它连接到某个客户端，就会连续回送输入行，直到客户端关闭这个连接中它的那一 端。因此，如果键入一个命令到标准输入，你将不会得到响应，直到服务器和客户端之间结
686 第三部分程序间的交互和通信
束。一个更好的方法是更细粒度的多路复用，服务器每次循环(至多）回送一个文本行。
--------------------------------------code/conc/select. c
1
2
5
6
7
8 9
10
11
12
13
14
15
16
17
18
19
20 21 22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
#include "csapp.ii" void echo(int connfd); void command(void);
int mainCint argc, char **argv)
{
int listenfd, connfd; socklen_t clientlen; struct sockaddr_storage clientaddr; fd_set read_set, ready_set;
if (argc !» 2) {
fprintf(stderr, "usage: %s <port>\n", argv[0]); exit(0);
>
listenfd = Open_listenfd(argv[l]);
FD_ZER0(&read_set);	/* Clear read set */
FD_SET(STDIN_FILEN0, &read_set); /* Add stdin to read set */ FD^SETClistenfd, &read_set);	/* Add listenfd to read set */
while (1) {
ready_set = read.set;
Select(listenfd+1, &ready_set, NULL, NULL, NULL); if (FD_ISSET(STDIN_FILENOt &ready_set))
commandO; /* Read command line from stdin */ if (FD_ISSET(listenfd, &ready_set)) {
clientlen = sizeof(struct sockaddr.storage);
connfd = Accept(listenfd, (SA *)&clientaddr, feclientlen);
echo(cormfd); /* Echo client input until EOF */
Close(connfd);
void command (void) ■( char buf[MAXLINE]; if (!Fgets(buf, HAXLINE, stdin)) exit(0);/* EOF */
printf("%s", buf); /* Process the input command */
----------------------------------- code/conc/select. c
图12-6使用I/O多路复用的迭代echo服务器。服务器使用select 等待监听描述符上的连接请求和标准输人上的命令
@练习题12.3在Linux系统里，在标准输入上键入Ctrl + D表示EOF。图12-6中的 程序阻塞在对select的调用上时，如果你键入Ctrl+D会发生什么？
12.2.1基于I/O多路复用的并发事件驱动服务器
I/O多路复用可以用做并发事件驱动（event-driven)程序的基础，在事件驱动程序中， 某些事件会导致流向前推进。一般的思路是将逻辑流模型化为状态机。不严格地说，一个
第12章并发编程 687
状态机（state machine)就是一组状态（state)、输入事件（input event)和转移（transition)， 其中转移是将状态和输人事件映射到状态。每个转移是将一个（输人状态，输人事件）对映 射到一个输出状态。自循琢（self-loop)是同一输人和输出状态之间的转移。通常把状态机 画成有向图，其中节点表示状态，有向弧表示转移，而弧上的标号表示输入事件。一个状 态机从某种初始状态开始执行。每个输入事件都会引发一个从当前状态到下一状态的
转移。
对于每个新的客户端I基于I/O多路 复用的并发服务器会创建一个新的状态机 &，并将它和已连接描述符A联系起来。如 图12-7所示，每个状态机〜都有一个状态 (“等待描述符 <准备好可读”）、一个输人事 件(“描述符A准备好可以读了”）和一个转移 (“从描述符A读一个文本行”）。
图12-7并发事件驱动echo服务器中逻辑流的状态机
服务器使用I/O多路复用，借助select函数检测输人事件的发生。当每个已连接描 述符准备好可读时，服务器就为相应的状态机执行转移，在这里就是从描述符读和写回一 个文本行。
图12-8展示了一个基于I/O多路复用的并发事件驱动服务器的完整示例代码。一个 pool结构里维护着活动客户端的集合（第3〜11行）。在调用init_pool初始化池（第27 行)之后，服务器进入一个无限循环。在循环的每次迭代中，服务器调用select函数来 检测两种不同类型的输入事件：a)来自一个新客户端的连接请求到达，b)—个已存在的客 户端的已连接描述符准备好可以读了。当一个连接请求到达时（第35行），服务器打开连 接(第37行），并调用add_client函数，将该客户端添加到池里（第38行）。最后，服务 器调用checl^clients函数，把来自每个准备好的已连接描述符的一个文本行回送回去 (第42行）。
--------------------------------------code/conc/echoservers.c
1	#include "csapp.h"
2
3	tjrpedef struct { /* Represents a pool of connected descriptors */
4	int maxfd;	/*	Largest descriptor in read.set */
5	fd_set read_set;	/*	Set of all active descriptors */
6	fd.set ready_set;	/*	Subset of descriptors ready for reading	*/
7	int nready;	/*	Number of ready descriptors from select	*/
8	int maxi;	/*	High water index into client array */
9	int clientfd[FD_SETSIZE];	/*	Set	of	active	descriptors	*/
10	rio_t clientrio[FD_SETSIZE];	/*	Set	of	active	read	buffers	*/
11	> pool;
12
13	int byte_cnt = 0; /* Counts total bytes received by server */
14
15	int main(int argc， char **axgv)
16	{
17	int listenfd, connfd;
18	socklen_t clientlen;
19	struct sockaddr_storage clientaddr;
图12-8基于I/O多路复用的并发echo服务器。每次服务器迭代 都回送来自每个准备好的描述符的文本行
688 第三部分程序间的交互和通信
20	static pool pool;
21
22	if Cargo != 2) ■(
23	fprintf(stderr, "usage: %s <port>\n,'> eirgv[0]);
24	exit(0);
25	>
26	listenfd = Open_listenfd(argv[l]);
27	init_pool(listenfd,	&pool);
28
29	while Cl) -C
30	/* Wait for listening/connected descriptor(s) to become ready */
31	pool.ready.set = pool.read_set;
32	pool.nready = Select(pool.maxfd+1, &pool.ready_set, NULL, NULL, NULL);
33
34	/* If listening descriptor ready, add new client to pool */
35	if (FD_ISSET(listenfd, &pool.ready_set))	{
36	clientlen. ~ sizeof (struct sockaddr_storage);
37	connfd = Acceptdistenfd, (SA *)&clientaddr, &clientlen);
38	add_client(connfd, &pool);
39	>
40
41	/* Echo a text line from each ready	connected descriptor */
42	check_clients(&pool);
43	>
44	>
code/conc/echoservers. c
图12-8	(续）
init_p〇〇l函数（图12-9)初始化客户端池。clientfd数组表示已连接描述符的集 合，其中整数一 1表示一个可用的槽位。初始时，已连接描述符集合是空的（第5〜7行）， 而且监听描述符是select读集合中唯一的描述符（第10~12行）
----------------------------------------------code/conc/echoservers.c
1	void init.pool(int listenfd, pool *p)
2	{
3	/* Initially, there are no connected descriptors */
4	int i;
5	p->maxi = -1;
6	for (i=0; i< FD—SETSIZE;	i++)
7	p->clientfd[i] = -1;
8
9	/* Initially, listenfd is only member of select read set */
10	p->maxfd = listenfd;
11	FD_ZERO(&p->read—set);
12	FD_SET(listenfd, &p->read_set);
13	>
code/conc/echoservers. c
图12-9 init_P〇〇l初始化活动客户端池
add_client函数（图12-10)添加一个新的客户端到活动客户端池中。在clientfd 数组中找到一个空槽位后，服务器将这个已连接描述符添加到数组中，并初始化相应的 RIO读缓冲区，这样一来我们就能够对这个描述符调用rio readlineb(第8〜9行）。然
第12章并发编程 689
后，我们将这个已连接描述符添加到select读集合(第12行），并更新该池的一些全局属 性。maxfd变量(第15〜16行)记录了 select的最大文件描述符。maxi变量（第17〜18 行）记录的是到clientfd数组的最大索引，这样check_clients函数就无需搜索整个数 组了。
2
3
4
5
6
7
8 9
10
11
12
13
14
15
16
17
18
19
20 21 22 23
void add_client(int connfd, pool *p)
code/conc/echoservers. c
int i;
p->nready——;
for (i = 0; i < FD_SETSIZE; i++) /* Find an available slot */ if (p->clientfd[i] < 0) {
/* Add connected descriptor to the pool */ p->clientfd[i] = connfd;
Rio_readinitb(&p->clientrio[i], connfd);
/* Add the descriptor to descriptor set */ FD_SET(connfd, &p->read_set);
/* Update max descriptor and pool high water mark */ if (connfd > p->maxfd) p->m«Lxfd = connfd; if (i > p->maxi) p->maxi = i; break;
>
if (i == FD_SETSIZE) /* Couldn't find an empty slot */ app_error("add_client error: Too many clients");
-----------------------------------------------code/conc/echoservers. c
图12-10 add_client向池中添加一个新的客户端连接
图12-11中的checkjrlients函数回送来自每个准备好的已连接描述符的一个文本行。 如果成功地从描述符读取了一个文本行，那么就将该文本行回送到客户端（第15〜18行）。 注意，在第15行我们维护着一个从所有客户端接收到的全部字节的累计值。如果因为客 户端关闭这个连接中它的那一端，检测到EOF,那么将关闭这边的连接端（第23行），并 从池中清除掉这个描述符（第24~25行）。
根据图12-7中的有限状态模型，select函数检测到输人事件，而acW_client函数 创建一个新的逻辑流（状态机）。check_clients函数回送输人行，从而执行状态转移， 而且当客户端完成文本行发送时，它还要删除这个状态机。
&练习题12.4图12-8所示的服务器中，我们在每次调用select之前都立即小心地 重新初始化pool.ready_set变量。为什么？
旁注
事件驱动的Web服务器
尽管有12.2.2节中说明的缺点，现代高性能服务器（例如Node, js、nginx和Tornado) 使用的都是基于 I/O 多路复用的事件驱动的编程方式，主要是因为相比于进程和 线程的方式，它有明显的性能优势。
690 第三部分程序间的交互和通信
1
2
3
4
5
void check_clients(pool *p)
int i, connfd, n; char buf[MAXLINE];
code/conc/echoservers. c
28
for (i = 0; (i <= p->maxi) && (p->uready > 0); i++) -C connfd = p->clientfd[i]; rio = p->clientrio[i];
/* If the descriptor is ready, echo a text line from it */ if ((connfd > 0) && (FD_ISSET(connfd, &p->ready_set))) { p->nready--;
if ((n = Rio_readlineb(&rio, buf, MAXLINE)) != 0) { byte_cnt += n;
printf("Server received 7〇d (°/0d total) bytes on fd XdW、 n, byte_cnt, connfd);
Rio_writen(connfd, buf, n);
>
/* EOF detected, remove descriptor from pool */ else {
Close(connfd);
FD_CLR(connfd, &p->read_set); p->clientfd[i] = -1;
code/conc/echoservers. c
图12-11 check_clients服务准备好的客户端连接
12.2.2丨/0多路复用技术的优劣
图12-8中的服务器提供了一个很好的基于I/O多路复用的事件驱动编程的优缺点示 例。事件驱动设计的一个优点是，它比基于进程的设计给了程序员更多的对程序行为的控 制。例如，我们可以设想编写一个事件驱动的并发服务器，为某些客户端提供它们需要的 服务，而这对于基于进程的并发服务器来说，是很困难的。
另一个优点是，一个基于I/O多路复用的事件驱动服务器是运行在单一进程上下文中 的，因此每个逻辑流都能访问该进程的全部地址空间。这使得在流之间共享数据变得很容 易。一个与作为单个进程运行相关的优点是，你可以利用熟悉的调试工具，例如GDB, 来调试你的并发服务器，就像对顺序程序那样。最后，事件驱动设计常常比基于进程的设 计要高效得多，因为它们不需要进程上下文切换来调度新的流。
事件驱动设计一个明显的缺点就是编码复杂^我们的事件驱动的并发echo服务器需要的 代码比基于进程的服务器多三倍，并且很不幸，随着并发粒度的减小，复杂性还会上升。这 里的粒度是指每个逻辑流每个时间片执行的指令数量。例如，在示例并发服务器中，并发粒 度就是读一个完整的文本行所需要的指令数量。只要某个逻辑流正忙于读一个文本行，其他 逻辑流就不可能有进展。对我们的例子来说这没有问题，但是它使得在“故意只发送部分文
第12章并发编程 691
本行然后就停止”的恶意客户端的攻击面前，我们的事件驱动服务器显得很脆弱。修改事件 驱动服务器来处理部分文本行不是一个简单的任务，但是基于进程的设计却能处理得很好， 而且是自动处理的。基于事件的设计另一个重要的缺点是它们不能充分利用多核处理器。
12.3基于线程的并发编程
到目前为止，我们已经看到了两种创建并发逻辑流的方法。在第一种方法中，我们为 每个流使用了单独的进程。内核会自动调度每个进程，而每个进程有它自己的私有地址空 间，这使得流共享数据很困难。在第二种方法中，我们创建自己的逻辑流，并利用I/O多 路复用来显式地调度流。因为只有一个进程，所有的流共享整个地址空间。本节介绍第三 种方法——基于线程，它是这两种方法的混合。
线程（thread)就是运行在进程上下文中的逻辑流。在本书里迄今为止，程序都是由每 个进程中一个线程组成的。但是现代系统也允许我们编写一个进程里同时运行多个线程的 程序。线程由内核自动调度。每个线程都有它自己的线程上下文（thread context),包括一 个唯一的整数线程IDCThreadlD, TID)、栈、栈指针、程序计数器、通用目的寄存器和 条件码。所有的运行在一个进程里的线程共享该进程的整个虚拟地址空间。
基于线程的逻辑流结合了基于进程和基于I/O多路复用的流的特性。同进程一样，线 程由内核自动调度，并且内核通过一个整数ID来识别线程。同基于I/O多路复用的流一 样，多个线程运行在单一进程的上下文中，因此共享这个进程虚拟地址空间的所有内容， 包括它的代码、数据、堆、共享库和打开的文件。
12.3. 1线程执行模型
多线程的执行模型在某些方面和多进 程的执行模型是相似的。思考图12-12中的 示例。每个进程开始生命周期时都是单一 线程，这个线程称为主线程（main thread)。
在某一时刻，主线程创建一个对等线程 (peer thread),从这个时间点开始，两个线 程就并发地运行。最后，因为主线程执行 —个慢速系统调用，例如read或者 sleep，或者因为被系统的间隔计时器中 断，控制就会通过上下文切换传递到对等 线程。对等线程会执行一段时间，然后控制传递回主线程，依次类推。
在一些重要的方面，线程执行是不同于进程的。因为一个线程的上下文要比一个进程 的上下文小得多，线程的上下文切换要比进程的上下文切换快得多。另一个不同就是线程 不像进程那样，不是按照严格的父子层次来组织的。和一个进程相关的线程组成一个对等 (线程）池，独立于其他线程创建的线程。主线程和其他线程的区别仅在于它总是进程中第 一个运行的线程。对等（线程）池概念的主要影响是，一个线程可以杀死它的任何对等线 程，或者等待它的任意对等线程终止。另外，每个对等线程都能读写相同的共享数据。
12.	3. 2 Posix 线程
Posix线程（Pthreads)是在C程序中处理线程的一个标准接口。它最早出现在1995
时间
)•线程上下文切换
]•线程上下文切换 }线程上下文切换
图12-12并发线程执行
692	第三部分程序间的交互和通信
年，而且在所有的Limix系统上都可用。Pthreads定义了大约60个函数，允许程序创建、 杀死和回收线程，与对等线程安全地共享数据，还可以通知对等线程系统状态的变化。
图12-13展示了一个简单的Pthreads程序。主线程创建一个对等线程，然后等待它的 终止。对等线程输出“Hello, world! \n”并且终止。当主线程检测到对等线程终止后， 它就通过调用exit终止该进程。这是我们看到的第一个线程化的程序，所以让我们仔细 地解析它。线程的代码和本地数据被封装在一个线程例程（thread routine)中。正如第二行 里的原型所示，每个线程例程都以一个通用指针作为输入，并返回一个通用指针。如果想 传递多个参数给线程例程，那么你应该将参数放到一个结构中，并传递一个指向该结构的 指针。相似地，如果想要线程例程返回多个参数，你可以返回一个指向一个结构的指针。
-----------------------------------------code/conc/hello. c
^ #include "csapp.h"
2	void *thread(void *vargp);
3
4	int mainO
5	{
6	pthread_t tid;
7	Pthread_create(&tid, NULL, thread, NULL);	.
8	Pthread_j oin(tid, NULL);
9	exit(0);
12	void *thread(void *vaxgp) /* Thread routine */
13	{
14	printf("Hello, world!\n");
15	return NULL;
16	>
-------------------------------------code/conc/hello. c
图 12-13 hello.c:使用 Pthreads 的 “Hello，world!” 程序
第4行标出了主线程代码的开始。主线程声明了一个本地变量tid，可以用来存放对 等线程的ID(第6行）。主线程通过调用pthread^reate函数创建一个新的对等线程（第 7行）。当对pthread_create的调用返回时，主线程和新创建的对等线程同时运行，并 且tid包含新线程的ID。通过在第8行调用pthreadjoin，主线程等待对等线程终止。 最后，主线程调用exit(第9行），终止当时运行在这个进程中的所有线程（在这个示例中 就只有主线程）。
第12〜16行定义了对等线程的例程。它只打印一个字符串，然后就通过执行第15行 中的return语句来终止对等线程。
12.	3. 3创建线程
线程通过调用pthreadjreate函数来创建其他线程。
#include <pthread.h> typedef void *Cfunc)(void *);
int pthread_create(pthread_t *tid, pthread_attr_t *attr, func *f, void *axg);
若成功则返回0,若出错则为非零，
第12章并发编程 693
pthread_create函数创建一个新的线程，并带着一个输人变量arg，在新线程的上 下文中运行线程例程f。能用attr参数来改变新创建线程的默认属性。改变这些属性已 超出我们学习的范围，在我们的示例中，总是用一个为NULL的attr参数来调用 pthread—create 函数。
当pthreacLcreate返回时，参数tid包含新创建线程的ID。新线程可以通过调用 pthreadjelf函数来获得它自己的线程ID。
#include <pthread.h>	
pthread_t pthread_self(void);	返回调用者的线程ID。
12. 3.4 终止线程
一个线程是以下列方式之一来终止的：
•当顶层的线程例程返回时，线程会隐式地终止。
•通过调用pthread_exit函数，线程会显式地终止。如果主线程调用pthread_ex-it,它会等待所有其他对等线程终止，然后再终止主线程和整个进程，返回值为 thread return。
#include <pthread.h>
void ptliread_exit (void *thread_retiirn);
从不返回。
•某个对等线程调用Linux的exit函数，该函数终止进程以及所有与该进程相关的 线程。
•另一个对等线程通过以当前线程ID作为参数调用Pthread_canCei函数来终止当 前线程。
#include <pthread.h>
int pthread_cancel(pthLread_t tid);
若成功则返回0，若出错则为非零。
12.3.5回收已终止线程的资源
线程通过调用pthreadjoin函数等待其他线程终止。
#include <pthread.h>
int pthread_join(ptliread_t tid, void **thread_return);
若成功则返回0，若出错则为非零。
pthreadjoin函数会阻塞，直到线程tid终止，将线程例程返回的通用（void*)指 针赋值为thread_return指向的位置，然后回收已终止线程占用的所有内存资源。
注意，和Linux的wait函数不同，Pthread_j〇in函数只能等待一个指定的线程终 止。没有办法让pthread_wait:等待任意一个线程终止。这使得代码更加复杂，因为它迫
694 第三部分程序间的交互和通信
使我们去使用其他一些不那么直观的机制来检测进程的终止。实际上，Stevens在[110]中 就很有说服力地论证了这是规范中的一个错误。
12.	3. 6分离线程
在任何一个时间点上，线程是可结合的（joinable)或者是分离的（detached)。一个可结 合的线程能够被其他线程收回和杀死。在被其他线程回收之前，它的内存资源（例如栈）是 不释放的。相反，一个分离的线程是不能被其他线程回收或杀死的^它的内存资源在它终 止时由系统自动释放。
默认情况下，线程被创建成可结合的。为了避免内存泄漏，每个可结合线程都应该要 么被其他线程显式地收回，要么通过调用pthread_detaCh函数被分离。
#include <pthread.h>
int pthread_detach(pthread_t tid);
若成功则返回0，若出错则为非零。
pthread_detach函数分离可结合线程tid。线程能够通过以pthread_self (>为参 数的pthread_detach调用来分离它们自己。
尽管我们的一些例子会使用可结合线程，但是在现实程序中，有很好的理由要使用分 离的线程。例如，一个高性能Web服务器可能在每次收到Web浏览器的连接请求时都创 建一个新的对等线程。因为每个连接都是由一个单独的线程独立处理的，所以对于服务器 而言，就很没有必要（实际上也不愿意）显式地等待每个对等线程终止。在这种情况下，每 个对等线程都应该在它开始处理请求之前分离它自身，这样就能在它终止后回收它的内存 资源了 ^
12.3. 7初始化线程
pthread_once函数允许你初始化与线程例程相关的状态。
#include <pthread.h>
pthread_once_t once_control = PTHREAD_ONCE_INIT;
int pthread_once(pthread_once_t *once_control, void (=*=init_routine) (void));
总是返回0。
once_contr〇l变量是一个全局或者静态变量，总是被初始化为PTHREAD_ONCE_ INIT。当你第一次用参数 once_control 调用 pthread_once 时，它调用 init_rou_ tine，这是一个没有输人参数、也不返回什么的函数。接下来的以〇nce_c〇ntr〇l为参数 的pthread_〇nce调用不做任何事情。无论何时，当你需要动态初始化^个线程共享的全 局变量时，pthread_once函数是很有用的。我们将在12. 5. 5节里看到一个示例。
12.	3. 8基于线程的并发服务器
图12-14展示了基于线程的并发echo服务器的代码。整体结构类似于基于进程的设 计。主线程不断地等待连接请求，然后创建一个对等线程处理该请求。虽然代码看似简
第12章并发编程 695
单，但是有几个普遍而且有些微妙的问题需要我们更仔细地看一看。第一个问题是当我们 调用pthreadjreate时，如何将已连接描述符传递给对等线程。最明显的方法就是传递 一个指向这个i述符的指针，就像下面这样
connfd = Accept(listenfd, (SA *) &clientaddr, ftclientlen);
Pthread_create(&tid, NULL, thread, &connfd);
然后，我们让对等线程间接引用这个指针，并将它赋值给一个局部变量，如下所示
void *thread(void *vaxgp) {
int connfd = *((int *)vargp);
code/conc/echoservert. c
1
2 3
5
6
7
8 9
10
11
12
13
14
15
16 17 18*
19
20 21 22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
#include "csapp.h"
void echo(int connfd); void *thread(void *vao:gp);
int main(int argc, char **argv)
int listenfd, *connfdp; socklen_t clientlen; struct sockaddr.storage clientaddr; pthread_t tid;
if (argc != 2) {
fprintf(stderr, "usage: %s <port>\n", argv[0]); exit(0);
>
listenfd = Dpen_listenfd(argv[l]); while (1) {
clientlen=sizeof(struct sockaddr_storage); connfdp = Malloc(sizeof(int));
♦connfdp = Accept(listenfd, (SA *) feclientaddr, ftclientlen); Pthread_create(fetid, NULL, thread, connfdp);
>
>
/* Thread routine */ void *tliread(void *vargp)
int connfd = *((int *)vargp); Pthread_detach(pthread_self()); FreeCvargp); echo(connfd);
Close(connfd); return NULL;
图12-14 基于线程的并发echo服务器
code/conc/echoservert. c
696 第三部分程序间的交互和通信
然而，这样可能会出错，因为它在对等线程的赋值语句和主线程的accept语句间引人了 竞争(race)。如果赋值语句在下一个accept之前完成，那么对等线程中的局部变量 cormfd就得到正确的描述符值。然而，如果赋值语句是在accept之后才完成的，那么对 等线程中的局部变量connfd就得到下一次连接的描述符值。那么不幸的结果就是，现在 两个线程在同一个描述符上执行输入和输出。为了避免这种潜在的致命竞争，我们必须将 accept返回的每个已连接描述符分配到它自己的动态分配的内存块，如第20〜21行所 示。我们会在12. 7. 4节中回过来讨论竞争的问题。
另一个问题是在线程例程中避免内存泄漏。既然不显式地收回线程，就必须分离每个 线程，使得在它终止时它的内存资源能够被收回（第31行）。更进一步，我们必须小心释 放主线程分配的内存块(第32行）。
练习题12.5在图12-5中基于进程的服务器中，我们在两个位置小心地关闭了已连
接描述符：父进程和子进程。然而，在图12-14中基于线程的服务器中，我们只在一
个位置关闭了已连接描述符：对等线程。为什么？
12.4多线程程序中的共享变量
从程序员的角度来看，线程很有吸引力的一个方面是多个线程很容易共享相同的程序 变量。然而，这种共享也是很棘手的。为了编写正确的多线程程序，我们必须对所谓的共 享以及它是如何工作的有很清楚的了解。
为了理解C程序中的一个变量是否是共享的，有一些基本的问题要解答：1)线程的基 础内存模型是什么？ 2)根据这个模型，变量实例是如何映射到内存的？ 3)最后，有多少线 程引用这些实例？ 一个变量是共享的，当且仅当多个线程引用这个变量的某个实例。
为了让我们对共享的讨论具体化，我们将使用图12-15中的程序作为运行示例。尽管 有些人为的痕迹，但是它仍然值得研究，因为它说明了关于共享的许多细微之处。示例程 序由一个创建了两个对等线程的主线程组成。主线程传递一个唯一的ID给每个对等线程， 每个对等线程利用这个ID输出一条个性化的信息，以及调用该线程例程的总次数。
12. 4. 1线程内存模型
一组并发线程运行在一个进程的上下文中。每个线程都有它自己独立的线程上下文， 包括线程ID、栈、栈指针、程序计数器、条件码和通用目的寄存器值。每个线程和其他 线程一起共享进程上下文的剩余部分。这包括整个用户虚拟地址空间，它是由只读文本 (代码）、读/写数据、堆以及所有的共享库代码和数据区域组成的。线程也共享相同的打 开文件的集合。
从实际操作的角度来说，让一个线程去读或写另一个线程的寄存器值是不可能的。另 一方面，任何线程都可以访问共享虚拟内存的任意位置，如果某个线程修改了一个内存位 置，那么其他每个线程最终都能在它读这个位置时发现这个变化。因此，寄存器是从不共 享的，而虚拟内存总是共享的。
各自独立的线程栈的内存模型不是那么整齐清楚的。这些桟被保存在虚拟地址空间的 栈区域中，并且通常是被相应的线程独立地访问的。我们说通常而不是总是，是因为不同 的线程栈是不对其他线程设防的。所以，如果一个线程以某种方式得到一个指向其他线程 栈的指针，那么它就可以读写这个栈的任何部分。示例程序在第26行展示了这一点，其 中对等线程直接通过全局变量ptr间接引用主线程的栈的内容。
第12章并发编程 697
code/concfsharing, c
1
2
3
4
5
6
7
8 9
10
11
12
18
19
20 21 22 23
25
26
#include "csapp.h"
#define N 2
void *thread(void *vargp);
char	/* Global variable */
int main() int i;
pthread_t tid; char *msgs[N] = {
"Hello from foo",
"Hello from bar"
>；
ptr = msgs;
for (i = 0; i < N; i++)
Pthread_create(&tid, NULL, thread, (void *)i); Pthread_exit(NULL);
void *t;hreaid(void 木vargp)
{
int myid = (int) vsirgp; static int cnt = 0;
printf("[%d]: %s (cnt=%d)\n", myid, ptr[myid], ++cnt); return NULL;
----------------------------code/conc/sharing. c
图12-15说明共享不同方面的示例程序
12.4.2将变量映射到内存
多线程的C程序中变量根据它们的存储类型被映射到虚拟内存：
•全局变量。全局变量是定义在函数之外的变量。在运行时，虚拟内存的读/写区域 只包含每个全局变量的一个实例，任何线程都可以引用。例如，第5行声明的全局 变量ptr在虚拟内存的读/写区域中有一个运行时实例。当一个变量只有一个实例 时，我们只用变量名（在这里就是ptr)来表示这个实例。
•本地自动变量。本地自动变量就是定义在函数内部但是没有static属性的变量。 在运行时，每个线程的栈都包含它自己的所有本地自动变量的实例。即使多个线程 执行同一个线程例程时也是如此。例如，有一个本地变量tid的实例，它保存在主 线程的栈中。我们用tid.m来表示这个实例。再来看一个例子，本地变量myid有 两个实例，一个在对等线程〇的栈内，另一个在对等线程1的栈内。我们将这两个 实例分别表示为myici.pCl和myid.pl。
•本地静态变量。本地静态变量是定义在函数内部并有static属性的变量。和全局 变量一样，虚拟内存的读/写区域只包含在程序中声明的每个本地静态变量的一个 实例。例如，即使示例程序中的每个对等线程都在第25行声明了 cnt,在运行时， 虚拟内存的读/写区域中也只有一个cnt的实例。每个对等线程都读和写这个实例。
698 第三部分程序间的交互和通信
12. 4. 3共享变量
我们说一个变量^是共享的，当且仅当它的一个实例被一个以上的线程引用。例如， 示例程序中的变量cnt就是共享的，因为它只有一个运行时实例，并且这个实例被两个对 等线程引用。在另一方面，myid不是共享的，因为它的两个实例中每一个都只被一个线 程引用。然而，认识到像msgs这样的本地自动变量也能被共享是很重要的。
@练习题12.6
A.利用12.4节中的分析，为图12-15中的示例程序在下表的每个条目中填写“是” 或者“否”。在第一列中，符号表示变量u的一个实例，它驻留在线程£的本 地栈中，其中〖要么是m(主线程），要么是pO(对等线程0)或者pi(对等线程1)。
变量实例	主线程引用的？	对等线程0引用的？	对等线程1引用的？
Ptr			
cnt			
i .m			
insgs . m			
myid.po			
rayid.pl			
B.根据A部分的分析，变量ptr、cnt、i、msgs和myid哪些是共享的？
12.5用信号量同步线程
共享变量是十分方便，但是它们也引入了同步错误（synchronization error)的可能性。考 虑图12-16中的程序badcnt.c，它创建了两个线程，每个线程都对共享计数变量cnt加1。 ---------------------------------code/conc/badcnt. c
1	/* WARNING: This code is buggy! */	
2	#include "csapp.h"	
4	void *thread(void *vargp); /* Thread	routine prototype
6	/* Global shared variable */	
7	volatile long cnt = 0; /* Counter */	
8 9	int main(int argc, char **argv)	
10		
11	long niters;	
12	pthread.t tidl, tid2;	
13 14	/* Check input argument */	
15	if (argc != 2) {	
16	printf("usage: %s <niters>\n",	,argv[0]);
17	exit(0);	
18	>	
19	niters = atoi(axgv[1]);	
20 21	/* Create threads and wait for them to finish */	
22	Pthread_create(fttidl, NULL, thread, feniters);	
[fi 12-16 badcnt. c: —个同步不正确的计数器程序
第12章并发编程 699
23	Pthread_create(&tid2, NULL, thread, feniters);
24	Pthread.joinCtidl, NULL);
25	Pthread_join(tid2, NULL);
26
27	/* Check result */
28	if (cnt != (2 * niters))
29	printf("BOOM! cnt=%ld\n", cnt);
30	else
31	printf("OK cnt=%ld\n", cnt);
32	exitC〇);
33	>
34
35	/* Thread routine */
36	void *thread(void *vargp)
37	{
38	long i, niters = *((long *)vargp);
39
40	for (i = 0; i < niters; i++)
41	cnt++;
42
43	return NULL;
44	>
code/conc/badcnt.c
图 12-16	(续）
因为每个线程都对计数器增加了 niters次，我们预计它的最终值是2Xniters。这 看上去简单而直接。然而，当在Linux系统上运行badcnt.c时，我们不仅得到错误的答 案，而且每次得到的答案都还不相同！
linux> ./badcnt 1000000
BOOM! cnt=1445085
-linux> ./badcnt 1000000
BOOM! cnt=1915220
linux> ./badcnt 1000000
BOOH! cnt=1404746
那么哪里出错了呢？为了清晰地理解这个问题，我们需要研究计数器循环（第40〜41 行）的汇编代码，如图12-17所示。我们发现，将线程i的循环代码分解成五个部分是很有 帮助的：
•	在循环头部的指令块。
•	L,-:加载共享变量cnt到累加寄存器％rdx,的指令，这里％rdx,表示线程i中的寄存 器％^乂的值。
•C/,:更新(增加）％rdx,的指令。
•	S,:的更新值存回到共享变量cnt的指令。
•	Ti:循环尾部的指令块。
注意头和尾只操作本地栈变量，而L、U,和S,操作共享计数器变量的内容。
当badcnt.c中的两个对等线程在一个单处理器上并发运行时，机器指令以某种顺序 一个接一个地完成。因此，每个并发执行定义了两个线程中的指令的某种全序（或者交 叉）。不幸的是，这些顺序中的一些将会产生正确结果，但是其他的则不会。
700 第三部分程序间的交互和通信
_______线程/的c代码________
for (i=0; i < niters; i++) ____cnt++;____________
线程/的汇编代码
movq testq jle movl	(%rdi),%rcx %rcx,%rcx .L2 $0,%eax
• L3:	
movq	cnt(%rip),%rdx
addq	%eax
movq	%eax,cnt(%rip)
addq	$1,%rax
cmpq	%rcx,%rax
j ne • L2:	,L3
•	:头
乂,.：加载cnt M :更新cnt 存储cnt
■7]:尾
[冬1 12-17 badcnt.c中计数器循环（第40〜41行）的汇编代码
这里有个关键点：一般而言，你没有办法预测操作系统是否将为你的线程选择一个正 确的顺序。例如，图12-18a展示了一个正确的指令顺序的分步操作。在每个线程更新了 共享变量cnt之后，它在内存中的值就是2,这正是期望的值。
另一方面，图12-18b的顺序产生一个不正确的cnt的值。会发生这样的问题是因为， 线程2在第5步加载cnt，是在第2步线程1加载cut之后，而在第6步线程1存储它的 更新值之前。因此，每个线程最终都会存储一个值为1的更新后的计数器值。我们能够借 助于一种叫做进度图（progress graph)的方法来阐明这些正确的和不正确的指令顺序的也 念，这个图我们将在下一节中介绍。
步骤	线程	指令	Xrdxi	%rdx2	cnt
1	1		——	—	0
2	1	Li	0	—	0
3		t/l	1	—	0
4	2	fi2	—	—	0
5	2	乙2	—	0	0
6	1	5i	1	—	1
7	1	A	1	—	1
8	2	u2	—	1	1
9	2	s2	—	1	1
10	2	T2	—	1	1
步骤	线程	指令	%rdx!	%rdx2	cnt
1			—	—	0
2			0	—	0
3		Ui	1	—	0
4		s,	1	—	1
5	2	H2	—	—	1
6	2		—	1	1
7	2	f/2	—	2	1
8	2	h	—	2	2
9	2	r2	—	2	2
10		n	1	—	2
a)正确的顺序	b)不正确的顺序
图12-18 badcnt.c中第一次循环迭代的指令顺序
@练习题12. 7 根据badcnt.c的指令顺序完成下表：
步骤	线程	指令	%rdxj	%rdx2	cnt
1	1	",	—	—	0
2	1				
3	2	h2			
4	2				
5	2	〇2			
6	2	s2			
7	I	",			
8	1				
9	1				
10	2	t2			
这种顺序会产生一个正确的cnt值吗？
第12章并发编程 701
12.5. 1进度图
进度图（progress graph)将个并发线程的执行模型化为一条n维笛卡儿空间中的轨 迹线。每条轴々对应于线程々的进度。每个点（h，L，…，代表线程AU = 1，…，
已经完成了指令h这一状态。图的原点对应于没有任何线程完成一条指令的初始状态。
图12-19展示了 badcnt.c程序第一次循环迭代的二维进度图。水平轴对应于线程1， 垂直轴对应于线程2。点(Lp S2)对应于线程1完成了 h而线程2完成了 52的状态。
进度图将指令执行模型化为从一种状态到另一种状态的转换（transition)。转换被表示 为一条从一点到相邻点的有向边。合法的转换是向右（线程1中的一条指令完成）或者向上 (线程2中的一条指令完成）的。两条指令不能在同一时刻完成——对角线转换是不允许 的。程序决不会反向运行，所以向下或者向左移动的转换也是不合法的。
一个程序的执行历史被模型化为状态空间中的一条轨迹线。图12-20展示了下面指令 顺序对应的轨迹线：
Hi» Z^i ? Ui» M2» 1^2» Si» T'i » U2» S2» T^2
线程2
线程2
T,	T2
(Li：S2)
S2	s2
U2	u2
/■2	L2
h2	h2
H, I, U, 5,	7-,
图12-19	badcnt.c第一次循环迭代的进度图
L, U, S、 7\ m 12-20 —个轨迹线示例
‘线程1
对于线程操作共享变量cnt内容的指令a,，u,，s,.)构成了一个（关于共享变量 cnt的）临界区（critical section),这个临界区不应该和其他进程的临界区交替执行。换句 话说，我们想要确保每个线程在执行它的临界区中的指令时，拥有对共享变量的互斥的访 问（mutually exclusive access)。通常这种现象称为互斥（mutual exclusion)。
在进度图中，两个临界区的交集形成的状态空间区域称为不安全区（unsafe region)。 图12-21展示了变量cnt的不安全区。注意，不安全区和与它交界的状态相毗邻，但并不 包括这些状态。例如，状态（Hu H2)和（Sp t；2)毗邻不安全区，但是它们并不是不安全 区的一部分。绕开不安全区的轨迹线叫做安全轨迹线（safe trajectory)。相反，接触到任何 不安全区的轨迹线就叫做不安全轨迹线（unsafe trajectory)。图12-21给出了7T；例程序 badcnt.c的状态空间中的安全和不安全轨迹线。上面的轨迹线绕开了不安全区域的左边 和上边，所以是安全的。下面的轨迹线穿越不安全区，因此是不安全的。
任何安全轨迹线都将正确地更新共享计数器。为了保证线程化程序示例的正确执行（实 际上任何共享全局数据结构的并发程序的正确执行)我们必须以某种方式同步线程，使它们 总是有一条安全轨迹线。一个经典的方法是基于信号量的思想，接下来我们就介绍它。
练习题12.8使用图12-21中的进度图，将下列轨迹线划分为安全的或者不安全的。
A.	i 1>1 » Ui y Si » H2 »	» S2 i t Ti
702	第三部分程序间的交互和通信
B. H2 > L，z» H\ * L，i * t/] » Si » Ti » U2» S2» Tz
C. Hu H2» L2, L/2» S2, L], L/-!, Si, Tj, T2
线程2
阍12-21安全和不安全轨迹线。临界区的交集形成了不安全区。 绕开不安全区的轨迹线能够正确更新计数器变量
12. 5. 2信号量
EdsgerDijkstra，并发编程领域的先锋人物，提出了一种经典的解决同步不同执行线 程问题的方法，这种方法是基于一种叫做信号量（semaphore)的特殊类型变量的。信号量5 是具有非负整数值的全局变量，只能由两种特殊的操作来处理，这两种操作称为P和V:
• PG):如果s是非零的，那么P将s减1，并且立即返回。如果s为零，那么就挂 起这个线程，直到s变为非零，而一个V操作会重启这个线程。在重启之后，尸操 作将s减1，并将控制返回给调用者。
•VG): V操作将s加1。如果有任何线程阻塞在P操作等待5变成非零，那么V操 作会重启这些线程中的一个，然后该线程将s减1，完成它的P操作。
P中的测试和减1操作是不可分割的，也就是说，一旦预测信号量s变为非零，就会 将s减1，不能有中断。V中的加1操作也是不可分割的，也就是加载、加1和存储信号 量的过程中没有中断。注意，V的定义中没有定义等待线程被重启动的顺序。唯一的要求 是V必须只能重启一个正在等待的线程。因此，当有多个线程在等待同一个信号量时，你 不能预测V操作要重启哪一个线程。
和V的定义确保了一个正在运行的程序绝不可能进人这样一种状态，也就是一个正 确初始化了的信号量有一个负值。这个属性称为信号量不变性（semaphore invariant)，为 控制并发程序的轨迹线提供了强有力的工具，在下一节中我们将看到。
Posix标准定义了许多操作信号量的函数。
#include <semaphore.h>		
int sem_init(sem_t *sem,	0, unsigned int value);	
int sem_wait(sem_t *s);	/* P(s) */	
int sem_post(sem_t *s);	/* V(s) */	返回：若成功则为0,若出错则为一u
第12章并发编程 703
sem_init函数将信号量sem初始化为value。每个信号量在使用前必须初始化。针 对我们的目的，中间的参数总是零。程序分别通过调用Sem_wait和 Sern_P〇St函数来执 行P和V操作。为了简明，我们更喜欢使用下面这些等价的P和V的包^函数：
#include "csapp.h"
void P(sem_t *s);	/* Wrapper function for sem_wait */
void V(sem_t *s);	/* Wrapper function for sem_post */
返回：无^
旁注
戸和\/名字的起源
Edsger Dijkstra(1930—2002)出生于荷兰。名字P和V来源于荷兰语单词Proberen (测试）和Verhogen(增加）。
12. 5.3使用信号量来实现互斥
信号量提供了一种很方便的方法来确保对共享变量的互斥访问。基本思想是将每个共 享变量(或者一组相关的共享变量）与一个信号量以初始为1)联系起来，然后用PU)和V (.■0操作将相应的临界区包围起来。
以这种方式来保护共享变量的信号量叫做二元信号量（binary semaphore)，因为它的 值总是〇或者1。以提供互斥为目的的二元信号量常常也称为互斥锁（mutex)。在一个互 斥锁上执行P操作称为对互斥锁加锁。类似地，执行V操作称为对互斥锁解锁。对一个 互斥锁加了锁但是还没有解锁的线程称为占用这个互斥锁。一个被用作一组可用资源的计 数器的信号量被称为计数信号量。
图12-22中的进度图展示了我们如何利用二元信号量来正确地同步计数器程序示例。 每个状态都标出了该状态中信号量s的值。关键思想是这种P和V操作的结合创建了一组
线程2
图12-22使用信号量来互斥。S<〇的不可行状态定义了一个禁止区，禁止区 完全包括了不安全区，阻止了实际可行的轨迹线接触到不安全区
704 第三部分程序间的交互和通信
状态，叫做禁止区（forbidden region)，其中s<0。因为信号量的不变性，没有实际可行的 轨迹线能够包含禁止区中的状态。而且，因为禁止区完全包括了不安全区，所以没有实际 可行的轨迹线能够接触不安全区的任何部分。因此，每条实际可行的轨迹线都是安全的， 而且不管运行时指令顺序是怎样的，程序都会正确地增加计数器值。
从可操作的意义上来说，由P和V操作创建的禁止区使得在任何时间点上，在被包 围的临界区中，不可能有多个线程在执行指令。换句话说，信号量操作确保了对临界区的 互斥访问。
总的来说，为了用信号量正确同步图12-16中的计数器程序示例，我们首先声明一个 信号量mutex:
volatile long cnt = 0; /* Counter */
sem.t mutex;	/* Semaphore that protects counter */
然后在主例程中将mutex初始化为1:
Sem_init(ferautex, 0， 1);	/* mutex = 1 */
最后，我们通过把在线程例程中对共享变量cnt的更新包围P和V操作，从而保护 它们：	.
for (i = 0; i < niters; i++) {
PC&mutex); cnt++;
V(&nmtex);
>
当我们运行这个正确同步的程序时，现在它每次都能产生正确的结果了。
linux> ./goodcnt 1000000 OK cnt=2000000
linux> ./goodcnt 1000000 OK cnt=2000000
旁注
进度图给了我们一种较好的方法，将在单处理器上的并发程序执行可视化，也帮助 我们理解为什么需要同步。然而，它们确实也有局限性，特别是对于在多处理器上的并 发执行，在多处理器上一组CPU/高速缓存对共享同一个主存。多处理器的工作方式是 进度图不能解释的。特别是，一个多处理器内存系统可以处于一种状态，不对应于进度 图中任何轨迹线。不管如何，结论总是一样的：无论是在单处理器还是多处理器上运行 程序，都要同步你对共享变量的访问。
12. 5. 4利用信号量来调度共享资源
除了提供互斥之外，信号量的另一个重要作用是调度对共享资源的访问。在这种场景 中，一个线程用信号量操作来通知另一个线程，程序状态中的某个条件已经为真了。两个 经典而有用的例子是生产者-消费者和读者-写者问题。
1.生产者-消费者问题
图12-23给出了生产者-消费者问题。生产者和消费者线程共享一个有《个槽的有限缓冲 区。生产者线程反复地生成新的项目（item),并把它们插入到缓冲区中。消费者线程不断地
第章并发编程 705
从缓冲区中取出这些项目，然后消费(使用)它们。也可能有多个生产者和消费者的变种。
图12-23生产者-消费者问题。生产者产生项目并把它们插人到一个有限的缓冲区中。
消费者从缓冲区中取出这些项目，然后消费它们
因为插人和取出项目都涉及更新共享变量，所以我们必须保证对缓冲区的访问是互斥 的。但是只保证互斥访问是不够的，我们还需要调度对缓冲区的访问。如果缓冲区是满的 (没有空的槽位），那么生产者必须等待直到有一个槽位变为可用。与之相似，如果缓冲区 是空的（没有可取用的项目），那么消费者必须等待直到有一个项目变为可用。
生产者-消费者的相互作用在现实系统中是很普遍的。例如，在一个多媒体系统中， 生产者编码视频帧，而消费者解码并在屏幕上呈现出来。缓冲区的目的是为了减少视频流 的抖动，而这种抖动是由各个帧的编码和解码时与数据相关的差异引起的。缓冲区为生产 者提供了一个槽位池，而为消费者提供一个已编码的帧池。另一个常见的示例是图形用户 接口设计。生产者检测到鼠标和键盘事件，并将它们插人到缓冲区中。消费者以某种基于 优先级的方式从缓冲区取出这些事件，并显示在屏幕上。
在本节中，我们将开发一个简单的包，叫做SBUF，用来构造生产者-消费者程序。 在下一节里，我们会看到如何用它来构造一个基于预线程化（prethreading)的有趣的并发 服务器。SBUF操作类型为sbuf_t的有限缓冲区（图12-24)。项目存放在一个动态分配的 n项整数数组（buf)中。front和rear索引值记录该数组中的第一项和最后一项a三个信 号量同步对缓冲区的访问。mutex信号量提供互斥的缓冲区访问。slots和items信号量 分别记录空槽位和可用项目的数量。
1	typedef struct -C
2	int	*buf;
3	iat	n;
4	int	front;
5	int	rear;
6	sem_t	mutex;
7	sem_t	slots;
8	sem_t	items;
9	> sbuf.t;
code/conc/sbuf.h
/* Buffer array */
/* Maximum number of slots */
/* buf[(front+l)%n] is first item */ /* buf[rear%n] is last item */
/* Protects accesses to buf */
/* Counts available slots 本/
/* Counts available items */
code/conc/sbuf.h
图12-24 sbuf_t: SBUF包使用的有限缓冲区
图12-25给出了 SBUF函数的实现。sbUf_init函数为缓冲区分配堆内存，设置 front和rear表示一个空的缓冲区，并为三个信号量赋初始值。这个函数在调用其他三 个函数中的任何一个之前调用一次。sbuf_deinit函数是当应用程序使用完缓冲区时，释 放缓冲区存储的。sbuf_inSert函数等待一个可用的槽位，对互斥锁加锁，添加项目，对 互斥锁解锁，然后宣布有一个新项目可用。sbuf_remove函数是与sbuf_insert函数对 称的。在等待一个可用的缓冲区项目之后，对互斥锁加锁，从缓冲区的前面取出该项目， 对互斥锁解锁，然后发信号通知一个新的槽位可供使用。
706 第三部分程序间的交互和通信
1
2
3
4
5
6
7
8 9
10
11
12
13
14
15
16
17
18
19
20 21 22 2B
24
25
26
27
28
29
30
31
32 3B
34
35
36
37
38
39
40
41
------------------------------------------------------------------------------code/conc/sbuf.c
#include "csapp.h"
#include "sbuf.h"
/* Create an empty, bounded, shared FIFO buffer with n slots */ void sbuf^initCsbuf.t *sp, int n)
sp->buf = Calloc(n,	sizeof(int))		
sp->n = n;			/*
sp->front - sp->rear		〇;	/*
Sem^init(&sp->mutex,	〇,	1);	/*
Sem_init(&sp~>slots,	〇,	n);	/*
Sem_in.it (&sp->items,	〇,	0);	/*
Buffer holds max of n items */
Empty buffer iff front =- rear */ Bineiry semaphore for locking */ Initially, buf has n empty slots */ Initially, buf has zero data items */
/* Clean up buffer sp */ void sbuf_deinit(sbuf_t *sp) i
Free(sp->buf);
/* Insert item onto the rear of shared buffer sp */ void sbuf_insert(sbuf_t *sp, int item)
P(&sp->slots);
P(&sp->mutex);
sp->buf[(++sp->rear)%(sp->n)] = item; V(&sp->mutex);
V(fesp->items);
/* Wait for available slot */ /* Lock the buffer */
/* Insert the item */
/* Unlock the buffer */
/* Announce available item */
/* Remove and return the first item from buffer sp */ int sbuf.remove (sbuf_t *sp)
int item;
P(&sp->items);
P(&sp->mutex);
item = sp->buf[(++sp->front)%(sp->n)]; V(&sp->nmtex);
V(&sp->slots); return item;
/* Wait for available item */ /* Lock the buffer */
/* Remove the item */
/* Unlock the buffer */
/* Announce available slot */
code/conc/sbuf.c
图12-25 SBUF:同步对有限缓冲区并发访问的包
@练习题12.9设f表示生产者数量，c表示消费者数量，而；7表示以项目单元为单位 的缓冲区大小。对于下面的每个场景，指出sbuf_insert和sbuf_remove中的互斥 锁信号量是否是必需的。	^
A.	户=1，（7=1，71>1
B.	p — 1, c=l, n = \
C.	/>>1，c>l，《=1 2.读者-写者问题
读者-写者问题是互斥问题的一个概括。一组并发的线程要访问一个共享对象，例如
第12章并发编程 m
—个主存中的数据结构，或者一个磁盘上的数据库。有些线程只读对象，而其他的线程只 修改对象。修改对象的线程叫做写者。只读对象的线程叫做读者。写者必须拥有对对象的 独占的访问，而读者可以和无限多个其他的读者共享对象。一般来说，有无限多个并发的 读者和写者。
读者-写者交互在现实系统中很常见。例如，一个在线航空预定系统中，允许有 无限多个客户同时查看座位分配，但是正在预订座位的客户必须拥有对数据库的独占 的访问。再来看另一个例子，在一个多线程缓存Web代理中，无限多个线程可以从 共享页面缓存中取出已有的页面，但是任何向缓存中写入一个新页面的线程必须拥有 独占的访问。
读者-写者问题有几个变种，分别基于读者和写者的优先级。第一类读者-写者问题，读 者优先，要求不要让读者等待，除非已经 把使用对象的权限赋予了一个写者。换句 话说，读者不会因为有一个写者在等待而 等待。第二类读者-写者问题，写者优先，
要求一旦一个写者准备好可以写，它就会 尽可能快地完成它的写操作。同第一类问 题不同，在一个写者后到达的读者必须等 待，即使这个写者也是在等待。
图12-26给出了一个对第一类读者-写者问题的解答。同许多同步问题的解 答一样，这个解答很微妙，极具欺骗性 地简单。信号量w控制对访问共享对象 的临界区的访问。信号量mutex保护对 共享变量readcnt的访问，readcnt统 计当前在临界区中的读者数量。每当一 个写者进人临界区时，它对互斥锁w加 锁，每当它离开临界区时，对w解锁。
这就保证了任意时刻临界区中最多只有 一个写者。另一方面，只有第一个进入 临界区的读者对w加锁，而只有最后一 个离开临界区的读者对w解锁。当一个 读者进人和离开临界区时，如果述有其 他读者在临界区中，那么这个读者会忽 略互斥锁w。这就意味着只要还有一个读 者占用互斥锁w，无限多数量的读者可以 没有障碍地进人临界区。
对这两种读者_写者问题的正确解答 可能导致饥饿（starvation),饥饿就是一 个线程无限期地阻塞，无法进展。例如，
图12-26所示的解答中，如果有读者不断	图12-26对第一类读者-写者问题的解答。
地到达，写者就可能无限期地等待。	读者优先级高于写者
/* Global variables */
int readcnt; /* Initially = 0 */
sera_t mutex, w; /* Both initially = 1 */
void reader(void)
while (1)
P(&mutex); readcnt++;
if (readcnt == 1) /* First in */ P(&w);
V(femutex);
/* Critical section */
/* Reading happens */
P(ferautex); readcnt--;
if (readcnt == 0) /* Last out */ V(&w);
V(&mutex);
>
>
void writer(void)
while ⑴{
P(&w);
/* Critical section */
/* Writing happens */
V(few);
>
708	第三部分程序间的交互和通信
@练习题12. 10图12-26所示的对第一类读者-写者问题的解答给予读者较高的优先 级，但是从某种意义上说，这种优先级是很弱的，因为一个离开临界区的写者可能重 启一个在等待的写者，而不是一个在等待的读者。描述出一个场景，其中这种弱优先 级会导致一群写者使得一个读者饥饿。
旁注
我们已经向你展示了如何利用信号量来同步线程，主要是因为它们简单、经典，并且 有一个清晰的语义模型。但是你应该知道还是存在着其他同步技术的。例如，Java线程是 用一种叫做Java监控器(Java Monitor)[48]的机制来同步的，它提供了对信号量互斥和调 度能力的更高级别的抽象；实际上，监控器可以用信号量来实现。再来看一个例子， Pthreads接口定义了一组对互斥锁和条件变量的同步操作^ Pthreads互斥锁被用来实现互 斥。条件变量用来调度对共享资源的访问，例如在一个生产者-消费者程序中的有限缓冲区。
12.5.5综合：基于预线程化的并发服务器
我们已经知道了如何使用信号量来访问共享变量和调度对共享资源的访问。为了帮助 你更清晰地理解这些思想，让我们把它们应用到一个基于称为预线程化（prethreading/技 术的并发服务器上。
在图12-14所示的并发服务器中，我们为每一个新客户端创建了一个新线程。这种方 法的缺点是我们为每一个新客户端创建一个新线程，导致不小的代价。一个基于预线程化 的服务器试图通过使用如图12-27所示的生产者-消费者模型来降低这种开销。服务器是 由一个主线程和一组工作者线程构成的。主线程不断地接受来自客户端的连接请求，并将 得到的连接描述符放在一个有限缓冲区中。每一个工作者线程反复地从共享缓冲区中取出 描述符，为客户端服务，然后等待下一个描述符。
图12-27预线程化的并发服务器的组织结构。一组现有的线程不断地取出 和处理来自有限缓冲区的已连接描述符
图12-28显示了我们怎样用SBUF包来实现一个预线程化的并发echo服务器。在初始 化了缓冲区sbuf (第24行）后，主线程创建了一组工作者线程（第25〜26行）。然后它进 入了无限的服务器循环，接受连接请求，并将得到的已连接描述符插人到缓冲区sbuf中。 每个工作者线程的行为都非常简单。它等待直到它能从缓冲区中取出一个已连接描述符 (第39行），然后调用eCh〇_cnt函数回送客户端的输入。
图12-29所示的函数echo_cnt是图11-22中的echo函数的一个版本，它在全局变量 byte_cmt中记录了从所有客户端接收到的累计字节数。这是一段值得研究的有趣代码， 因为它向你展示了一个从线程例程调用的初始化程序包的一般技术。在这种情况中，我们
第12章并发编程 709
需要初始化byte_cnt计数器和mutex信号量。一个方法是我们为SBUF和m〇程序包 使用过的，它要求主线程显式地调用一个初始化函数。另外一个方法，在此显示的，是当 第一次有某个线程调用ech〇_Cnt函数时，使用Pthread_onCe函数(第19行）去调用初始化 函数。这个方法的优点是它€程序包的使用更加容易。这种方法的缺点是每一次调用ech〇_ cnt都会导致调用pthread_once函数，而在大多数时候它没有做什么有用的事。
code/conc/echoservert-pre. c
1	#include "csapp.h"
2	#include "sbuf.h"
3	#define NTHREADS	4
4	#define SBUFSIZE	16
5
6	void echo_cnt(int connfd);
7	void *threadCvoid *vargp);
8
9	sbuf_t sbuf; /* Shared buffer of connected descriptors */
10
11	int main(int argc, chair **argv)
12	{
13	int i, listenfd, connfd;
14	socklen_t clientlen;
15	struct sockaddr_storage clientaddr;
16	pthread_t tid;
17
18	if (argc != 2) {
19	fprintf(stderr, "usage: %s <port>\n", argv[0]);
20	exit(0);
21	>
22	listenfd = Open_listenfd(argv[l]);
23
24	sbuf_init C&sbuf, SBUFSIZE);
25	for (i = 0; i < NTHREADS; i++)	/* Create worker threads */
26'	Pthread_create(&tid, NULL, thread, NULL);
27
28	while	(1)	{
29	clientlen = sizeof(struct sockaddr.storage);
30	connfd = Accept(listenfd, (SA *) &clientaddr, ftclientlen);
31	sbuf.insert(fesbuf, connfd); /* Insert connfd in buffer */
32	>
33	>
B4
35	void *thread(void *vargp)
36	{
37	Pthread_detach(pthread_self());
38	while	(1)	{
39	int connfd = sbuf_remove(&sbuf); /* Remove connfd from buffer */
40	echo_cnt(coimfd);	/* Service client */
41	Close(connfd);
42	>
43	>
code/conc/echoservert-pre.c
图12-28 —个预线程化的并发echo服务器。这个服务器使用的是 有一个生产者和多个消费者的生产者-消费者模型
710 第三部分程序间的交互和通信
code/conc/echo-cnt. c
^	#include "csapp.h"
2
l	static int byte_cnt; /* Byte counter */
4	static sem_t mutex;	/* and the mutex that protects it */
5
6	static void init_echo_cnt(void)
7	{
8	Sem.init(&mutex, 0，	1);
9	byte_cnt = 0;
i〇 >
n
12	void echo_cnt(int connfd)
13	{
14	int n;
15	char buf[MAXLIKE];
16	rio_t rio;
17	static pthread_once_t once =	PTHREAD_ONCE_INIT;
18
19	Pthread_once(feonce,	init_echo_cnt);
20	Rio_readinitb(&rio,	connfd);
21	while((n = Rio_readlineb(&rio, buf, MAXLINE)) != 0) {
22	P(&mutex);
23	byte_cnt += n;
24	printf("server	received	%d (%d total) bytes on fd %d\n"，
25	n, byte_cnt, connfd);
26	V(&mutex);
27	Rio_writen(connfd,	buf,	n);
28	>
29	>
----------------------------------code/conc/echo-cnt. c
1冬I 12-29 echo_cnt: echo的一个版本，它对从客户端接收的所有字节计数
—旦程序包被初始化，ech〇_Cnt函数会初始化RIO带缓冲区的I/O包（第20行）， 然后回送从客户端接收到的每一个文本行。注意，在第23〜25行中对共享变量byte_cnt 的访问是被P和V操作保护的。
旁注
基于线程的事件驱动程序
I/O多路复用不是编写事件驱动程序的唯一方法。例如，你可能已经注意到我们刚 才开发的并发的预线程化的服务器实际上是一个事件驱动服务器，带有主线程和工作者 线程的简单状态机。主线程有两种状态（“等待连接请求”和“等待可用的缓冲区槽 位”）、两个I/O事件（“连接请求到达”和“缓冲区槽位变为可用”）和两个转换（“接受连 接请求”和“插入缓冲区项目”）。类似地，每个工作者线程有一个状态（“等待可用的缓 冲项目”）、一个I/O事件（“缓冲区项目变为可用”）和一个转换（“取出缓冲区项目”）。
12.6使用线程提高并行性
到目前为止，在对并发的研究中，我们都假设并发线程是在单处理器系统上执行的。
第12章并发编程 711
然而，大多数现代机器具有多核处理器。并发程序通常在这样的机器上运行得更快，因为 操作系统内核在多个核上并行地调度这些并发线程，而不是在单个核上顺序地调度。在像 繁忙的Web服务器、数据库服务器和大型科学计算代码这样的应用中利用这样的并行性 是至关重要的，而且在像Web浏览器、电子表格处理程序和文档处理程序这样的主流应 用中，并行性也变得越来越有用。	所有的程序
图12-30给出了顺序、并发和并行程序之间的 集合关系。所有程序的集合能够被划分成不相交 的顺序程序集合和并发程序的集合。写顺序程序 只有一条逻辑流。写并发程序有多条并发流。并 行程序是一个运行在多个处理器上的并发程序。
因此，并行程序的集合是并发程序集合的真子集。
并行程序的详细处理超出了本书讲述的范围，
但是研究一个非常简单的示例程序能够帮助你理解并行编程的一些重要的方面。例如，考 虑我们如何并行地对一列整数〇,…，n—1求和。当然，对于这个特殊的问题，有闭合形 式表达式的解答(译者注：即有现成的公式来计算它，即和等于— 1)/2)，但是尽管如 此，它是一个简洁和易于理解的示例，能让我们对并行程序做一些有趣的说明。
将任务分配到不同线程的最直接方法是将序列划分成r个不相交的区域，然后给f个 不同的线程每个分配一个E域。为了简单，假设《是〖的倍数，这样每个区域有个元 素。让我们来看看多个线程并行处理分配给它们的区域的不同方法。
最简单也最直接的选择是将线程的和放人一个共享全局变量中，用互斥锁保护这个变 量。图12-31给出了我们会如何实现这种方法。在第28〜33行，主线程创建对等线程，然后 等待它们结束。注意，主线程传递给每个对等线程一个小整数，作为唯一的线程1D。每个对 等线程会用它的线程ID来决定它应该计算序列的哪一部分。这个向对等线程传递一个小的 唯一的线程ID的思想是一项通用技术，许多并行应用中都用到了它。在对等线程终止后， 全局变量gsum包含着最终的和。然后主线程用闭合形式解答来验证结果(第36〜37行）。
--------------------------------code/conc/psum-mutex.c
1	#include "csapp.h"
2	#define MAXTHREADS 32
3
4	void *sum_rautex(void *vargp); /* Thread routine */
5
6	/* Global shared variables */
7	long gsum = 0;	/*	Global sum */
8	long nelems_per_thread;	/*	Number of elements to sum */
9	sem_t mutex;	/*	Mutex to protect global sum */
10
11	int main(int argc, char **argv)
12	{
13	long i, nelems, log_nelems, nthreads, myid[MAXTHREADS];
14	pthread_t tid[MAXTHREADS];
15
16	/* Get input arguments */
图12-31 psum-mutex的主程序，使用多个线程将一个序列元素的和放入 一个用互斥锁保护的共享全局变量中
并发程序	
	顺序程序
图12-30顺序、	并发和并行程序
集合之间的关系
712	第三部分程序间的交互和通信
17	if (sirgc != 3) {
18	printf("Usage: %s <nthreads> <log_nelems>\n", argv[0]);
19	exit(O);
20	>
21	nthreads = atoi(argv[1]);
22	log_nelems = atoi(axgv[2]);
23	nelems = (1L « log_nelems);
24	nelems_per_tliread = nelems / nthreads;
25	sem.init(&mutex, 0, 1);
26
27	/* Create peer threads and wait for them to finish */
28	for (i = 0; i < nthreads; i++) {
29	myid[i] = i;
30	Pthread_createC&tid[i], NULL,	sum^mutex, &myid[i]);
31	>
32	for (i = 0; i < nthreads; i++)
33	Ptliread_joiii(tid[i] , NULL);
34
35	/* Check final answer */
36	if (gsum != (nelems * (nelems-l))/2)
37	printf("Error: result=%ld\n"，	gsum);
38
39	exit(0);
40	>
code/conc/psum-mutex. c
图 12-31	(续）
图12-32给出了每个对等线程执行的函数。在第4行中，线程从线程参数中提取出线 程ID，然后用这个ID来决定它要计算的序列区域(第5〜6行）。在第9〜13行中，线程在 它的那部分序列上迭代操作，每次迭代都更新共享全局变量gsum。注意，我们很小心地 用P和V互斥操作来保护每次更新。
-------------------------------------------------------------------code/conc/psum-mutex.c
1	/* Thread routine for psum-rautex.c */
2	void *sum_mutex(void *vargp)
B {
4	long	myid = *((long	*)vargp);	/*	Extract the	thread ID	*/
5	long	start	= myid *	nelems_per_thread;	/*	Start element index */
6	long	end »	start + nelems_per_thread;	/*	End element	index */
7	long	i;
8
9	for (i	= start;	i < end; i++) {
l〇	P(femutex);
11	gsum += i;
12	V(&mutex);
13	>
14	return	NULL;
15	>
--------------------------------------code/conc/psum-mutex.c
图12-32 psum-mutex的线程例程。每个对等线程将各自的和累加进 一个用互斥锁保护的共享全局变量中
第12章并发编程 713
我们在一个四核系统上，对一个大小为n = 231的序列运行psum- mutex，测量它的运 行时间（以秒为单位），作为线程数的函数，得到的结果难懂又令人奇怪：
	线程数				
版本	1	2	4	8	16
psum-mutex	68	432	| 719	552	599
程序单线程顺序运行时非常慢，几乎比多线程并行运行时慢了一个数量级。不仅如 此，使用的核数越多，性能越差。造成性能差的原因是相对于内存更新操作的开销，同步 操作（户和\〇代价太大。这突显了并行编程的一项重要教训.•同步开销巨大，要尽可能避 免。如果无可避免，必须要用尽可能多的有用计算弥补这个开销。
在我们的例子中，一种避免同步的方法是让每个对等线程在一个私有变量中计算它自 己的部分和，这个私有变量不与其他任何线程共享，如图12-33所示。主线程（图中未显 示)定义一个全局数组psum，每个对等线程；把它的部分和累积在psum[i]中。因为小心 地给了每个对等线程一个不同的内存位置来更新，所以不需要用互斥锁来保护这些更新。 唯一需要同步的地方是主线程必须等待所有的子线程完成。在对等线程结束后，主线程把 psum向量的元素加起来，得到最终的结果。
1
2
4
5
6
7
8 9
U
12
------------------------------------------------------—-----------code/conc/psum-array. c
/* Thread routine for psum-array.c */ void *sum_array(void *vargp)
long myid = *((long *)vargp);	/* Extract tlie thread ID 本/
long start = myid * nelems_per_tliread; /* Start element index */ long end = start + nelems_per_thread; /* End element index */ long i;
for (i = start; i < end; i++) { psum [myid] += i;
>
return NULL;
>
------------------------------------------------------------------code/conc/psum-array. c
图12-33 psum-array的线程例程。每个对等线程把它的部分和
累积在一个私有数组元素中，不与其他任何对等线程共享该元素
在四核系统上运行psum- array时，我们看到它比psum-mutex运行得快好几个数 量级：
	线程数				
版本	1	2	4	8	16
psum-mutex	68.00	432.00	719.00	552.00	599.00
psum-array	7.26	3.64	1.91	1.85	1.84
在第5章中，我们学习到了如何使用局部变量来消除不必要的内存引用。图12-34展 示了如何应用这项原则，让每个对等线程把它的部分和累积在一个局部变量而不是全局变 量中。当在四核机器上运行psum-local时，得到一组新的递减的运行时间：
714 第三部分程序间的交互和通信
	线程数				
版本	1	2	4	8	16
psum-mucex	68.00	432.00	719.00	552.00	599.00
psum-array	7.26	3.64	1.91	1.85	1.84
psum-local	1.06	0.54	0.28	0.29	0.30
-----------------------------------------------------------------------—code/conc/psum-local.c
1	/* Thread routine for psum-local.c */
2	void *sum_local(void *vargp)
3	{
4	long	myid = *((long	*)vargp);	/*	Extract the	thread ID */
5	long	start = myid *	nelems.per.thread;	/*	Start element index */
6	long	end = start + nelems_per_thread;	/*	End element	index */
7	long	i, sum = 0;
8
9	for (i	= start;	i < end; i++) {
10	sum += i;
11	>	-
12	psum[myid] =	sum;
13	return	NULL;
14	>
---------------------------------------code/conc/psum-local.c
图12-34 psum-local的线程例程。每个对等线程把它的部分和累积在一个局部变量中
从这个练习可以学习到一个重要的经验，那就是写并行程序相当棘手。对代码看上去 很小的改动可能会对性能有极大的影响。
刻画并行程序的性能
图12-35给出了图12-34中程序 psum- local的运行时间，它是线程数 的函数。在每个情况下，程序运行在一 个有四个处理器核的系统上，对一个 « = 23]个元素的序列求和。我们看到，
随着线程数的增加，运行时间下降，直 到增加到四个线程，此时，运行时间趋 于平稳，甚至开始有点增加。
在理想的情况中，我们会期望运行时 间随着核数的增加线性下降。也就是说，
我们会期望线程数每增加一倍，运行时间就下降一半。确实是这样，直到到达z>4的时候， 此时四个核中的每一个都忙于运行至少一个线程。随着线程数量的增加，运行时间实际上增 加了一点儿，这是由于在一个核上多个线程上下文切换的开销。由于这个原因，并行程序常 常被写为每个核上只运行一个线程。
虽然绝对运行时间是衡量程序性能的终极标准，但是还是有一些有用的相对衡量标准能 够说明并行程序有多好地利用了潜在的并行性。并行程序的加速比(speedup)通常定义为
线程
阁12-35 psum-local的性能（图12-34) ^用四个 处理器核对一个231个元素序列求和
第12章并发编程 715
S - Tl
Sp-T~P
这里p是处理器核的数量，Tk是在丨个核上的运行时间。这个公式有时被称为强扩展 (strong scaling)。当了1是程序顺序执行版本的执行时间时，Sp称为绝对加速比（absolute speedup)。当：^是程序并行版本在一个核上的执行时间时，S,称为相对加速比（relative speedup)。绝对加速比比相对加速比能更真实地衡量并行的好处。即使是当并行程序在一 个处理器上运行时，也常常会受到同步开销的影响，而这些开销会人为地增加相对加速比 的数值，因为它们增加了分子的大小。另一方面，绝对加速比比相对加速比更难以测量， 因为测量绝对加速比需要程序的两种不同的版本。对于复杂的并行代码，创建一个独立的 顺序版本可能不太实际，或者因为代码太复杂，或者因为源代码不可得。
—种相关的测量量称为效率（efficiency)，定义为
Ep =
通常表示为范围在（0, 100]之间的百分比。效率是对由于并行化造成的开销的衡量。具有 高效率的程序比效率低的程序在有用的工作上花费更多的时间，在同步和通信上花费更少
的时间。
图12-36给出了我们并行求和示 例程序的各个加速比和效率测量值。 像这样超过90%的效率是非常好的， 但是不要被欺骗了。能取得这么高的 效率是因为我们的问题非常容易并行 化。在实际中，很少会这样。数十年
线程（/)	1	2	4	8	16
核（P)	1	2	4	4	4
运行时间（7；)	1.06	0.54	0.28	0.29	0.30
加速比（总）	1	1.9	3.8	3.7	3.5
效率（&)	100%	98%	95%	91%	88%
图12-36 图12-35中执行时间的加速比和并行效率
来，并行编程一直是一个很活跃的研究领域。随着商用多核机器的出现，这些机器的核数 每几年就翻一番，并行编程会继续是一个深入、困难而活跃的研究领域。
■加速比还有另外一面，称为弱扩展（weak scaling),在增加处理器数量的同时，增加 问题的规模，这样随着处理器数量的增加，每个处理器执行的工作量保持不变。在这种描 述中，加速比和效率被表达为单位时间完成的工作总量。例如，如果将处理器数量翻倍， 同时每个小时也做了两倍的工作量，那么我们就有线性的加速比和100%的效率。
弱扩展常常是比强扩展更真实的衡量值，因为它更准确地反映了我们用更大的机器做 更多的工作的愿望。对于科学计算程序来说尤其如此，科学计算问题的规模很容易增加， 更大的问题规模直接就意味着更好地预测。不过，还是有一些应用的规模不那么容易增 加，对于这样的应用，强扩展是更合适的。例如，实时信号处理应用所执行的工作量常常 是由产生信号的物理传感器的属性决定的。改变工作总量需要用不同的物理传感器，这不 太实际或者不太必要。对于这类应用，我们通常想要用并行来尽可能快地完成定量的 工作。
练习题12."M对于下表中的并行程序，填写空白处。假设使用强扩展。
线程（0	1	2	4
核（/〇	1	2	4
运行时间（7；)	12	8	6
加速比（5P)		1.5	
效率（尽）	100%		50%
716 第三部分程序间的交互和通信
12.7其他并发问题
你可能已经注意到了，一旦我们要求同步对共享数据的访问，那么事情就变得复杂得 多了。迄今为止，我们已经看到了用于互斥和生产者-消费者同步的技术，但这仅仅是冰 山一角。同步从根本上说是很难的问题，它引出了在普通的顺序程序中不会出现的问题。 这一小节是关于你在写并发程序时需要注意的一些问题的（非常不完整的）综述。为了让事 情具体化，我们将以线程为例描述讨论。不过要记住，这些典型问题是任何类型的并发流 操作共享资源时都会出现的。
12.7.1线程安全
当用线程编写程序时，必须小心地编写那些具有称为线程安全性（thread safety)属性 的函数。一个函数被称为线程安全的（thread-safe),当且仅当被多个并发线程反复地调用 时，它会一直产生正确的结果。如果一个函数不是线程安全的，我们就说它是线程不安全 的（thread-unsafe) 0
我们能够定义出四个（不相交的）线程不安全函数类：
第1类：不保护共享变量的函数。我们在图12-16的thread函数中就已经遇到了这样 的问题，该函数对一个未受保护的全局计数器变量加1。将这类线程不安全函数变成线程安 全的，相对而言比较容易：利用像P和V■操作这样的同步操作来保护共享的变量。这个方法 的优点是在调用程序中不需要做任何修改。缺点是同步操作将减慢程序的执行时间。
第2类：保持跨越多个调用的状态的函数。一个伪随机数生成器是这类线程不安全函 数的简单例子。请参考图12-37中的伪随机数生成器程序包。rand函数是线程不安全的， 因为当前调用的结果依赖于前次调用的中间结果。当调用srand为rand设置了一个种子 后，我们从一个单线程中反复地调用rand，能够预期得到一个可重复的随机数字序列。 然而，如果多线程调用rand函数，这种假设就不再成立了。
-------------------------------code/conc/rand. c
unsigned next.seed = 1;
/* rand - return pseudorandom integer in the range 0..32767 */ unsigned rand(void)
next_seed = next_seed*1103515245 + 12543; return (unsigned)(next_seed>>16) % 32768;
>
/* srand - set the initial seed for randO */ void srand(unsigned new_seed)
next_seed = new^seed;
13
14
-----------------------------------code/conc/rand. c
图12-37 —个线程不安全的伪随机数生成器（基于[61])
使得像rand这样的函数线程安全的唯一方式是重写它，使得它不再使用任何static 数据，而是依靠调用者在参数中传递状态信息。这样做的缺点是，程序员现在还要被迫修
第12章并发编程 717
改调用程序中的代码。在一个大的程序中，可能有成百上千个不同的调用位置，做这样的 修改将是非常麻烦的，而且容易出错。
第3类：返回指向静态变量的指针的函数。某些函数，例如ctime和gethost-byname，将计算结果放在一个static变量中，然后返回一个指向这个变量的指针。如果我 们从并发线程中调用这些函数，那么将可能发生灾难，因为正在被一个线程使用的结果会 被另一个线程悄悄地覆盖了。
有两种方法来处理这类线程不安全函数。一种选择是重写函数，使得调用者传递存放结 果的变量的地址。这就消除了所有共享数据，但是它要求程序员能够修改函数的源代码。
如果线程不安全函数是难以修改或不可能修改的（例如，代码非常复杂或是没有源代 码可用），那么另外一种选择就是使用加锁-复制（lock-ami-copy)技术。基本思想是将线程 不安全函数与互斥锁联系起来。在每一个调用位置，对互斥锁加锁，调用线程不安全函 数，将函数返回的结果复制到一个私有的内存位置，然后对互斥锁解锁。为了尽可能地减 少对调用者的修改，你应该定义一个线程安全的包装函数，它执行加锁-复制，然后通过 调用这个包装函数来取代所有对线程不安全函数的调用。例如，图12-38给出了 ctime的 一个线程安全的版本，利用的就是加锁-复制技术。
------------------------------------------code/conc/ctime-ts. c
1	char *ctime_ts(coast time_t 木timep, char *privatep)
2	{
3	char *sharedp;
4
5	P(&mutex);
6	sharedp = ctime(timep);
7	strcpy(privatep, sharedp); /* Copy string from shared to private 本/
8	V(&mutex);
9	return privatep; i〇 >
------------------------------------------code/conc/ctime-ts.c
图12-38 C标准库函数ctime的线程安全的包装函数。使用加锁-复制技术 调用一个第3类线程不安全函数
第4类：调用线程不安全函数的函数。如果函数/调用线程不安全函数g，那么/就 是线程不安全的吗？不一定。如果g是第2类函数，即依赖于跨越多次调用的状态，那么 /也是线程不安全的，而且除了重写g以外，没有什么办法。然而，如果g是第1类或者 第3类函数，那么只要你用一个互斥锁保护调用位置和任何得到的共享数据，/仍然可能 是线程安全的。在图12-38中我们看到了一个这种情况很好的示例，其中我们使用加锁-复制编写了一个线程安全函数，它调用了一个线程不安全的函数。
12.7.2 可重入性
有一类重要的线程安全函数，叫做可重入函 数（reentrant function),其特点在于它们具有这 样一种属性：当它们被多个线程调用时，不会引 用任何共享数据。尽管线程安全和可重入有时会 (不正确地）被用做同义词，但是它们之间还是有 清晰的技术差别，值得留意。图12-39展示了可
所有的函数________________
线程安全函数
线程不安全函数
闬12-39 可重人函数、线程安全函数和线程 不安全函数之间的集合关系
718	第三部分程序间的交互和通信
重人函数、线程安全函数和线程不安全函数之间的集合关系。所有函数的集合被划分成不 相交的线程安全和线程不安全函数集合。可重人函数集合是线程安全函数的一个真子集。
可重入函数通常要比不可重人的线程安全的函数高效一些，因为它们不需要同步操 作。更进一步来说，将第2类线程不安全函数转化为线程安全函数的唯一方法就是重写 它，使之变为可重人的。例如，图12-40展示了图12-37中rand函数的一个可重入的版 本。关键思想是我们用一个调用者传递进来的指针取代了静态的next变量。
------------------------------------code/conc/rand-r. c
1	/* rand.r - return a pseudorandom integer on 0..32767 */
2	int rand_r (unsigned int =*=nextp)
3	{
4	*nextp = *nextp * 1103515245 + 12345;
5	return (unsigned int) (*nextp / 65536) 7, 32768;
6	>
code/conc/rand-r. c
图12-40 rand_r:图12-37中的rand函数的可重人版本
检查某个函数的代码并先验地断定它是可重人的，这可能吗？不幸的是，不一定能这 样。如果所有的函数参数都是传值传递的（即没有指针），并且所有的数据引用都是本地的 自动栈变量（即没有引用静态或全局变量），那么函数就是显式可重入的（explicitly reentrant)， 也就是说，无论它是被如何调用的， 都可以断言它是可重人的。
然而，如果把假设放宽松一点，允许显式可重人函数中一些参数是引用传递的（即允 许它们传递指针），那么我们就得到了 一个隐式可重入的（implicitly reentrant)函数，也就 是说，如果调用线程小心地传递指向非共享数据的指针，那么它是可重人的。例如，图 12-40中的rand_r函数就是隐式可重人的。
我们总是使用术语可重入的（reentrant)既包括显式可重人函数也包括隐式可重人函 数。然而，认识到可重人性有时既是调用者也是被调用者的属性，并不只是被调用者单独 的属性是非常重要的。
g练习题12. 12 图12-38中的ctiine_tS函数是线程安全的，但不是可重入的。请解释说明。
12.7.3在线程化的程序中使用已存在的库函数
大多数Linux函数，包括定义在标准C库中的函数（例如malloc、free、realloc、 printf和scanf)都是线程安全的，只有一小部分是例外。图12-41列出了常见的例外。 (参考[110]可以得到一个完整的列表。）strtok函数是一个已弃用的（不推荐使用）函数。 asctime、ctime和localtime函数是在不同时间和数据格式间相互来回转换时经常使用 的函数。gethostbyname、gethostbyaddr和inet_ntoa函数是已弃用的网络编程函 数，已经分别被可重人的getaddrinfo、getnameinfo和inet_ntop函数取代（见第11 章）。除了 rand和strtok以外，所有这些线程不安全函数都是第3类的，它们返回一个 指向静态变量的指针。如果我们需要在一个线程化的程序中调用这些函数中的某一个，对 调用者来说最不惹麻烦的方法是加锁-复制。然而，加锁-复制方法有许多缺点。首先，额 外的同步降低了程序的速度。第二，像gethostbyname这样的函数返回指向复杂结构的 结构的指针，要复制整个结构层次，需要深层复制（deep copy)结构。第三，加锁-复制方 法对像rand这样依赖跨越调用的静态状态的第2类函数并不有效。
第】2聿并发编程 7J9
线程不安全函数	线程不安全类	Linux线程安全版本
rand	2	rand_r
strtok	2	strtok_r
asctime	3	asctime_r
ctime	3	ctime_r
gethostbyaddr	3	gethostbyaddr_r
gethostbyname	3	gethostbyname_r
inet_ntoa	3	(无）
localtime	3	localtime_r
图12-41常见的线程不安全的库函数
因此，Linux系统提供大多数线程不安全函数的可重人版本。可重人版本的名字总是 以“_r”后缀结尾。例如，asctime的可重人版本就叫做asctime_r。我们建议尽可能地 使用这些函数。
12. 7. 4 竞争
当一个程序的正确性依赖于一个线程要在另一个线程到达y点之前到达它的控制流中的x点 时，就会发生竞争(mce)。通常发生竞争是因为程序员假定线程将按照某种特殊的轨迹线穿过执行 状态空间，而忘记了另一条准则规定：多线程的程序必须对任何可行的轨迹线都正确工作。
例子是理解竞争本质的最简单的方法。让我们来看看图12-42中的简单程序。主线程创 建了四个对等线程，并传递一个指向一个唯一的整数ID的指针到每个线程。每个对等线程 复制它的参数中传递的ID到一个局部变量中（第22行），然后输出一个包含这个ID的信息。 它看上去足够简单，但是当我们在系统上运行这个程序时，我们得到以下不正确的结果：
linux> ./race Hello from thread 1 Hello from thread 3 • Hello from thread 2 Hello from thread 3
-----------------------------------------code/conc/race. c
1	/* WARNING: This code is buggy! */
2	#include "csapp.h"
3	#define N 4
4
5	void *thread(void *vargp);
6
7	int raainO
8	{
9	pthread_t	tid[N];
10	int i;
11
12	for Ci = 0; i < N; i++)
13	Pthread_create(&tid[i], NULL, thread, &i);
14	for (i =	0;	i	<	N; i++)
15	Pttiread_joiiiCtid[i] , NULL);
16	exit(0);
图12-42	—个具有竞争的程序
720 第三部分程序间的交互和通信
18
19	/* Thread routine */
20	void *thread(void *vargp)
21	{
22	int myid = *((int *)vargp);
23	printf("Hello from thread %d\n", myid);
24	return NULL;
25	>
图 12-42	(续）
code/conc/race.c
问题是由每个对等线程和主线程之间的竞争引起的。你能发现这个竞争吗？下面是发 生的情况。当主线程在第13行创建了一个对等线程，它传递了一个指向本地栈变量z的 指针。在此时，竞争出现在下一次在第12行对〖加1和第22行参数的间接引用和赋值之 间。如果对等线程在主线程执行第12行对i加1之前就执行了第22行，那么myid变量 就得到正确的K)。否则，它包含的就会是其他线程的ID。令人惊慌的是，我们是否得到 正确的答案依赖于内核是如何调度线程的执行的。在我们的系统中它失败了，但是在其他 系统中，它可能就能正确工作，让程序员“幸福地”察觉不到程序的严重错误。	•
为了消除竞争，我们可以动态地为每个整数ID分配一个独立的块，并且传递给线程 例程一个指向这个块的指针，如图12-43所示（第12〜14行）。请注意线程例程必须释放 这些块以避免内存泄漏。
-------------------------------code/conc/norace. c
2
3
4
5
6
19
20
23
24
25
26
28
#include "csapp.h"
#define N 4
void *ttiread(void *vaxgp); int mainO
pthread_t tid[N]; int i, *ptr;
for (i = 0; i < N; i++) ■{
ptr = Malloc(sizeof(int));
*ptr = i;
Pthread_create(fetid[i], NULL, thread, ptr);
>
for (i = 0; i < N; i++)
Pthread_join(tid[i], NULL); exit(0);
>
/* Thread routine */ void *tliread(void *vargp)
int myid = *(Cint *)vargp);
Free(vargp);
printf("Hello from thread %d\n", myid); return NULL;
>
-------------------------------------------—-----code/conc/norace. c
图12-43图12-42中程序的一个没有竞争的正确版本
第12章并发编程 721
当我们在系统上运行这个程序时，现在得到了正确的结果：
linux> ./norace Hello from thread 0 Hello from thread 1 Hello from thread 2 Hello from thread 3
g练习题12. 13在图12-43中，我们可能想要在主线程中的第14行后立即释放已分配 的内存块，而不是在对等线程中释放它。但是这会是个坏注意。为什么？ g练习题12. 14
A.	在图12-43中，我们通过为每个整数ID分配一个独立的块来消除竞争。给出一个 不调用malloc或者free函数的不同的方法。
B.	这种方法的利弊是什么？
12. 7. 5 死锁
信号量引人了一种潜在的令人厌恶的运行时错误，叫做死锁（deadlock),它指的是一 组线程被阻塞了，等待一个永远也不会为真的条件。进度图对于理解死锁是一个无价的工 具。例如，图12-44展示了一对用两个信号量来实现互斥的线程的进程图。从这幅图中， 我们能够得到一些关于死锁的重要知识：
*程序员使用P和V操作顺序不当，以至于两个信号量的禁止区域重叠。如果某个执 行轨迹线碰巧到达了死锁状态那么就不可能有进一步的进展了，因为重叠的禁 止区域阻塞了每个合法方向上的进展。换句话说，程序死锁是因为每个线程都在等 待其他线程执行一个根不可能发生的V操作。
•重叠的禁止区域引起了一组称为死锁区域（deadlock region)的状态。如果一个轨迹 线碰巧到达了一个死锁区域中的状态，那么死锁就是不可避免的了。轨迹线可以进 人死锁区域，但是它们不可能离开。
722	第三部分程序间的交互和通信
•死锁是一个相当困难的问题，因为它不总是可预测的。一些幸运的执行轨迹线将绕开死 锁区域，而其他的将会陷入这个区域。图12-44展示了每种情况的一个示例。对于程序 员来说，这其中隐含的着实令人惊慌。你可以运行一个程序1000次不出任何问题，但是 下一次它就死锁了。或者程序在一台机器上可能运行得很好，但是在另外的机器上就会 死锁。最糟糕的是，错误常常是不可重复的，因为不同的执行有不同的轨迹线。
程序死锁有很多原因，要避免死锁一般而言是很困难的。然而，当使用二元信号量来 实现互斥时，如图12-44所示，你可以应用下面的简单而有效的规则来避免死锁：
互斥锁加锁顺序规则：给定所有互斥操作的一个全序，如果每个线程都是以一种顺序 获得互斥锁并以相反的顺序释放，那么这个程序就是无死锁的。
例如，我们可以通过这样的方法来解决图12-44中的死锁问题：在每个线程中先对s 加锁，然后再对z加锁。图12-45展示了得到的进度图。
线程2
V{s)
V{t)
Pit)
初始
s=l
t=l
P(s)
J的禁止区		
	f的禁止区	
		
• • • P(s) ... P(t) ... V(s) ... V{t) 1?1 12-45	—个无死锁程序的进度图
线程1
K练习题12. 15 初始时：s = 1
思考下面的程序， t = 0.
它试图使用一对信号量来实现互斥。
线程1: P(s) V(s) P(t) V(t)
线程2: PCs) V(s) P(t) V(t)
A.	画出这个程序的进度图。
B.	它总是会死锁吗？
C.	如果是，那么对初始信号量的值做哪些简单的改变就能消除这种潜在的死锁呢？
D.	画出得到的无死锁程序的进度图。
12.8 小结
一个并发程序是由在时间上重叠的一组逻辑流组成的。在这一章中，我们学习了三种不同的构建并 发程序的机制：进程、】/〇多路复用和线程。我们以一个并发网络服务器作为贯穿全章的应用程序。
第12章并发编程 m
进程是由内核自动调度的，而且因为它们有各自独立的虚拟地址空间，所以要实现共享数据，必须 要有显式的IPC机制。事件驱动程序创建它们自己的并发逻辑流，这些逻辑流被模型化为状态机，用 I/O多路复用来显式地调度这些流。因为程序运行在一个单一进程中，所以在流之间共享数据速度很快而 且很容易。线程是这些方法的混合。同基于进程的流一样，线程也是由内核自动调度的。同基于I/O多 路复用的流一样，线程是运行在一个单一进程的上下文中的，因此可以快速而方便地共享数据。
无论哪种并发机制，同步对共享数据的并发访问都是一个困难的问题。提出对信号量的P和V操作 就是为了帮助解决这个问题。信号量操作可以用来提供对共享数据的互斥访问，也对诸如生产者-消费者 程序中有限缓冲区和读者-写者系统中的共享对象这样的资源访问进行调度。一个并发预线程化的echo 服务器提洪了信号量使用场景的很好的例子。
并发也引人了其他一些困难的问题。被线程调用的函数必须具有一种称为线程安全的属性。我们定 义了四类线程不安全的函数，以及一些将它们变为线程安全的建议。可重人函数是线程安全函数的一个 真子集，它不访问任何共享数据。可重人函数通常比不可重入函数更为有效，因为它们不需要任何同步 原语。竞争和死锁是并发程序中出现的另一些困难的问题。当程序员错误地假设逻辑流该如何调度时， 就会发生竞争。当一个流等待一个永远不会发生的事件时，就会产生死锁。
参考文献说明
信号量操作是Dijkstra提出的[31]。进度图的概念是Coffman[23]提出的，后来由Carson和Reyn-olds[16]形式化的。Counois等人[25]提出了读者_写者问题。操作系统教科书更详细地描述了经典的同 步问题，例如哲学家进餐问题、打瞌睡的理发师问题和吸烟者问题[102，106，113]。Butenhof的书 [15]对Posix线程接口有全面的描述。Binrell [7]的论文对线程编程以及线程编程中容易遇到的问题做了 很好的介绍。Reinders的书[90]描述了 C/C++库，简化了线程化程序的设计和实现。有一些课本讲述了 多核系统上并行编程的基础知识[47, 71]。Pugh描述了 Java线程通过内存进行交互的方式的缺陷，并 提出了替代的内存模型[88]。Gustafson提出了替代强扩展的弱扩展加速模型[43]。
家庭作业
• 12. 16
‘ 12. 17
编写hello.c(图12-13)的一个版本，它创建和回收《个可结合的对等线程，其中《是一个命令 行参数。
A.图12-46中的程序有一个bug。要求线程睡眠一秒钟，然后输出一个字符串。然而，当在我们 的系统上运行它时，却没有任何输出。为什么？
------------------------------code/conc/hellobug.c
3
5
/* WARNING: This code is buggy! */
#include "csapp.h"
void 傘threaLd(void 本vaxgp);
int rnainC)
pthread_t tid;
Pthread_create(&tid, NULL, thread, NULL); exit(O);
/* Thread routine */ void *thread(void *vargp)
Sleep ⑴；
printf("Hello, world!\n"); return NULL;
----------------------------------code/conc/hellobug.c
图12-46 练习题12. 17的有bug的程序
724 第三部分程序间的交互和通信
.12. 18 ** 12. 19
** 12. 20
** 12. 21 ^ 12. 22
•*12.23
.12. 24 * 12.25
** 12. 26
-12.27
* 12. 28
B.你可以通过用两个不同的Pthreads函数调用中的一个替代第10行中的exit函数来改正这个 错误。选哪一个呢？
用图12-21中的进度图，将下面的轨迹线分类为安全或者不安全的。
A.	，只1，Li，S2，Ui，Si，了1，7^
B. biz » -f^l »	' Si » 1-2 J Ti , U2 t S2 J 7~2
C. Hi, L.\ t H2» L，2 f Uz 1 S2» C/j » Si » Ti » T2
图12-26中第一类读者-写者问题的解答给予读者的是有些弱的优先级，因为读者在离开它的临 界区时，可能会重启一个正在等待的写者，而不是一个正在等待的读者。推导出一个解答，它给 予读者更强的优先级，. 当写者离开它的临界K的时候，如果有读者正在等待的话，就总是重启一 个正在等待的读者。
考虑读者-写者问题的一个更简单的变种，即最多只有N个读者。推导出一个解答，给予读者和 写者同等的优先级，即等待中的读者和写者被赋予对资源访问的同等的机会。提示：你可以用一 个计数信号量和一个互斥锁来解决这个问题。
推导出第二类读者-写者问题的一个解答，在此写者的优先级高于读者。
检查一下你对select函数的理解，请修改图12-6中的服务器，使得它在主服务器的每次迭代中 最多只回送一个文本行。
图12-8中的事件驱动并发echo服务器是有缺陷的，因为一个恶意的客户端能够通过发送部分的 文本行，使服务器拒绝为其他客户端服务。编写一个改进的服务器版本，使之能够非阻塞地处理 这些部分文本行。
RI0 I/O包中的函数（10. 5节）都是线程安全的。它们也都是可重人函数吗？
在图12-28中的预线程化的并发echo服务器中，每个线程都调用ech〇_Cnt函数（图12-29)。 ech〇_cnt是线程安全的吗？它是可重人的吗？为什么是或为什么不是呢？
用加锁-复制技术来实现gethostbyname的—线程安全而又不可重人的版本，称为gethost -byname_tsD —个正确的解答是使用由互斥锁保护的hostent结构的深层副本^
一些网络编程的教科书建议用以下的方法来读和写套接字：和客户端交互之前，在同一个打开的 已连接套接字描述符上，打开两个标准I/O流，一个用来读，一个用来写：
FILE *fpin, *fpout;
fpin = fdopen(sockfd, "r"); fpout * fdopen(sockfd, "w");
当服务器完成和客户端的交互之后，像下面这样关闭两个流：
fclose(fpin); fclose(fpout);
然而，如果你试图在基于线程的并发服务器上尝试这种方式，将制造一个致命的竞争条件。 请解释。
在图12-45中，将两个V操作的顺序交换，对程序死锁是否有影响？通过画出四种可能情况的进 度图来证明你的答案：
情况1		情况2		情况3		情况4	
线程1	线程2	线程1	线程2	线程1	线程2	线程1	线程2
PCs)	PCs)	PCs)	P(s)	P(s)	PCs)	PCs)	PCs)
P(t)	P(t)	PCt)	PCt)	PCt)	P(t)	PCt)	P(t)
V(s)	V(s)	V(s)	V(t)	V(t)	V(s)	VCt)	V(t)
V(t)	VCt)	V(t)	V(s)	V(s)	V(t)	VCs)	V(s)
• 12. 29
下面的程序会死锁吗？为什么会或者为什么不会？
第12章并发编程 725
初始时：a=l，b = l, c = l
* 12. 30
线程1	线程2	
P(a)	P(c)	
P(b)	PCb)	
V(b)	V(b)	
PCc)	V(c)	
V(c)		
V(a)		
考虑下面这个会死锁的程序。		
初始时：a=l, b=l，c=l		
线程1	线程2	线程3
P(a)	P(c)	PCc)
P(b)	P(b)	V(c)
V(b)	VCb)	P(b)
P(c)	V(c)	P(a)
V(c)	P(a)	V(a)
V(a)	V(a)	V(b)
V 12. 31
A.	列出每个线程同时占用的一对互斥锁。
B.	如果a<6<c，那么哪个线程违背了互斥锁加锁顺序规则？
C.	对于这些线程，指出一个新的保证不会发生死锁的加锁顺序。
实现标准I/O函数fgets的一个版本，叫做tfgets,假如它在5秒之内没有从标准输人上接收到 一个输人行，那么就超时，并返回一个NUI丄指针。你的函数应该实现在一个叫做tfgets-proc.c 的包中，使用进程、信号和非本地跳转。它不应该使用Linux的alarm函数。使用图12-47中的驱 动程序测试你的结果。
---------------------------------------------------------code/conc/tfgets-main. c
1	#include "csapp.h"
2
3	char *tfgets(char *s, int size, FILE *stream);
4
5	int main〇
6	{
7	char buf[MAXLINE];
8
9	if CtfgetsCbuf,	MAXLINE, stdin) == NULL)
10	printf (，_B0〇M!\n”）；
11	else
12	printf("%s", buf);
13
14	exit(O);
15	>
---------------------------------------------------------code/conc/tfgets-mainx
图12-47 家庭作业题12. 31〜12. 33的驱动程序
12. 32使用select函数来实现练习题12. 31中tfgets函数的一个版本。你的函数应该在一个叫做tf-@亡3-祀16以义的包中实现。用练习题12.31中的驱动程序测试你的结果。你可以假定标准输人 被赋值为描述符0。
712.33 实现练习题12.31中tfgets函数的一个线程化的版本。你的函数应该在一个叫做tfgets-thread.c的包中实现。用练习题12. 31中的驱动程序测试你的结果。
**12.34编写一个NXM矩阵乘法核心函数的并行线程化版本。比较它的性能与顺序的版本的性能。
**12. 35实现一个基于进程的TINY Web服务器的并发版本。你的解答应该为每一个新的连接请求创建一 个新的子进程。使用一个实际的Web浏览器来测试你的解答。
*： 12.36实现一个基于I/O多路复用的TINY Web服务器的并发版本。使用一个实际的Web浏览器来测 试你的解答。
726 第三部分程序间的交互和通信
Y 12. 37实现一个基于线程的TINY Web服务器的并发版本。你的解答应该为每一个新的连接请求创建一 个新的线程。使用一个实际的Web浏览器来测试你的解答。
12.38实现一个TINY Web服务器的并发预线程化的版本你的解答应该根据当前的负载，动态地增加 或减少线程的数目。一个策略是当缓冲区变满时，将线程数量翻倍，而当缓冲区变为空时，将线 程数目减半使用一个实际的Web浏览器来测试你的解答。
= 12.39 Web代理是一个在Web服务器和浏览器之间扮演中间角色的程序。浏览器不是直接连接服务器 以获取网页，而是与代理连接，代理再将请求转发给服务器。当服务器响应代理时，代理将响应 发送给浏览器。为了这个试验，请你编写一个简单的可以过滤和记录请眾的Web代理：
A.	试验的第一部分中，你要建立以接收请求的代理，分析HTTP，转发请求给服务器，并且返 回结果给浏览器。你的代理将所有请求的URL记录在磁盘上一个日志文件中，同时它还要阻 塞所有对包含在磁盘上一个过滤文件中的URL的请求。
B.	试验的第二部分中，你要升级代理，它通过派生一个独立的线程来处理每一个请求，使得代 理能够一次处理多个打开的连接。当你的代理在等待远程服务器响应一个请求使它能服务于 一个浏览器时，它应该可以处理来自另一个浏览器未完成的请求。
使用一个实际的Web浏览器来检验你的解答。
练习题答案
12.1当父进程派生子进程时，它得到一个已连接描述符的副本，并将相关文件表中的引用计数从1增 加到2。当父进程关闭它的描述符副本时，引用计数就从2减少到U因为内核不会关闭一个文 件，直到文件表中它的引用计数值变为零，所以子进程这边的连接端将保持打开。
12.2当一个进程因为某种原因终止时，内核将关闭所有打开的描述符。因此，当子进程退出时，它的 已连接文件描述符的副本也将被自动关闭。
12.3回想一下，如果一个从描述符中读一个字节的请求不会阻塞，那么这个描述符就准备好可以读了。 假如EOF在一个描述符上为真，那么描述符也准备好可读了，因为读操作将立即返回一个零返回 码，表示EOF。因此，键人Ctri+D会导致select函数返囡，准备好的集合中有描述符0。
12.4因为变量pool.read_Set既作为输人参数也作为输出参数，所以我们在每一次调用select之前 都重新初始化它。在输人时，它包含读集合。在输出，它包含准备好的集合。
12.5因为线程运行在同一个进程中，它们都共享相同的描述符表。无论有多少线程使用这个已连接描 述符，这个已连接描述符的文件表的引用计数都等于1。因此，当我们用完它时，一个close操 作就足以释放与这个已连接描述符相关的内存资源了。
12.6这里的主要的思想是，栈变量是私有的，而全局和静态变量是共享的。诸如cnt这样的静态变量 有点小麻烦，因为共享是限制在它们的函数范围内的一一在这个例子中，就是线程例程。
A.下面就是这张表：
变量实例	被主线程引用？	被对等线程0引用？	被对等线程1引用？
ptr	是	是	是
cnt	否	是	是
i .m	是	否	否
msgs.m	是	是	是
myid.pO	否	是	否
myid.pl	否	否	是
说明：
*Ptr:—个被主线程写和被对等线程读的全局变量。
*	cnt:—个静态变量，在内存中只有一个实例，被两个对等线程读和写。
*	i.m: —个存储在主线程栈中的本地自动变量。虽然它的值被传递给对等线程，但是对等线 程也绝不会在栈中引用它，因此它不是共享的。
第12章并发编程 727
^msgs.rii:—个存储在主线程栈中的本地自动变量，被两个对等线程通过ptr间接地引用. »myid.O和myid.l: —个本地自动变量的实例，分别驻留在对等线程〇和线程1的栈中。 B.变量ptr、cnt和msgs被多亍一个线程引用，因此它们是共享的。
12.7这里的重要思想是，你不能假设当内核调度你的线程时会如何选择顺序。
步骤	线程	指令			cnt
1	1			—	0
2	1	乙i	0	—	0
3	2	"2	—	—	0
4	2	乙2	—	0	0
5	2	"2	—	1	0
6	2	S2	—	1	1
7	1	"1	1	—	1
8	1		1	—	1
9	1	Tl	1	—	1
10	2	t2	—	1	1
变量cnt最终有一个不正确的值1。
12.8这道题简单地测试你对进度图中安全和不安全轨迹线的理解^像八和C这样的轨迹线绕开了临界 区，是安全的，会产生正确的结果。
A.	仏，[；!，S" L2, U2, S2，T” 丁,：安全的
B.	认，Lu U,, T,，U2, S2，了2:不安全的
C.	，H2, M，U2, S2, M，Si，乃，丁2:安全的
12.9 A. p = l, c=l，《>1:是，互斥锁是需要的，因为生产者和消费者会并发地访问缓冲区。
B.	夕=1, c=l，n = l:不是，在这种情况中不需要互斥锁信号量，因为一个非空的缓冲K就等于 满的缓冲区。当缓冲区包含一个项目时，生产者就被阻塞了。当缓冲区为空时，消费者就被阻 塞了。所以在任意时刻，只有一个线程可以访问缓冲区，因此不用互斥锁也能保证互斥。
C.	/>>1，C>1，72=1:不是，在这种情况中，也不需要互斥锁，原因与前面一种情况相同。
12. 10假设一个特殊的信号量实现为每一个信号量使用了一个UFO的线程栈。当一个线程在P操作中 .	阻塞在一个信号量上，它的ID就被压入栈中。类似地，V操作从栈中弹出栈顶的线程ID，并重
启这个线程。根据这个栈的实现，一个在它的临界区中的竞争的写者会简单地等待，直到在它释 放这个信号量之前另一个写者阻塞在这个信号量上。在这种场景中，当两个写者来回地传递控制 权时，正在等待的读者可能会永远地等待下去。
注意，虽然用FIFO队列而不是用LIFO更符合直觉，但是使用LIFO的栈也是对的，而且也没 有违反P和V操作的语义。
12. 11这道题简单地检查你对加速比和并行效率的理解：
线程⑴	1	2	4
核(>)	1	2	4
运行时间（7；)	12	8	6
加速比（5p	I	1.5	2
效率（£p)	100%	75%	50%
12.12 ctime_ts函数不是可重人函数，因为每次调用都共享相同的由gethostbyname函数返回的static变 量。然而，它是线程安全的，因为对共享变量的访问是被P和V•操作保护的，因此是互斥的。
12. 13如果在第14行调用了 pthread_Create之后，我们立即释放块，那么将引入一个新的竞争，这 次竞争发生在主线程对free的调用和线程例程中第24行的赋值语句之间。
12. 14 A.另一种方法是直接传递整数i,而不是传递一个指向i的指针： for (i * 0; i < N; i++)
Pthread_cr©ate(fetid[i], NULL, thread, (void *)i);
728	第三部分程序间的交互和通信
在线程例程中，我们将参数强制转换成一个int类型，并将它赋值给myid: int myid = (int) vargp;
B，优点是它通过消除对malloc和free的调用降低了开销。一个明显的缺点是，它假设指针至 少和int—样大。即便这种假设对于所有的现代系统来说都为真，但是它对于那些过去遗留 下来的或今后的系统来说可能就不为真了。
12. 15 A.原始的程序的进度图如图12-48所示.
线程2
图12-48 —个有死锁的程序的进度图
B.	因为任何可行的轨迹最终都陷人死锁状态中，所以这个程序总是会死锁。
C.	为了消除潜在的死锁，将二元信号量t初始化为1而不是0。
D.	改成后的程序的进度图如图12-49所示^
线程2
Pit)
V{s)
浦禁止区
P(s)
初始 5=1 ? = 1
----------*-*----*--—线程 1
…P(s)……P(t)…V(t)
图12-49改正后的无死锁的程序的进度图
附录A
错误处理
程序员应该总是检查系统级函数返回的错误代码。有许多细微的方式会导致出现错 误，只有使用内核能够提供给我们的状态信息才能理解为什么有这样的错误。不幸的是， 程序员往往不愿意进行错误检查，因为这使他们的代码变得很庞大，将一行代码变成一个 多行的条件语句。错误检查也是很令人迷惑的，因为不同的函数以不同的方式表示错误。
在编写本书时，我们面临类似的问题。一方面，我们希望代码示例阅读起来简洁简 单；另一方面，我们又不希望给学生们一个错误的印象，以为可以省略错误检查。为了解 决这些问题，我们采用了一种基于错误处理包装函数（error-handling wrapper)的方法，这 是由W. Richard Stevens在他的网络编程教材[110]中最先提出的。
其思想是，给定某个基本的系统级函数f〇〇,我们定义一个有相同参数、只不过开头 字母大写了的包装函数F〇〇。包装函数调用基本函数并检查错误。如果包装函数发现了错 误，那么它就打印一条信息并终止进程。否则，它返回到调用者。注意，如果没有错误， 包装函数的行为与基本函数完全一样。换句话说，如果程序使用包装函数运行正确，那么 我们把每个包装函数的第一个字母小写并重新编译，也能正确运行。
包装函数被封装在一个源文件（csapp.c)中，这个文件被编译和链接到每个程序中。 一个独立的头文件（csapp.h)中包含这些包装函数的函数原型。
本附录给出了一个关于Unix系统中不同种类的错误处理的教程，还给出了不同风格 的错误处理包装函数的示例。csapp.h和csapp.c文件可以从CS: APP网站上获得。
.A. 1 Unix系统中的错误处理
本书中我们遇到的系统级函数调用使用三种不同风格的返回错误：Unix风格的、 Posix风格的和GAI风格的。
1.	Unix风格的错误处理
像fork和wait这样Unix早期开发出来的函数（以及一些较老的Posix函数）的函数 返回值既包括错误代码，也包括有用的结果。例如，当Unix风格的wait函数遇到一个 错误（例如没有子进程要回收），它就返回一 1，并将全局变量errno设置为指明错误原因 的错误代码。如果wait成功完成，那么它就返回有用的结果，也就是回收的子进程的 PID。Unix风格的错误处理代码通常具有以下形式：
1	if (Cpid = wait (NULL)) < 0) ■(
2	fprintf (stderr, ''wait error: %s\n" , strerror(errno));
3	exit(0);
4	>
strerror函数返回某个errno值的文本描述。
2.	Posix风格的错误处理
许多较新的Posix函数，例如Pthread函数，只用返回值来表明成功（0)或者失败（非 0)。任何有用的结果都返回在通过引用传递进来的函数参数中。我们称这种方法为Posix
730 附录A 错误处理
风格的错误处理。例如，Posix风格的pthread_create函数用它的返回值来表明成功或 者失败，而通过引用将新创建的线程的ID(有用的结果）返回放在它的第一个参数中。P〇s-ix风格的错误处理代码通常具有以下形式：
1	if ((retcode = pthread_create(fetid, NULL, thread, NULL)) != 0) {
2	fprintf(stderr, "pthread_create error: %s\n", strerror(retcode));
3	exitCO);
4	>
strerror函数返回retcode某个值对应的文本描述。
3.GAI风格的错误处理
getaddrinfo(GAI)和getnameinfo函数成功时返回零，失败时返回非零值。GAI 错误处理代码通常具有以下形式：
1	if ((retcode = getaddrinfo(host，service, fehints, ^result)) != 0) {
2	fprintf(stderr, "getaddrinfo error: %s\n", gai.strerror(retcode));
3	exit(0);
gai_strerror函数返回retcode某个值对应的文本描述。
4.错误报告函数小结
贯穿本书，我们使用下列错误报告函数来包容不同的错误处理风格:
#include "csapp.h"	
void unix_error(chax *msg); void posix_error(int code, char *msg); void gai_error(int code, char *msg); void app_error(char *msg);	返回：无。
正如它们的名字表明的那样，unix_erro;r、posix_error和gai_error函数报告 Unix风格的错误、Posix风格的错误和GAI风格的错误，然后终止。包括app_error函 数是为了方便报告应用错误。它只是简单地打印它的输人，然后终止。图A-1展示了这些 错误报告函数的代码。
-------------------------------------------------code/src/csapp. c
1	void unix_error(char *msg) /* Unix-style error */
2	{
3	fprintf(stderr, "%s: %s\n", msg, strerror(errno));
4	exit(0);
5	>
6
7	void posix_error(int code, char 本msg) /* Posix-style error */
8	{
9	fprintf(stderr,	”％s: %s\n"， msg, strerror(code));
i〇	exit(0);
11 >
12
13	void gai_error(int code, char 本msg) /* Getaddrinfo-style error */
图A-l错误报告函数
附录A 错误处理 731
14	{
15	fprintf (stderr,	"%s:	°/〇s\n",	msg, gai_strerror(code));
16	exit(O);
17	>
18
19	void app_error(char *msg) /* Application error */
2〇 i
21	fprintf(stderr,	“^sVa"，	msg);
22	exit(O);
23	>
code/src/csapp. c
图A-l (续）
A. 2错误处理包装函数
下面是一些不同错误处理包装函数的示例：
• Unix风格的错误处理包装函数。图A-2展示了 Unix风格的wait函数的包装函数。 如果wait返回一个错误，包装函数打印一条消息，然后退出。否则，它向调用者 返回一个PID。图A-3展示了 Unix风格的kill函数的包装函数。注意，这个函数 和wait不同，成功时返回void。
1	pid_t Wait(int ^status)
2	{
3	pid_t pid;
4
5	if C(pid =	wait(status)) < 0)
6	unix_error("Wait error");
7	return pid;
8	>
code/src/csapp. c
code/src/csapp. c
图A-2 Unix风格的wait函数的包装函数
1	void Kill(pid_t pid, int	signum)
2		
3	int rc;	
4		
5	if C(rc = kill(pid, £	signurn)) < 0)
6 7	ujiix_error ("Kill >	error");
code/src/csapp. c
code/src/csapp. c
图A-3 Unix风格的kill函数的包装函数
• Posix风格的错误处理包装函数。图A-4展示了 Posix风格的pthread_detach函 数的包装函数。同大多数Posix风格的函数一样，它的错误返回码中不会包含有用 的结果，所以成功时，包装函数返回void。
732 附录A 错误处理
--------------------------------------------------------------code/src/csapp. c
1	void Pthread_detach(pthread_t tid) {
2	int rc;
B
4	if ((rc = pthread_detach(tid)) != 0)
5	posix_errorCrc, "Pthread_detach error");
6	>
--------------------------------------------------------------code/src/csapp. c
图A-4 Posix风格的pthread_detach函数的包装函数
• GAI风格的错误处理包装函数。图A-5展了 GAI风格的getaddrinfo函数的包 装函数。
---------------------------------------------------------------code/src/csapp. c
1	void Getaddrinfo(const char *node, const char ^service,
2	const struct addrinfo *hints, struct addrinfo **res)
3	{
4	int rc;
5
6	if ((rc = getaddrinfo(node, service, hints, res)) != 0)
7	gai_error(rc, "Getaddrinfo error");
8	>
---------------------------------------------------------------code/src/csapp. c
图A-5 GAI风格的getaddrinfo函数的包装函数
参考文献
[1]	Advanced Micro Devices, Inc. Software Optimization Guide for AMD64 Processors, 2005. Publication Number 25112.
[2]	Advanced Micro Devices, Inc. AMD64 Architecture Programmer's Manual, Volume 1: Application Programming, 2013. Publication Number 24592.
[3]	Advanced Micro Devices, Inc. AMD64 Architecture Programmer's Manual, Volume 3: General-Purpose and System Instructions, 2013. Publication Number 24594.
[4]	Advanced Micro Devices, Inc. AMD64 Architecture Programmer's Manual, Volume
4:128-Bit and 256-Bit Media Instructions, 2013. Publication Number 26568.
[5]	K. Arnold, J. Gosling, and D. Holmes. The Java Programming Language, Fourth Edition. Prentice Hall, 2005.
[6]	T. Berners-Lee, R. Fielding, and H. Frystyk. Hypertext transfer protocol - HTTP/1.0. RFC 1945,1996.
[7]	A. Birrell. An introduction to programming with threads. Technical Report 35, Digital Systems Research Center, 1989.
[8]	A. Birrell, M. Isard, C. Thacker, and T. Wobber. A design for high-performance flash disks. SIGOPS Operating Systems Review 41(2):88-93,2007.
[9]	G. E. Blelloch, J. T. Fineman, P. B. Gibbons, and H. V. Simhadri. Scheduling irregular parallel computations on hierarchical caches. In Proceedings of the 23rd Symposium on Parallelism in Algorithms and Architectures (SPAA)y pages 355-366. ACM, June 2011.
[10]	S. Borkar. Thousand core chips: A technology perspective. In Proceedings of the 44th Design Automation Conference, pages 746-749. ACM, 2007.
[11]	D. Bovet and M. Cesati. Understanding the Linux Kernel, Third Edition. O'Reilly Media, Inc., 2005.
[12]	A. Demke Brown and X Mowry. Taming the memory hogs: Using compiler-inserted releases to manage physical memory intelligently. In
Proceedings of the 4th Symposium on Operating Systems Design and Implementation (OSDI) pages 31^4. Usenix, October 2000.
[13]	R. E. Bryant. Term-level verification of a pipelined CISC microprocessor. Technical Report CMU-CS-05-195, Carnegie Mellon University, School of Computer Science, 2005.
[14]	R. E. Bryant and D. R. O’Hallaron. Introducing computer systems from a programmer’s perspective. In Proceedings of the Technical Symposium on Computer Science Education (SIGCSE), pages 90-94. ACM, February 2001.
[15]	D. Butenhof. Programming with Posix Threads Addison-Wesley, 1997.
[16]	S. Carson and P. Reynolds. The geometry of semaphore programs. ACM Transactions on 尸rogrammkg Langwfl尽ei1 and S少siem59(l):25-
53,1987.
[17]	J. B. Carter, W. C. Hsieh, L. B. Stoller, M. R. Swanson, L. Zhang, E. L. Brunvand, A. Davis,
C.-C. Kuo, R. Kuramkote, M. A. Parker,
L.	Schaelicke, and T. Tateyama. Impulse: Building a smarter memory controller. In Proceedings of the 5th International Symposium-on High Performance Computer Architecture (HPCA), pages 70-79. ACM, January 1999.
[18]	K. Chang, D. Lee, Z. Chishti, A. Alameldeen,
C.	Wilkerson, Y. Kim, and O. Mutlu. Improving DRAM performance by parallelizing refreshes with accesses. In Proceedings of the 20th International Symposium on High-Performance Computer Architecture (HPCA). ACM, February 2014.
[19]	S. Chellappa, F. Franchetti, and M. Piischel. How to write fast numerical code: A small introduction. In Generative and Transformational Techniques in Software Engineering II, volume 5235 of Lecture Notes in Computer Science, pages 196-259. Springer-Verlag, 2008.
[20]	P, Chen, E. Lee, G. Gibson, R. Katz, and
D.	Patterson. RAID: High-performance, reliable secondary storage. ACM Computing Surveys 26(2):145-185, June 1994.
t21] S. Chen, P. Gibbons, and T. Mowry. Improving index performance through prefetching. In
734 参考文献
Proceedings of the 2001 ACM S1GMOD International Conference on Management of Data, pages 235-246. ACM, May 2001.
[22]	T. Chilimbi, M. Hill, and J. Larus. Cacheconscious structure layout. In Proceedings of the 1999 ACM Conference on Programming Language Design and Implementation (PLDI). pages 1-12. ACM, May 1999.
[23]	E. Coffman, M. Elphick, and A. Shoshani. System deadlocks. ACM Computing Surveys 3(2):67-78, June 1971.
[24]	D. Cohen. On holy wars and a plea for peace.
IEEE Computer 14(10):48-54, October 1981.
[25]	P. J. Courtois, F. Heymans, and D. L. Pamas. Concurrent control with “readers” and uwriters.,> Communications of the ACM 14(10):667-668,1971.
[26]	C. Cowan, P. Wagle, C. Pu, S. Beattie, and J. Walpole. Buffer overflows: Attacks and defenses for the vulnerability of the decade. In DARPA Information Survivability Conference and Expo (DISCEX), volume 2, pages 119-129, March 2000.
[27]	J. H. Crawford. The i486 CPU: Executing instructions in one clock cycle. IEEE Micro 10(1):27-36, February 1990.
[28]	V. Cuppu, B. Jacob, B. Davis, and T. Mudge.
A performance comparison of contemporary DRAM architectures. In Proceedings of the 26th International Symposium on Computer Architecture (ISCA), pages 222-233, ACM, 1999.
[29]	B. Davis, B. Jacob, and T. Mudge. The new DRAM interfaces: SDRAM, RDRAM, and variants. In Proceedings of the 3rd International Symposium on High Performance Computing (ISHPC), volume 1940 of Lecture Notes in Computer Science, pages 26-31. Springer-Verlag, October 2000.
[30]	E. Demaine. Cache-oblivious algorithms and data structures. In Lecture Notes from the EEF Summer School on Massive Data Sets. BRICS, University of Aarhus, Denmark, 2002.
[31]	E. W. Dijkstra. Cooperating sequential processes. Technical Report EWD-123, Technological University, Eindhoven, the Netherlands, 1965.
[32]	C. Ding and K. Kennedy. Improving cache performance of dynamic applications through data and computation reorganizations at run time. In Proceedings of the 1999 ACM Conference on Programming Language Design and Implementation (PLDI), pages 229-241.
ACM, May 1999.
[33]	M. Dowson. The Ariane 5 software failure.
SIGSOFTSoftware Engineering Notes 22(2):84,
1997.
[34]	U. Drepper. User-level IPv6 programming introduction. Available at http://www.akkadia .org/drepper/userapi-ipv6.html, 2008.
[35]	M. W. Eichen and J. A. Rochlis. With microscope and tweezers: An analysis of the Internet virus of November, 1988. In Proceedings of the IEEE Symposium on Research in Security and Privacy, pages 326-343. IEEE, 1989.
[36]	ELF-64 Object File Format, Version 1.5 Draft 2,
1998.	Available at http://www.uclibc.org/docs/ elf-64-gen.pdf.
[37]	R. Fielding, J. Gettys, J. Mogul, H. Frystyk,
L. Masinter, P. Leach, and T. Berners-Lee. Hypertext transfer protocol - HTTP/1.1. RFC 2616,1999.
[38]	M. Frigo, C. E. Leiserson, H. Prokop, and
S. Ramachandran. Cache-oblivious algorithms. In Proceedings of the 40th IEEE Symposium on Foundations of Computer Science (FOCS), pages 285-297. IEEE, August 1999.
[39]	M. Frigo and V. Strumpen. The cache complexity of multithreaded cache oblivious algorithms. In Proceedings of the 18th Symposium on Parallelism in Algorithms and Architectures (SPAA), pages 271-280. ACM, 2006.
[40]	G. Gibson, D. Nagle, K. Amiri, J. Butler,
F. Chang, H. Gobioff, C. Hardin, E. Riedel,
D.	Rochberg, and J. Zelenka. A cost-effective, high-bandwidth storage architecture. In Proceedings of the 8th International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS), pages 92-103. ACM, October 1998.
[41]	G. Gibson and R. Van Meter. Network attached storage architecture. Communications of the ACM 43(11):37-45, November 2000.
[42]	Google. IPv6 Adoption. Available at http:// www.google.com/intI/en/ipv6/statistics.html.
[43]	J. Gustafson. Reevaluating Amdahl’s law. Communications of the ACM 31(5):532-533, August 1988.
[44]	L. Gwennap. New algorithm improves branch prediction. Microprocessor Report 9(4), March 1995.
[45]	S. P. Harbison and G. L. Steele, Jr. C, A Reference Manual, Fifth Edition. Prentice Hall, 2002.
[46]	J. L. Hennessy and D. A. Patterson. Computer
参考文献 735
Architecture: A Quantitative Approach, Fifth Edition. Morgan Kaufmann, 2011.
[47]	M. Herlihy and N. Shavit. The Art of Multiprocessor Programming. Morgan Kaufmann, 2008.
[48]	C. A. R. Hoare. Monitors: An operating system structuring concept. Communications of the ACM 17(10):549-557, October 1974.
[49]	Intel Corporation. Intel 64 and IA-32 Architectures Optimization Reference Manual. Available at http://www.intel.com/content/ www/us/en/processors/architectures-software-developer-manuals.html.
[50]	Intel Corporation. Intel 64 and IA-32 Architectures Software Developer's Manual, Volume 1: Basic Architecture. Available at http://www.intel.com/content/www/us/en/ processors/architectures-software-developer-manuals.html.
[51]	Intel Corporation. Intel 64 and IA-32 Architectures Software Developer's Manual, Volume 2: Instruction Set Reference. Available at http://www.intel.com/content/www/us/en/ processors/architectures-software-developer-manuals.html.
[52]	Intel Corporation. Intel 64 and IA-32 Architectures Software Developer's Manual, Volume 3a: System Programming Guide, Part 1. Available at http://www.intel.com/content/www/us/en/ processors/architectures-software-developer-manuals.html.
[53]	Intel Corporation. Intel Solid-State Drive 730
. Series: Product Specification. Available at
http://www.intel.com/content/www/us/en/solid-
state-drives/ssd-730-series-spec.html.
[54]	Intel Corporation. Tool Interface Standards Portable Formats Specification, Version 1.1, 1993. Order number 241597.
[55]	F. Jones, B. Prince, R. Norwood, J. Hartigan, W. Vogley, C. Hart, and D. Bondurant. Memory_a new era of fast dynamic RAMs (for video applications). IEEE Spectrum, pages 43^5, October 1992.
[56]	R. Jones and R. Lins. Garbage Collection: Algorithms for Automatic Dynamic Memory Management. Wiley, 1996.
[57]	M. Kaashoek, D. Engler, G. Ganger, H. Briceo, R. Hunt, D. Maziers, T. Pinckney, R. Grimm,
J. Jannotti, and K. MacKenzie. Application performance and flexibility on Exokernel systems. In Proceedings of the 16th ACM Symposium on Operating System Principles (SOSP), pages 52-65. ACM, October 1997.
[58]	R. Katz and G. Borriello. Contemporary Logic Design, Second Edition. Prentice Hall, 2005.
[59]	B. W. Kernighan and R. Pike. The Practice of Programming. Addison-Wesley, 1999.
[60]	B. Kernighan and D. Ritchie. The C Programming Language, First Edition. Prentice Hall, 1978.
[61]	B. Kernighan and D. Ritchie. The C Programming Language, Second Edition. Prentice Hall, 1988.
[62]	Michael Kerrisk. The Linux Programming Interface. No Starch Press, 2010.
[63]	T. Kilbum, B. Edwards, M. Lanigan, and F. Sumner. One-level storage system. IRE Transactions on Electronic Computers EC-11:223-235, April 1962.
[64]	D. Knuth. The Art of Computer Programming, Volume 1: Fundamental Algorithms, Third Edition. Addison-Wesley, 1997.
[65]	J. Kurose and K. Ross. Computer Networking: A Top-Down Approach, Sixth Edition. Addison-Wesley, 2012.
[66]	M. Lam, E. Rothberg, and M. Wolf. The cache performance and optimizations of blocked algorithms. In Proceedings of the 4th International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS), pages 63-74. ACM, April 1991.
[67]	D. Lea. A memory allocator. Available at http://gee.cs.oswego.edu/dl/html/malloc.html, 1996.
[68]	C. E. Leiserson and J. B. Saxe. Retiming synchronous circuitry. Algorithmica 6(1-6), June 1991.
[69]	J. R. Levine. Linkers and Loaders. Morgan Kaufmann, 1999.
[70]	David Levinthal. Performance Analysis Guide for Intel Core i7 Processor and Intel Xeon 5500 Processors. Available at https://software .intel.com/sites/products/collateral/hpc/vtune/ performance_analysis_guide.pdf.
[71]	C. Lin and L. Snyder. Principles of Parallel Programming. Addison Wesley, 2008.
[72]	Y. Lin and D. Padua. Compiler analysis of irregular memory accesses. In Proceedings of the 2000 ACM Conference on Programming Language Design and Implementation (PLDI), pages 157-168. ACM, June 2000.
[73]	J. L. Lions. Ariane 5 Flight 501 failure. Technical Report, European Space Agency, July 1996.
736 参考文献
[74]	S. Macguire. Writing Solid Code. Microsoft Press, 1993.
[75]	S. A. Mahlke, W. Y. Chen, J. C. Gyllenhal, and W. W. Hwu. Compiler code transformations for superscalar-based high-performance systems. In Proceedings of the 1992 ACM/IEEE Conference on Supercomputing, pages 808-817. ACM, 1992.
[76]	E. Marshall. Fatal error: How Patriot overlooked a Scud. Science, page 1347, March 13, 1992.
[77]	M. Matz, J. Hubicka, A. Jaeger, and M. Mitchell. System V application binary interface AMD64 architecture processor supplement. Technical Report, x86-64.org, 2013. Available at http:// www.x86-64.org/documentation_folder/abi-0 .99.pdf.
[78]	J. Morris, M. Satyanarayanan, M. Conner,
X Howard, D. Rosenthal, and F. Smith. Andrew: A distributed personal computing environment. Communications of the ACM, pages 184-201, March 1986.
[79]	T. Mowry, M. Lam, and A. Gupta. Design and evaluation of a compiler algorithm for prefetching. In Proceedings of the 5th International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS), pages 62-73. ACM, October 1992.
[80]	S. S. Muchnick. Advanced Compiler Design and Implementation. Morgan Kaufmann, 1997.
[81]	S. Nath and P. Gibbons. Online maintenance of very large random samples on flash storage. In
Proceedings ofVLDB, pages 970-983. VLDB Endowment, August 2008.
[82]	M. Overton. Numerical Computing with IEEE Floating Point Arithmetic. SIAM, 2001.
[83]	D. Patterson, G. Gibson, and R. Katz. A case for redundant arrays of inexpensive disks (RAID). In Proceedings of the 1998 ACM SIGMOD International Conference on Management of Data, pages 109-116. ACM, June 1988.
[84]	L. Peterson and B. Davie. Computer Networks: A Systems Approach, Fifth Edition. Morgan Kaufmann, 2011.
[85]	J. Pincus and B. Baker. Beyond stack smashing: Recent advances in exploiting buffer overruns. IEEE Security and Privacy 2(4):20-27, 2004.
[86]	S. Przybylski. Cache and Memory Hierarchy Design: A Performance-Directed. Approach. Morgan Kaufmann, 1990.
[87]	W. Pugh. The Omega test: A fast and practical integer programming algorithm for dependence analysis. Communications of the ACM
35(8):102-114, August 1992.
[88]	W. Pugh. Fixing the Java memory model. In Proceedings of the ACM Conference on Java Grande, pages 89-98. ACM, June 1999.
[89]	J. Rabaey, A. Chandrakasan, and B. Nikolic. Digital Integrated Circuits: A Design Perspective, Second Edition. Prentice Hall, 2003.
[90]	J. Reinders. Intel Threading Building Blocks. O’Reilly, 2007.
[91]	D. Ritchie. The evolution of the Unix timesharing system. AT&T Bell Laboratories Technical Journal 63(6 Part 2):1577-1593, October 1984.
[92]	D. Ritchie. The development of the C language.
In Proceedings of the 2nd ACM SIGPLAN Conference on History of Programming Languages, pages 201-208. ACM, April 1993.
[93]	D. Ritchie and K. Thompson. The Unix timesharing system. Communications of the ACM 17(7):365-367, July 1974.
[94]	M. Satyanarayanan, J. Kistler, P. Kumar,
M.	Okasaki, E. Siegel, and D. Steere. Coda:
A highly available file system for a distributed workstation environment. IEEE Transactions on Computers 39(4):447-459, April 1990.
[95]	J. Schindler and G. Ganger. Automated disk drive characterization. Technical Report CMU-CS-99-176, School of Computer Science, Carnegie Mellon University, 1999.
[96]	F. B. Schneider and K. P. Birman. The monoculture risk put into context. IEEE Security and Privacy 7(1):14-17, January 2009.
[97]	R. C. Seacord. Secure Coding in C and C++, Second Edition. Addison-Wesley, 2013.
[98]	R. Sedgewick and K. Wayne. Algorithms, Fourth Edition. Addison-Wesley, 2011.
[99]	H. Shacham, M. Page, B. Pfaff, E.-J. Goh,
N.	Modadugu, and D. Boneh. On the effectiveness of address-space randomization. In Proceedings of the 11th ACM Conference on Computer and Communications Security (CCS), pages 298-307. ACM, 2004.
[100]	J. P. Shen and M. Lipasti. Modern Processor Design: Fundamentals of Superscalar Processors. McGraw Hill, 2005.
参考文献 737
[101]	B. Shriver and B. Smith. The Anatomy of a High-Performance Microprocessor: A Systems Perspective. IEEE Computer Society, 1998.
[102]	A. Silberschatz, P. Galvin, and G. Gagne. Operating Systems Concepts, Ninth Edition. Wiley, 2014.
[103]	R. Skeel. Roundoff error and the Patriot missile. SMM TV而 25 ⑷:11，July 1992.
[104]	A. Smith. Cache memories. ACM Computing Surveys 14(3), September 1982.
[105]	E. H. Spafford. The Internet worm program: An analysis. Technical Report CSD-TR-823, Department of Computer Science, Purdue
University, 1988.
[106]	W_ Stallings* OperattVig Sysfems:
Design Principles, Eighth Edition. Prentice Hall, 2014.
[107]	W. R. Stevens. TCP/IP Illustrated, Volume 3: TCP for Transactions, HTTP, NNTP and the Unix Domain Protocols. Addison-Wesley, 1996.
[108]	W. R. Stevens. Unix Network Programming: Interprocess Communications, Second Edition, volume 2. Prentice Hall, 1998.
[109]	W. R. Stevens and K. R. Fall. TCP/IP Illustrated, Volume 1: The Protocols, Second Edition. Addison-Wesley, 2011.
[110]	W. R. Stevens, B. Fenner, and A. M. Rudoff. Unix Network Programming: The Sockets Networking API, Third Edition, volume 1. Prentice Hall, 2003.
[111]	W. R. Stevens and S. A. Rago. Advanced Programming in the Unix Environment, Third-Edition. Addison-Wesley, 2013.
[112]	T. Strieker and X Gross. Global address space, non-uniform bandwidth: A memory system performance characterization of parallel systems. In Proceedings of the 3rd International Symposium on High Performance Computer
Architecture (HPCA), pages 168-179. IEEE, February 1997.
[113]	A. S. Tanenbaum and H. Bos. Modern Operating Systems, Fourth Edition. Prentice Hall, 2015.
[114]	A. S. Tanenbaum and D. Wetherall. Computer Networks, Fifth Edition. Prentice Hall, 2010.
[115]	K. P. Wadleigh and I. L. Crawford. Software Optimization for High-Performance Computing: Creating Faster Applications. Prentice Hall, 2000.
[116]	J. F. Wakerly. Digital Design Principles and Practices, Fourth Edition. Prentice Hall, 2005.
[117]	M. V. Wilkes. Slave memories and dynamic storage allocation. IEEE Transactions on Electronic Computers, EC-14(2), April 1965.
[118]	P. Wiison, M. Johnstone, M. Neely, and D. Boles. Dynamic storage allocation: A survey and critical review. In International Workshop on Memory Management, volume 986 of Lecture Notes in Computer Science, pages 1-116. Springer-Veriag, 1995.
[119]	M. Wolf and M. Lam. A data locality algorithm. In Proceedings of the 1991 ACM Conference on Programming Language Design and Implementation (PLDI), pages 30-44, June 1991.
[120]	G. R. Wright and W. R. Stevens. TCP/IP Illustrated, Volume 2: The Implementation. Addison-Wesley, 1995.
[121]	J. Wylie, M. Bigrigg, J. Strunk, G. Ganger,
H. Kiliccote, and P. Khosla. Survivable information storage systems. IEEE Computer 33:61-68, August 2000.
[122]	T.-Y. Yeh and Y. N. Patt. Alternative implementation of two-level adaptive branch prediction. In Proceedings of the 19th Annual International Symposium on Computer Architecture (ISCA), pages 451^61. ACM, 1998.
推荐阅读-
计算机组成与设计：硬件/软件接口（原书第5版1计算机组成与设计：硬件/软件接口丨英文版•第5版_亚洲版)
作者：戴维A.帕特森等 ISBN: 978-7-111-50482-5 定价：99.00元
作者：David A. Patterson ISBN: 978-7-111-45316-1 定价：139.00元
计算机体系结构：量化研究方法（英文版•第5版）计算机系统：系统架构与操作系统的高度集成
#者：JohnL.Hennessy等	作者：阿i肯尚尔.拉姆阿堪德兰等
ISBN： 978-7-111-36458-0 定价：138.00元	ISBN: 978-7-111-50636-2 定价：99.00元
如何使用本书
从程序员的角度来学习计算机系统是如何工作 的会非常有趣。最理想的学习方法是在真正的系统 上解决具体的问题，或是编写和运行程序。这个主 题观念贯穿本书始终。因此我们建议你用如下方式 学习这本书：
*学习一个新槪念时，你应该立刻做一做紧随其 后的一个或多个练习题来检验你的理解。这些 练习题的解答在每章的末尾。要先尝试自己来 解答每个问题，然后再查阅答案。
♦每一章后都有一组难度不同的作业题，这些题 目需要的时间从十几分钟到十几个小时，但建 议你尝试完成这些作业题，完成之后你会发现 对系统的理解更加深入。
*本书中有丰富的代码示例，鼓励你在系统上运 行这些示例的源代码。
»我们邀请国内名师录制了本书的导读，从中你 可以了解各章的重点内容和知识关联，形成关 于计算机系统的知识架构。
*向老师或他人请教和交流是很好的学习方式。 我们将不定期组织线上线下的学习活动，你可 以登录本书网络社区及时了解活动的信息，并 与学习本书的其他读者交流、讨论。
为帮助读者更好地学习本书，我们开设了本书 的网络社区，请扫描如下二维码或登录http://www. hzmedia.com.cn/e/丨sj加入社区，获得本书相关学 习资源，了解活动信息。
深入即解ili?：机系统齡第3版
Computer Systems A Programmer's Perspccti\ e Third Edition
基于该教村的北欠“计算机系沆导论”课程实施已有五年，焊到了学生的广泛赞誉，学生们通过 这门课程的学习建立了完整的计舁机系统的知识体系和整体知识樞架.养成了良好的编程习惯并获得 丫縞写高性能、可移植和健壮的程序的能力，奠定了后续学习操作系统、鴂译、计算机体系结构等专 业课程的基絀北大的教学实践表明，这是一衣值得推荐采用的好教村本书第3版采用最新X86-64架 构来贯穿各部分知识我相信、该书的出版将有助于国内计算机系统教学的进一步改进，为培养从事 系统级钊新的计算机人才奠定氓好的基絀
-咐宏中国科学院院士/发展中国家科学院院士
以低年级开设•‘深入理解计舁机系统”课程为基础，我先后在复旦大学和上海交通大学软件学院 主导了汲进的教学改革……现在我课題组的奇年教师全部是首批经历此教学改革的学生_本科的扎实 基絀为他们认事系统软件的研究打下了良好的基絀……师資力殳的补充又为推进更加激进的教学改革 钊造了条件.
喊诚卞上海交通大学软件学院院长
本书是一本将计算机软件和硬件理论结合讲述的经典教程，内容覆盖计算机导论、体系结构和处理器 设计等多门课程。本书的最大优点是从程序员的角度描述计算机系统的实现细节，通过描述程序是如何映 射到系统上，以及程序是如何执行的，使读者更好地理解程序的行为，以及程序效率低下的原因。
和第2版相比，本版内容上最大的变化是，从以IA32和X86-64为基础转变为完全以X86-64为基础。主 要更新如下：
*基于X86-64,大量地重写代码，首次介绍对处理浮点数据的程序的机器级支持。
*处理器体系结构修改为支持64位字和操作的设计。
*引入更多的功能单元和更复杂的控制逻辑，使基于程序数据流表示的程序性能模型预测更加可靠。
參扩充关于用GOT和PLT创建与位置无关代码的讨论，描述了更加强大的链接技术（比如库打桩）。
•增加了对信号处理程序更细致的描述，包括异步信号安全的函数等。
*采用最新函数，更新了与协议无关和线程安全的网络编程。
"P Pearson
本书将陆续为读者提供丰富的学习资源， 扫描二维码加入本书社区，获得相关学习资源，
www.pearson.com
.投播热线：（010)88379604
丨客服热线：（010)88378991 88361066
:钩书热线：（010)68326294 88379649 68995259
华章网站：www.hzbook.com 网上钩书：www.china-pub.com 败字阅读：www.hzmedia.com.cn
上架指导：计0机\基础