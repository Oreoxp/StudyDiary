# 多线程服务器的适用场合

[TOC]

​		开发服务端程序的一个基本任务是处理并发连接，现在服务端网络编程处理并发连接主要有两种方式:

- 当 “ 线程 ” 很廉价时 , 一台机器上可以创建远高于 CPU 数目的 “ 线程 ” 。这时一个线程只处理一个 TCP 连接 ( 甚至半个 ) , 通常使用阻塞 IO ( 至少看起来如此 ) 。例如，Python gevent、Go goroutine、Erlang actor。这里的“线程”由语言的 runtime 自行调度，与操作系统线程不是一回事。
- 当线程很宝贵时，一台机器上只能创建与 CPU 数目相当的线程。这时一个线程要处理多个 TCP 连接上的 IO ,通 常使用**非阻塞 IO**和 **IO multiplexing**。 这是原生线程，能被操作系统的任务调度器看见。

​        首先，一个由多台机器组成的分布式系统必然是多进程的(字面意义上) ,  因为进程不能跨 OS 边界。在这个前提下，我们把目光集中到- -台机器，一台拥有至少 4 个核的普通服务器。如果要在一台多核机器上提供-种服务或执行一个任务，可用的模式有 :  ( 这里的“模式”不是pattern,而是model,不巧它们的中译文是一样的。)

1. 运行一个单线程的进程;
2. 运行一个多线程的进程;
3. 运行多个单线程的进程;
4. 运行多个多线程的进程。

这些模式之间的比较已经是老生常谈，简单地总结如下。

- 模式 1 是不可伸缩的( scalable ),  不能发挥多核机器的计算能力。
- 模式 3 是目前公认的主流模式。它有以下两种子模式:
                3a 简单地把模式 1 中的进程运行多份
                3b 主进程 + woker 进程，如果必须绑定到一个 TCP port , 比如httpd+fastcgi
- 模式 2 是被很多人所鄙视的，认为多线程程序难写，而且与模式 3 相比并没有什么优势。
- 模式 4 更是千夫所指，它不但没有结合 2 和 3 的优点，反而汇聚了二者的缺点。



​		本文主要想讨论的是模式 2 和模式 3b 的优劣，即:  什么时候一个服务器程序应该是多线程的。从功能上讲，没有什么是多线程能做到而单线程做不到的，反之亦然，都是状态机嘛。从性能上讲，无论是 IO bound 还是 CPU bound 的服务，多线程都没有什么优势。

​		由此可见，多线程并不是万灵丹( silver bullet)，它有适用的场合。那么究竟什么时候该用多线程?在回答这个问题之前，我们先谈谈必须用单线程的场合。



## 必须使用单线程的场合

​		据我所知，有两种场合必须使用单线程:

1. 程序可能会 fork(2);
2. 限制程序的 CPU 占用率。

​        **一、只有单线程程序能 fork(2)** 根据后面的分析，一个设计为可能调用 fork(2)的程序必须是单线程的，比如后面中提到的“看门狗进程”。多线程程序不是不能调用fork(2)，而是这么做会遇到很多麻烦，我想不出做的理由。

​		一个程序 fork(2) 之后一般有两种行为:

1. 立刻执行 exec()， 变身为另一个程序。例如 shell 和 inetd ;  又比如 lighttpd fork() 出子进程，然后运行 fastcgi 程序。或者集群中运行在计算节点上的负责启动 job 的守护进程(即所谓的“看门狗进程" )。
2. 不调用 exec() ,  继续运行当前程序。要么通过共享的文件描述符与父进程通信 , 协同完成任务 ; 要么接过父进程传来的文件描述符，独立完成工作，例如 20 世纪 80 年代的 Web 服务器 NCSAhttpd。

​        这些行为中，我认为只有“看门狗进程”必须坚持单线程，其他的均可替换为多线程程序( 从功能上讲)。

​		**二、单线程程序能限制程序的 CPU 占用率**  这个很容易理解， 比如在一个 8 核的服务器上 , 一个单线程程序即便发生 busy-wait ( 无论是因为 bug,还是因为overload ) , 占满 1 个 core, 其 CPU 使用率也只有 12.5%.   在这种最坏的情况下，系统还是有 87.5% 的计算资源可供其他服务进程使用。



## 单线程程序的优缺点

​		从编程的角度，单线程程序的优势无须赘言 : 简单。程序的结构一般如第二章所言，是一个基于 IO multiplexing 的 event loop 。或者直接用阻塞 IO。event loop 的典型代码框架见S3.2。

​		Event loop 有一个明显的缺点，它是**非抢占的( non-preemptive)**。假设事件 a 的优先级高于事件 b , 处理事件 a 需要 1ms , 处理事件 b 需要 10ms 。如果事件b稍早于a发生，那么当事件a到来时，程序已经离开了poll(2)调用，并开始处理事件
b。事件a要等上10ms才有机会被处理，总的响应时间为 11ms。这等于发生了优先
级反转。这个缺点可以用多线程来克服，这也是多线程的主要优势。



## 适用多线程程序的场景

 		我认为多线程的适用场景是 : **提高响应速度**，让 IO 和 “ 计算 ” 相互重叠，降低 latency。虽然多线程不能提高绝对性能，但能提高平均响应性能。

​		一个程序要做成多线程的，大致要满足:

- 有多个 CPU 可用。单核机器上多线程没有性能优势 ( 但或许能简化并发业务逻辑的实现 ) 。
- 线程间有共享数据，即内存中的全局状态。如果没有共享数据，用模型 3b （主进程 + woker 进程）就行。虽然我们应该把线程间的共享数据降到最低，但不代表没有。
- 共享的数据是可以修改的，而不是静态的常量表。如果数据不能修改，那么可以在进程间用 shared memory , 模式 3 就能胜任。
- 提供非均质的服务。即，事件的响应有优先级差异，我们可以用专门的线程来处理优先级高的事件。防止优先级反转。
- latency 和 throughput 同样重要，不是逻辑简单的 IO bound 或 CPU bound 程序。换言之，程序要有相当的计算量。
- 利用异步操作。比如 logging。无论往磁盘写 log file , 还是往 log server 发送消息都不应该阻塞 critical path。
- 能 scale up。一个好的多线程程序应该能享受增加 CPU 数目带来的好处，目前主流是 8 核,很快就会用到 16 核的机器了。
- 具有可预测的性能。随着负载增加，性能缓慢下降，超过某个临界点之后会急速下降。线程数目一般不随负载变化。
- 多线程能有效地划分责任与功能，让每个线程的逻辑比较简单，任务单一，便于编码。而不是把所有逻辑都塞到一个 event  loop 里，不同类别的事件之间相互影响。

这些条件比较抽象，这里举两个具体的 ( 虽然是虚构的 ) 例子。

​		假设要管理一个 Linux 服务器机群，这个机群里有 8 个计算节点，1 个控制节点。机器的配置都是一样的，双路四核 CPU , 千兆网互联。现在需要编写一个简单的机群管理软件 ( 参考 LLNL 的 SLURM  ), 这个软件由 3 个程序组成:

1. 运行在控制节点上的 master , 这个程序监视并控制整个机群的状态。
2. 运行在每个计算节点上的 slave , 负责启动和终止 job , 并监控本机的资源。
3. 供最终用户使用的 client 命令行工具，用于提交 job 。

​        根据前面的分析，slave 是个 “ 看门狗进程 ”，它会启动别的 job 进程，因此必须是个单线程程序。另外它不应该占用太多的 CPU 资源，这也适合单线程模型。master 应该是个模式 2 的多线程程序 : 

- 它独占一台 8 核的机器，如果用模型 1，等于浪费了 87.5% 的 CPU 资源。
- 整个机群的状态应该能完全放在内存中，这些状态是共享且可变的。如果用模式 3 ,  那么进程之间的状态同步会成大问题。而如果大量使用共享内存，则等于是掩耳盗铃，是披着多进程外衣的多线程程序。**因为一个进程一旦在临界区内阻塞或 crash , 其他进程会全部死锁。**
- master 的主要性能指标不是 throughput，而是 latency , 即尽快地响应各种事件。它几乎不会出现把 IO 或 CPU 跑满的情况。
- master 监控的事件有优先级区别，一个程序正常运行结束和异常崩溃的处理优先级不同，计算节点的磁盘满了和机箱温度过高这两种报警条件的优先级也不同。如果用单线程，则可能会出现优先级反转。
- master 要异步地往本地硬盘写 log , 这要求 logging library 有自己的 IO 线程。
- master 有可能要读写数据库，那么数据库连接这个第三方 library 可能有自己的线程，并回调 master 的代码。
- master 要服务于多个 clients , 用多线程也能降低客户响应时间。也就是说它可以再用 2 个 IO 线程专用处理和 clients 的通信。
- master 还可以提供一个 monitor(监控) 接口,用来广播推送 ( pushing ) 机群的状态 , 这样用户不用主动轮询 ( polling )。这个功能如果用单独的线程来做，会比较容易实现，不会搞乱其他主要功能。
- master 一共开了 10 个线程：
  - 4 个用于和 slaves 通信的 IO 线程。
  - 1 个 logging 线程。
  - 1 个数据库 IO 线程。
  - 2 个和 clients 通信的 IO 线程。
  - 1 个主线程，用于做些背景工作，比如 job 调度。
  - 1 个 pushing 线程，用于主动广播机群的状态。
- 虽然线程数目略多于 core 数目，但是这些线程很多时候都是空闲的，可以依赖 OS 的进程调度来保证可控的延迟。

综上所述，master 用多线程方式编写是自然且高效的。

​		





​		再举一个 TCP 聊天服务器的例子，这里的 “ 聊天 ” 不完全指人与人聊天，也可能是机器与机器 “ 聊天 ” 。 这种服务的特点是并发连接之间有数据交换，从一个连接收到的数据要转发给其他多个连接。因此我们不能按模式 3 的做法，把多个连接分到多个进程中分别处理 ( 这会带来复杂的进程间通信 ) ，而只能用模式 1 或者模式 2 。如果纯粹只有数据交换，那么我想模式 1 也能工作得很好，因为现在的 CPU足够快 , 单线程应付几百个连接不在话下。

​		如果功能进一步复杂化， 加上关键字过滤、黑名单、防灌水等等功能，甚至要给聊天内容自动加上相关连接，每一项功能都会占用 CPU 资源。这时就要考虑模式 2 了，因为单个 CPU 的处理能力显得捉襟见肘，顺序处理导致消息转发的延迟增加。这时我们考虑把空闲的多个 CPU 利用起来，自然的做法是把连接分散到多个线程上 ,  例如按 round-robin 的方式把 1000 个客户连接分配到 4 个 IO 线程上。这样充分利用多核加速。具体的例子见第六章。





### 线程的分类

​		一个多线程服务程序中的线程大致可分为 3 类：

1. IO 线程，这类线程的主循环是 IO multiplexing， 阻塞地等在 select/po1l/epoll_wait 系统调用上。这类线程也处理定时事件。当然它的功能不止 IO , 有些简单计算也可以放入其中，比如消息的编码或解码。
2. 计算线程 , 这类线程的主循环是 blocking queue , 阻塞地等在 condition variable 上。这类线程一般位于 thread  pool 中。这种线程通常不涉及 IO ,  一般要避免任何阻塞操作。
3. 第三方库所用的线程，比如 logging , 又比如 database  connection。

​        服务器程序一般不会频繁地启动和终止线程。甚至，create thread 只在程序启动的时候调用，在服务运行期间是不调用的。

































